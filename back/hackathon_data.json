{
    "hackathons": [
        {
            "title": "hackTAMS 2025",
            "location": "University of North Texas",
            "url": "https://hacktams-2025.devpost.com/",
            "submission_dates": "Feb 15 - 16, 2025",
            "themes": [
                "Beginner Friendly",
                "Open Ended",
                "Web"
            ],
            "organization": "hackTAMS",
            "winners": false,
            "projects": [
                [
                    {
                        "title": "Drug-on-Drug Interaction Network",
                        "description": "Before mixing prescriptions, over-the-counter medication, or supplements, check for potential interactions with our AI-powered DDI Network. Ensure your safety with just a few clicks!",
                        "story": "Inspiration: Every year, 16.3 million people misuse prescription medications, often unaware of the risks posed by drug interactions. Healthcare specialists agree that the widespread availability and high usage of prescription drugs contribute to abuse, addiction, and even overdose. Many of these tragedies could be prevented with greater awareness and smarter tools for managing medication safety. That\u2019s why we created the Drug-on-Drug Interaction (DDI) Network\u2014a powerful, AI-driven solution designed to help users identify potential drug interactions before they lead to serious health consequences.What it does: Drug-on-Drug Interaction Network(DDI Network) is a safety guide that allows users to input their personal health information and medication details, including dosage. It then analyzes potential drug interactions using a comprehensive drug database and helps users determine if the medicines they are taking are compatible with each other.How it was Built: We developed the DDI Network using the following.Llama to deploy and run the AI model efficiently.Python for backend logic and AI-driven drug interaction analysis.Biogrid and Therapeutics Data Commons (TDC) databases for accurate and up-to-date drug interaction data.Streamlit for a clean and user-friendly interface.,Challenges we ran into: Something that we struggled with was ensuring the LLM was trained on up-to-date drug interaction data and understood these chemical processes. To do so, we needed to fine-tune our LLM, which came with its own set of complications; however, we were able to debug these issues and develop real-time AI integration. Additionally, designing an intuitive and accessible UI for users of all demographics was challenging. With multiple iterations, we created and added specific features each time that made our project more accessible for all demographics.Accomplishments that we're proud of: We\u2019re proud of successfully building a functional prototype within 24 hours, and specifically integrating real-time drug interaction analysis using AI. We also created a seamless user experience with a clean, accessible design and developed a potentially life-saving tool that can benefit users worldwide.What we learned: Through researching and building this project, we learned the true complexity of drug interactions and the importance of reliable medical data. We also gained experience in optimizing AI models for real-time processing and user-friendly outputs. Most importantly, our project experience shed light on accessibility within healthcare applications.What's next for Drug on Drug Interaction Network: There are multiple next steps for DDI Network. We would like to implement voice input and chatbot features for easier accessibility and to make medical information more easily understandable for the public. Additionally, we\u2019d like to not only inform what drugs do or do not interact well, but also provide substitutions for drugs that perform similarly without interacting.",
                        "github": "https://github.com/anirudhmazumder/DDI-Platform",
                        "url": "https://devpost.com/software/fefe"
                    },
                    {
                        "title": "Murder Mystery",
                        "description": "Murder mystery generator that generates groups of suspects, weapons and places and based on one of those things filled in identifies the other parts (ex: place-beach, weapon-knife, suspect- Dan)",
                        "story": "Inspiration: The game Murdle (Murdle.com)What it does: It provides a murder mystery scenario with different characters, weapons and locations. It gives multiple statements that are used by the game and players to solve for the murderer, where they were and the weapon they had.How we built it: It hasn't been built yet due to my lack of experience with Javascript, but I'm planning to program it next year.Challenges we ran into: Likely challenges would probably be making sure there are no contradictions in the code that would result in an wrong answer, unsolvable mystery or an error when running it.Accomplishments that we're proud of: Right now? Making the presentation with the different cards.What we learned: What's next for Murder Mystery: Next year development of the program and possibly animation of the game's format will take place, where players are allowed to input their answer to see if it's right or wrong.",
                        "github": "",
                        "url": "https://devpost.com/software/murder-mystery-mz6aw5"
                    },
                    {
                        "title": "HS Course Planner",
                        "description": "The last 4 years of your childhood is spent on deciding how the entire course of your life goes. Isn't it stressful trying to figure out if you are making the right choices? Look no further!",
                        "story": "Inspiration: At the start of my freshman year, I had no clue what I planned to do in the future. The uncertainness of it was frightening, and I had no idea how to start planning ahead! Now, in the present, we've created a tool to assist with what we had troubles with in the past.What it does: Our project will help determine what classes you should take in high school depending on the course rigor, planned major and college, current grade level, and ability to double on core classes. With that info, we give users a planned route of classes to take until 12th grade.How we built it: We used next js as our framework, and Openai's models to help decide what courses the user should take, the courses were scraped off college and high school sites in order to get the data.Challenges we ran into: Using AI was a new thing for most of us, except for one person, so he had to teach us how to make use of the openai models. Getting the back end to work was also difficult and we never ended up finishing that part however we managed to get it working locally last secondAccomplishments that we're proud of: IT WORKS!!!\nWhat we learned\nHow to use gpt models in the core functionality of projects. We also improved our ui design compared to previous projects.What's next for HS Course Planner: Adding an additional page so that counselors can modify courses offered and more user friendly Ui.",
                        "github": "https://github.com/Kevin-the-the/CoursePlanner",
                        "url": "https://devpost.com/software/hs-course-planner"
                    },
                    {
                        "title": "Bit-By-Bit",
                        "description": "Quickly learn how to use logic gates. Have fun moving through levels and completing challenges with logic gates. ",
                        "story": "How to Use: Instructions:Scroll to Zoom in/out\nMiddle Mouse / RMB to pan\nLeft Click to place / move items\nLeft Click nodes to connect them to each other\nLeft Click on attached nodes to detach themInspiration: We wanted to help teach people about how to use logic gates. We also wanted to spread awareness about the inner workings of a laptop.What it does: Our application has 2 modes. The first mode is playground mode where the user can mess around with logic gates freely to learn in a free-form response. The second mode is Challenge mode where the user completes challenges with specific constraints on the logic gates that can be used.How we built it: We built our application using Godot with GD Script. Godot is a great tool for creating games and has a \"unity-like\" interface. We also used a version of Photoshop to help with image and asset creationChallenges we ran into: We ran into many challenges while developing this project. For example, we had to work around drag and drop for objects to ensure that we could move them around. Another struggle was Godot's weird behavior where it kept changing the UIDs of files, causing frequent merge conflicts and file overridesAccomplishments that we're proud of: We were incredibly proud when we figured out how to make wiring work properly within the logic gates so that the user wouldn't be able to break them. This was incredibly difficult and was initially a big roadblock in our project. The primary hurdle was coming up with a system for the nodes to understand what is connected to what. We ended up designing an observer object that handles all the connections between the sockets in the game.What we learned: We learned how to manage version control with 5 different programmers. Many of us also learned game programming logic and used Godot for the first time. This was a very different programming experience as it was more premade objects based rather than traditional OOP where there are classes that derive from each other. This style allowed us to prototype more rapidly than focus on the structure of the code and systems.What's next for Bit-By-Bit: Next, we hope to add more modes, many more lessons, and a calculator functionality into our application. These changes will make our application more complete and functional overall.\"MIT made Scratch, This team made 'Bit by Bit'\" - Aasrith Parasu",
                        "github": "https://github.com/cyberneel/bit-by-bit",
                        "url": "https://devpost.com/software/bit-by-bit-0xelc7"
                    },
                    {
                        "title": "TCuS Medical AI Web-App ",
                        "description": "Don't want to go to the doctors just yet and don't want to be an internet doctor? Try TCuS Health, a web-app using AI and a plethora of datasets to check all your symptoms and receive a diagnosis!",
                        "story": "What was our Inspiration forTCuS Health?: As we started living away from home, it has been difficult to schedule doctor check-ups and attend them without stressing over losing time from homework and classes. Searching symptoms from the internet gave us so many different diagnoses-- I don't think I have cancer from a headache! Our solution is TCuS Health, a web-app that accurately records your symptoms to give a realistic diagnosis.What it does: TCuS Health first displays a list of questions like \"do you have a cough?\" or \"are you experiencing shortness of breath?\". Then, each question is followed by a yes or no option or a enter value based on the question type. The app then takes the data and runs it through the AI Model we created to output if the user had a possible cardiovascular issue, stroke, cold, COVID, and influenza (flu).How we built it: First we went through hundreds of medical Kaggle datasets to see what matched our needs all around. Then, we created a model by using SK Learn and TensorFlow that takes in numerical and categorical data which is what all of our suggestions are based from. Simultaneously, we created the front end on ExpoGo to have our questions shown to the user to display the final result.Challenges we ran into: Some include...Accomplishments that we're proud of: In these 24 hours...What we learned: What's next for TCuS Medical AI Web-App: Whats next? Right now, the app focuses on respiratory and cardiovascular issues and diseases, and we plan on adding more diseases and disorders from more body systems. We also would love to add mental health issues in our app, so stay tuned so yall can get more med-tastic diagnoses! :)",
                        "github": "",
                        "url": "https://devpost.com/software/tcus-medical-ai-web-app"
                    },
                    {
                        "title": "InvestAware",
                        "description": "The Future of Intelligent Investing.",
                        "story": "Inspiration: Imagine losing thousands of dollars because you sold Tesla stock just hours before it skyrocketed. This isn't an hypothetical - it's the reality millions of retail investors face every day, not because they lack intelligence, but because they're overwhelmed by data.InvestAwarehelps remediate this problem.The numbers are staggering: individual investors losebillionsannually due to emotional trading and information overload. Almosttwo-thirdsof retail investors underperform the market, despite having access to more information than ever before. The problem isn't a lack of data - it's having too much of it.Picture yourself trying to make a single trading decision. You're juggling multiple news sources, technical indicators, social media sentiment, and analyst reports - all while trying to act before the opportunity disappears. This fragmented approach leads to analysis paralysis and missed opportunities.Currently, investors face an impossible choice: either paythousandsfor enterprise-level tools or settle for oversimplified apps that lack real analytical depth. Thanks to recent breakthroughs in artificial intelligence, we've found a better way.What it does: Our platform's power comes from it'sthree-layered approach:But here's what makes us unique - our AI doesn't just analyze these streams separately: it understands how they interact. This is best demonstrated with a real-world example:During Apple's latest earnings announcement, our system analyzed the earnings report alongside3,000news articles and social media posts in real-time. The result? Our model predicted actionable insights12 hoursbefore a major price movement.How we built it: We started with a two-pronged approach: one person focused on the front-end and workflow integration, while the other tackled the complexities of training the AI model. For the front-end, we began with a basic HTML/CSS/JS system, embedding necessary functions and styling directly into the HTML page using<script>tags and in-line CSS. As we progressed, we developed reusable styling sheets and scripts to ensure consistency across the website. Finally, we connected the front-end to the AI model through a Redis database and a Python back-end, creating a seamless flow of data and insights.With the model, we faced the challenge of balancing accuracy and efficiency. Training the AI on historical data to predict news sentiment and market movements required significant computational power. To optimize this, we started by testing smaller data sets and gradually scaled up, running extensive training sessions overnight. This iterative approach allowed us to refine the model without compromising on performance.Challenges we ran into: The primary hurdle we ran into was the lack of historical data. We tried to find a reliable resource to directly pull news headlines in recent times from, but this didn't work. This resulted in us having to create a scraper of sorts and then pull the date of the article when training our model.Another hurdle was time. Training the model on large historical data sets to ensure accurate sentiment analysis and market predictions was incredibly time-consuming. To mitigate this, we adopted a phased approach: testing on smaller data sets during the day and running full-scale training overnight. This allowed us to make progress without being bottlenecked by the model's training time.Lastly, we also ran into a challenge with integrating the front-end with the back-end seamlessly. Ensuring that the Redis database communicated effectively with the Python back-end and the front-end required meticulous debugging and optimization. However, overcoming these challenges made the final product more robust and reliable.Accomplishments that we're proud of: We're incredibly proud of how the project came together. While there\u2019s always room for polish, the core functionality is fully operational, and the predictions page, the heart of our platform, works exactly as envisioned.Some specific achievements we\u2019re proud of include:: Mastering Redis: Figuring out how nodes and tasks work in Redis was a major milestone.UI/UX Design: Creating an intuitive and visually appealing interface that simplifies complex data for users.Model Training: Successfully training the AI model to analyze and predict market movements with impressive accuracy (back testing, or predicting for past dates, reveals an average accuracy of 64% \u00b1 2).,What we learned: This project was a massive learning experience for both of us. We gained hands-on experience in UI/UX design, full-stack development, and AI model training. Understanding how to integrate these components into a cohesive system was invaluable. Additionally, we learned the importance of iterative testing and optimization, especially when working with large data sets and complex algorithms.What's next for InvestAware: We believe InvestAware has the potential to go far beyond hackTAMS. The platform is designed with scalability in mind, and we\u2019ve already incorporated monetization elements to prepare for a potential product launch.Our next steps include:Enhancing the AI model: Expanding the data sets and refining the algorithms to improve prediction accuracy.Adding more features: Incorporating advanced tools like portfolio optimization and risk assessment.User feedback: Launching a beta version to gather user feedback and make iterative improvements.,InvestAware isn\u2019t just a project\u2014it\u2019s a solution to a real-world problem.",
                        "github": "",
                        "url": "https://devpost.com/software/investaware"
                    },
                    {
                        "title": "Sherriff",
                        "description": "AI-Driven Small-Scale Supply Chain Risk Forecasting: Simulating Disruptions, Predicting Impact",
                        "story": "Inspiration: We were interested in one primary question: \"Can new reports help predict disruptions in supply chains?\"Companies like Palantir often have extremely large datasets or incredibly comprehensive internal data streams. However, in the real world, this is often not always accessible, and humans in decision-making roles must make the best out of sparse, proprietary dataset.What it does: We structured our project around three core components:How we built it: We built it using langchain, python, openai, flask, and lots of code.What we learned: Throughout the process, we uncovered several key insights:News-based forecasting is viable\u2013 Sentiment analysis and structured extraction from news articles can offer meaningful risk indicators.Simulated data can be useful\u2013 While real-world datasets are often sparse or proprietary, generating simulated historical supply chain events allowed us to test our models effectively.Traditional neural networks struggle\u2013 Standard machine learning approaches are ok at making accurate risk predictions, but LLM-based methods performed surprisingly well with minimal input.,",
                        "github": "",
                        "url": "https://devpost.com/software/sherriff"
                    },
                    {
                        "title": "LinkedUp",
                        "description": "Professional connections, without the BS.\r\nLinkedUp offers impactful, industry-spanning personalized contacts so that you can elevate yourself and your business.",
                        "story": "Pitch Deck LinkInspiration: We were motivated by theoverwhelming negative perceptionsurrounding LinkedIn. Many people complained about itspoor UI, unprofessional atmosphere, and general tendency to impede professional connection.What it does: LinkUp takes the ideology behind LinkedIn andactuallyimplements it properly. LinkedIn facilitates connections between industry and academic professionals through asleek, minimalist UI, aself-cleansing productivity-oriented atmosphere, and acommitment to foster network growth.How we built it: To bring LinkUp to life, we used NextJS and React. To includeseamless authentication and onboarding, we leverage Clerk. We are committed to real human interaction -- our use of getStream allows us to generaterealtime video and voice callsin ascalable, impactful fashion. Finally, we leverage anadvanced ML-powered user score systemto effectively match professionals with like-minded peers. (Specific technicalities refer to our github readme).Challenges we ran into: We initially attempted to provide user authentication viaSupabase. This proved unfruitful, so we migrated toClerk(although we still use Supabase for our backend).Accomplishments that we're proud of: We are firstly proud to have a working product demo showing off ourmost impactful features. We are confident that our current application isscalable and modifiable, as we plan to continue working on it even past Digital Jam.What we learned: We learned that hackathons can be stressful and nerve-wracking, but alsofun. We learned a lot about Clerk and Stream -- none of us had ever used these APIs before -- in a raw, experience-focused way thatcouldn't happen in a non-hackathon setting.What's next for LinkUp: We are slated to addseveral new featuresto LinkUp: B2B meeting opportunities, mentor-client sessions, and employer-employee interviews, to name a few. We are also committed to improving the general look and feel of the app, to ensure its competitiveness to the best of our ability.",
                        "github": "",
                        "url": "https://devpost.com/software/linkedup-d5slpu"
                    },
                    {
                        "title": "SSRNA",
                        "description": "The future of antibiotic development",
                        "story": "We used python. its a prototype. woohoo guys!! go csooo",
                        "github": "",
                        "url": "https://devpost.com/software/ssrna"
                    },
                    {
                        "title": "Sign 2 Speech",
                        "description": "Convert ASL to text-to-speech.",
                        "story": "",
                        "github": "https://github.com/adippiii/hackTAMS25",
                        "url": "https://devpost.com/software/sign-language-2-speech"
                    },
                    {
                        "title": "DeepScan Intelligence",
                        "description": "In a world where deepfakes and AI-generated content spread faster than the truth, how can you tell what\u2019s real and what\u2019s not? That\u2019s where DeepScan Intelligence comes in. ",
                        "story": "DeepScan Intelligence: Our Story: In an era where misinformation spreads rapidly, distinguishing real from fake has become increasingly difficult. With AI-generated deepfakes becoming more sophisticated, manipulated media has the power to mislead, distort reality, and erode trust. Recognizing the urgency of this issue, a team of passionate innovators at the Texas Academy of Mathematics and Science came together to create a solution\u2014DeepScan Intelligence.DeepScan was founded on a shared vision: to provide a simple yet powerful tool to help individuals, businesses, and organizations verify the authenticity of digital content. With backgrounds in artificial intelligence, cybersecurity, and ethics, our team saw firsthand how deepfake technology was evolving, making it harder to discern between genuine and manipulated media.As AI-generated content became more widespread, we asked ourselves:\n\"How can we empower people to detect manipulation in videos? How can we make AI a force for truth rather than deception?\"Thus, DeepScan Intelligence was born\u2014an AI-powered tool designed to detect deepfake videos and promote transparency in digital media.We designed DeepScan to examine multiple key aspects of a video, leveraging AI to identify subtle inconsistencies that are often imperceptible to the human eye. Our scanner analyzes Facial Analysis, Audio-Visual Sync, Lighting & Shadows, and Behavioral Patterns.By integrating these AI-powered checks, DeepScan generates a comprehensive authenticity report\u2014allowing users to make informed decisions about the content they consume. We aim to level the playing field, equipping people with tools to fight digital deception and restore trust in online media.At DeepScan, we are not just building technology\u2014we are shaping the future of ethical AI. Our mission is clear: to make the internet a more transparent, trustworthy space for everyone. Join us in the fight against misinformation. Scan smarter. Stay informed. Trust DeepScan.",
                        "github": "https://github.com/azzytang/hackTAMS2025",
                        "url": "https://devpost.com/software/deepscan-intelligence"
                    },
                    {
                        "title": "Sororin Cafe",
                        "description": "The Sororin Cafe!\r\nShe must make a successful cafe business!",
                        "story": "Inspiration: it was inspired by the anime cafes I saw.What it does: You play as Sororin to run her cafe business and make the cafe sucessful!How we built it: I have yet to learn to code, but I will learn Java next year, and I am really excited to learn how to code this game!Challenges we ran into: No challenges yet!Accomplishments that we're proud of: Coming up with a narrative and story for the basis of the game I will create next year!What we learned: Game requires win and lose condition and then story + characters!What's next for Sororin Cafe: Actual coding and character development",
                        "github": "",
                        "url": "https://devpost.com/software/sororin-cafe"
                    },
                    {
                        "title": "Narrow Escape",
                        "description": "A game where you control your player to avoid obstacles which increase as you level up. With each new level, the speed increases and the levels have less time and get more difficult. ",
                        "story": "Inspiration: Our inspiration was a originally a normal car game where a player has to race around a track, but later it evolved into a game where the red box, originally known as the car, has to go through obstacles to pass through different levels. This was also inspired by the original game where it's a balloon instead of a red box and has to go through similar levels to reach and float through the sky.What it does: There is a box which you control to avoid obstacles. The obstacles are horizontal lines which block the whole row, and there is only a small space to fit your object through. The more levels you pass through, the more the speed increases and the difficulty increases.How we built it: We used Visual Studio to code the game itself using HTML and JavaScript. It took lots of brainstorming of what we wanted our game to do, and searching up codes for help whenever we ran into trouble. We took turns searching up game ideas we could use, and decided to use said ideas to come up with a design plan for our game.Challenges we ran into: We ran into challenges such as coding it exactly as we wanted it to be. We ran into a lot of trouble trying to add certain features, or when we were trying to make the game more user-friendly. Such features included the spacing between obstacles, the speed of each level, and restarting the game.Accomplishments that we're proud of: We are proud that we were able to think of this idea and code the game even though we ran into a ton of trouble. Making a game for the first time, we felt successful even though it was quite simple to play. We struggled a lot, but we got through and finished the game!What we learned: We learned how to code on Visual Studio Code and how to deal with coding troubles that come in our way. We also learned how to work with a time constraint and pressure, learning to succeed no matter what.What's next for Narrow Escape: We want to add more level, difficulties, and obstacles, with different playing styles and consequences. We want the players to get a faster reaction time and quick finger movements.",
                        "github": "https://github.com/srinfj/Narrow-Escape.git",
                        "url": "https://devpost.com/software/narrow-escape"
                    },
                    {
                        "title": "MacroManage",
                        "description": "MacroManage isn't your ordinary calorie tracking app. On top of data analysis for your calorie tracking journey, it introduces competition and features to facilitate maintaining your calorie goal.",
                        "story": "Inspiration: Me and my partner felt very boring and demotivated to use, with a lack of elements to make it more fun.What it does: Macro Manage is a fun competitive calorie-tracking app that turns nutrition and meal login into a game. It helps users track their daily calorie intake, stay consistent with their eating habits, and compete with friends or other users to earn badges and climb leaderboards.How we built it: The entire designing was done through Figma.Challenges we ran into: Though we can prerequisite knowledge of Figma, it was still a new application to us so we had to research to figure out where to find the different elements and tools.Accomplishments that we're proud of: We were especially proud because this was a complete new interface to us, and we struggle throughout the process of trying to navigate it. Nonetheless, we overcame this hurdle and were able to get to the final result.What we learned: We learned how to use a new interface, Figma, as well as the importance of different components that must be considered when trying to me an app engaging and interesting. We had to consider things like color palette, awards, and competition.What's next for MacroManage: New AI implementations may be included, including an AR feature that can detect the weight and type of food.",
                        "github": "",
                        "url": "https://devpost.com/software/macromanage"
                    },
                    {
                        "title": "Fusic",
                        "description": "Fusic is something that bridges the gap between peoples music taste, and complex musical talent.",
                        "story": "Inspiration: Inspiration\nWe drew inspiration from Tinder and Spotify, combining elements of personalized recommendations and user interaction to create a unique music experience.What It Does\nFusic analyzes users' favorite songs and generates new music with a similar style, offering a fresh yet familiar listening experience.How We Built It\nWe developed Fusic using HTML, CSS, and JavaScript, integrating various APIs to power the music generation process.Challenges We Faced\nOne of our biggest challenges was dealing with API reliability\u2014whenever we made progress, the APIs would frequently shut down, causing the website to break.Accomplishments We're Proud Of\nWe successfully hard-coded the music generator, allowing us to complete the project despite API limitations. Overcoming these obstacles made the final product even more rewarding.What We Learned\nThroughout this project, we gained a deeper understanding of how APIs work, how to integrate multiple LLMs, and the importance of time management, speed, and efficiency in development.What's Next for Fusic\nMoving forward, we aim to enhance the music generation process by refining the quality and authenticity of the generated songs.What it does: How we built it: Challenges we ran into: Accomplishments that we're proud of: What we learned: What's next for Fusic:",
                        "github": "",
                        "url": "https://devpost.com/software/fusic"
                    },
                    {
                        "title": "shady chess",
                        "description": "Winning games by any means necessary. Using the Meta Ray-Banz Glasses, we prove the versatility and optimality of continuous classification challenges, outperforming similar chess models' latency.",
                        "story": "Inspiration: Srinikesh had the idea, after his billionaire friend Akshay Sunkara purchased the Meta Glasses that he could use them for much more than simple LLM tasks. He's always been a fan of games, whether poker or League of Legends, so chess seemed like the most valuable and natural progression, especially as an avid learner. Upon hearing his idea, Benji, Hunter, and Feir joined suit and became the shady chess team!What it does: We created a fully-fleshed system for converting video streaming data from the Meta Quest Glasses to a stockfish-based system.Since the Meta Glasses API is practically nonexistent, we had to navigate and optimize the latency challenge by streaming the feed to an iPhone hosting an Instagram live (the only built-in functionality of the glasses). We converted that stream into usable data for a classification algorithm through ingenuity and perseverance.The classification algorithm turns the image into a FEN code (chess notation that is past move independent). After our novel dual classification validation using and optimizing Fenify and YOLO11s, it outputs a board FEN code that can be fed to stockfish.Stockfish returns an optimal move and converts it into a human-oriented MP3 file the user can play in their ear upon receiving it.How we built it: We created our program using Python, machine learning tools, and some shenanigans with throwable Quicktime and Instagram Live.Challenges we ran into: Our code was made before, but they had a latency of 17 seconds between their tea. Ours was around 1 second, making ours significantly more efficient than their model.Accomplishments that we're proud of: My team and I had little experience with classification tasks, so we are learning how to use those tools. It was a novel experience. We are proud of how well we worked around the glass's lack of an API and features to work with products outside of meta.What we learned: We learned a lot about computer vision and algorithms. Two of our biggest problems were when to end a tour and /or whose turn it was and determining which piece was which. To solve our turn issue, we made it so the user would give a signal whenever they wanted the best optimal move. By reading research papers and other documentation, we learned more about computer vision, fact-checking, and improving our accuracy because we know the starting position and the board's position after each turn.What's next for shady chess: We plan to expand out of chess and make it so that the glasses can keep count and track of many things at once. With chess, the difficulty comes with memorizing openings, planning steps, and analyzing and tracking the whole board. The same technology that accounts for all of this can be easily transitioned into a different environment to simplify much of the human labor and provide more accuracy when it comes to more challenging work.",
                        "github": "https://github.com/Relaxolotl07/hacktams25",
                        "url": "https://devpost.com/software/shady-chess"
                    }
                ]
            ]
        },
        {
            "title": "CalgaryHacks 2025",
            "location": "University of Calgary",
            "url": "https://calgaryhacks-2025.devpost.com/",
            "submission_dates": "Feb 15 - 16, 2025",
            "themes": [
                "Beginner Friendly",
                "Gaming",
                "Web"
            ],
            "organization": "Computer Science Undergraduate Society",
            "winners": true,
            "projects": [
                [
                    {
                        "title": "TamaLife",
                        "description": "Turn your daily habits into a game \u2013 because your life deserves a progress bar!",
                        "story": "Inspiration: The idea for this project came from Tamagotchi, the beloved virtual pet from the late \u201890s, and the desire to make personal productivity more engaging.We realized that staying on top of tasks, eating well, and maintaining healthy habits can feel like a chore\u2014so why not turn it into a game?By integrating real-world actions with a virtual pet, we created a system where your habits directly affect your pet\u2019s health, mood, and growth. The better you take care of yourself, the happier your pet becomes!What it does: TamaLife gamifies personal productivity by linking your daily habits to a virtual pet\u2019s well-being. Every action you take in real life influences how your pet grows and behaves.Core Features:\n\u2705 To-Do System \u2013 Complete tasks to keep your pet happy.\n\u2705 Food Tracking \u2013 Log meals to \u201cfeed\u201d your pet, using ML to determine if what you're eating is \"Junk Food\"\n\u2705 Real-Time Mood System \u2013 Your pet reacts based on how well your diet is, and how often you do your tasks!\n\u2705 Optional Arduino Pet \u2013 A physical 3D-printed pet with LED feedback that changes based on your progress.How we built it: TamaLife is a full-stack application with hardware integration:Mobile App (Frontend):\nReact Native with Expo\nTypeScript\nTensorFlow.js for ML model integration\nCustom animations and UI componentsBackend:\nNode.js with Express\nMongoDB for data persistence\nJWT authentication\nWebSocket for real-time updates\nMachine Learning\nTensorFlow/Keras for food classification\nCustom trained model on food/non-food dataset\nModel conversion to TFLite for mobile deploymentHardware:\nArduino microcontroller\nLCD display\nRGB LED indicators\nSerial communication with backendChallenges we ran into: \ud83d\udd38 Real-Time Syncing \u2013 Ensuring task completions and meal logs updated instantly across the system.\ud83d\udd38 User Engagement \u2013 Making sure the the app motivated users to complete their tasks, and take care of Tama!Accomplishments that we're proud of: \ud83e\udd47 Creating a Fun, Engaging User Experience \u2013 Users actually enjoy logging their habits!\ud83e\udd47 Hardware-Software Integration \u2013 Our Arduino-powered physical pet reacts to your progress.\ud83e\udd47 Healthy/Junk Food ML Model that detects what kind of food you eat, which Tama reacts to!What we learned: \u2714 Gamification boosts engagement \u2013 People are more likely to complete tasks when they feel rewarded.\u2714 Users need customization \u2013 Different people track habits in different ways. We built flexible options.\u2714 Machine learning is super fun to incorporate in projectsWhat's next for TamaLife: \ud83d\udd1c Speak to Tama - Integration of LLM's that allow users to speak to Tama\ud83d\udd1c Social Features \u2013 Compete with friends and track habit streaks together.\ud83d\udd1c Exercise Tracking \u2013 Integration with Apple Health so that Tama works out with you!\ud83d\udd1c Expanding Hardware Integration \u2013 More physical pet interactions like sounds and animations.",
                        "github": "https://github.com/hsp8412/TamaLife",
                        "url": "https://devpost.com/software/tamalife"
                    },
                    {
                        "title": "Make Your Own Friends",
                        "description": "Solve puzzles using your clones in this collaborative puzzle platformer",
                        "story": "Inspiration: We were inspired by games like Pico Park and Fireboy and Waterboy and other puzzle platformer style games where you control multiple characters working together to beat the level.What it does: You were trapped by an experiment gone wrong. Using powerful orbs released by the experiment you can duplicate yourself into different, more powerful variants. Now, you must work together with your variants to solve puzzling levels and escape from the lab!We chose to follow the third prompt which tasked us to make a game centred around Collaboration. We decided to incorporate this by having the player need to use multiple duplicates of themself to solve puzzles and escape from the lab.How we built it: We built the game in Unity with C# using art from OpenGameArt.org as well as our own art designed in Aseprite, Procreate, and Paint. \nArt credits for art not created by us:\nGame Developer Studio for the laboratory tileset which we then modified\nhassekf for the Sci-Fi Background \nCpt_Flash for the 2D Wooden BoxChallenges we ran into: We found it challenging to get all the systems working as well as transition from our placeholder models to the assets we used in the end. It was difficult getting the characters to be able to pick up other characters and throw them.Accomplishments that we're proud of: We are proud of being able to complete most of what we set out to do in the very short 24 hour time period. While some of it is a little rough, basically everything works the way we wanted in some capacity.What we learned: We learned more about Unity, creating UI and full game systems. We also learned about tilemaps and how to distribute tasks in a fairly smooth way to work together on one game in Unity over Github.What's next for Make Your Own Friends: We would like to polish the game more, and fix more buggy issues. Also, making the game design smoother and adding more levels are things we would like to work on more.How to use the game: In the github repo linked below, there is a release that includes a windows executable to run the game.\nThe controls are:AandDto moveSpaceto jump as the JumperSto shrink as the ShrinkerCto swap between your duplicatesFto pick up other duplicatesRto throw the duplicates you are carryingEto interact with objects like the exit doors\nLastly, useEscapeto pause",
                        "github": "https://github.com/Monkey042/CalgaryHacksCollabGame",
                        "url": "https://devpost.com/software/wonky-experimentation"
                    },
                    {
                        "title": "Doe or Die : Fire Rescue",
                        "description": "Become a wildlife rescuer and firefighter in a high-stakes battle against nature\u2019s fury! Save endangered animals, fight wildfires, and restore the wild in this action-packed, cooperative adventure!",
                        "story": "Inspiration: Recent wildfires have devastated ecosystems, displacing wildlife and endangering entire habitats. Inspired by real-world events such as the wildfires in LA, California, Jasper, and Australia in recent years, as well as the bravery of firefighters and wildlife rescuers, we wanted to create an engaging and educational game that raises awareness about environmental conservation while providing a fun, cooperative experience.What it does: It creates an exciting, collaborative experience that not only challenges players to work together but also raises awareness about critical real-world issues, such as wildlife conservation and wildfire prevention.How we built it: We developed Doe or Die: Fire Rescue using the Godot engine and GDScript. The fire simulation system is driven by a random number generation and check system, allowing fires to spread dynamically and unpredictably. Wildlife movement and behavior are controlled using A*, ensuring realistic navigation as animals react to the environment. The game is designed for local co-op, providing a shared experience. Instead of a structured mission system, the gameplay rewards players for saving animals and extinguishing fires the fastest, motivating them to collaborate to rescue wildlife and contain fires. All assets are hand-drawn or sourced from public domain libraries, giving the game a unique, stylized look.Challenges we ran into: One of the biggest challenges we ran into was structuring our project in a way that made collaboration smooth. Since multiple team members were working on different parts of the game, we often spent a lot of time merging and editing code on GitHub, which sometimes led to conflicts that had to be manually resolved.\nAnother major hurdle was figuring out certain aspects of Godot and GDScript. While some of us had experience with the engine, there were still features and best practices we had to learn on the fly, which slowed down development at times.\nWe also had to create brand-new animations and assets from scratch, which was time-consuming. Making sure everything fit the visual style we wanted and worked well within the game took a lot of iteration.\nFinally, one of our most ambitious tasks was developing our own wildlife CPU that could move around the environment and avoid obstacles. Implementing pathfinding and making the CPU behave naturally required a lot of tweaking and testing, but in the end, we were able to get it working in a way that added life to our game.Accomplishments that we're proud of: We\u2019re proud to have created a game that is polished enough to be expanded into a full release, with the potential to be delivered to actual players. Not only does it provide an engaging gameplay experience, but it also effectively fulfills our mission of raising awareness about wildfire prevention and wildlife conservation. The foundation we've built allows for future improvements, making this more than just a prototype\u2014it\u2019s a meaningful project with real impact.What we learned: Throughout the hackathon, we learned a lot about project organization and collaboration. One key takeaway was the importance of setting up a clear project structure from the start to avoid long merge conflicts and workflow bottlenecks. Using GitHub more efficiently\u2014like creating smaller, more frequent commits and clearly defining roles\u2014helped improve our workflow over time.\nWe also gained a deeper understanding of Godot and GDScript. Some features weren\u2019t immediately intuitive, but through trial and error, we learned how to properly structure our code, optimize performance, and make better use of the engine\u2019s built-in tools.\nWhen creating animations and assets, we realized how important it is to balance quality and efficiency. Instead of aiming for perfection right away, we found that iterating quickly and refining later helped us make better use of our time.\nDeveloping our own wildlife CPU taught us a lot about pathfinding, obstacle avoidance, and how to make movement feel natural. We experimented with different approaches and learned how small tweaks in logic and behavior can make CPU feel more dynamic and realistic.\nOverall, we learned how to tackle challenges under time pressure, adapt when things didn\u2019t go as planned, and work as a team to bring an idea to life.What's next for Doe or Die : Fire Rescue: Next, we plan to add more levels, new animals, and unique classes with specialized abilities. We\u2019ll introduce power-ups, different climate crisis themes, and new gameplay mechanics to deepen the experience and keep players engaged.",
                        "github": "https://github.com/CalHacks2025/Calgary-Hacks-2025",
                        "url": "https://devpost.com/software/doe-or-die-fire-rescue"
                    },
                    {
                        "title": "URide",
                        "description": "Who Rides? URide.",
                        "story": "Inspiration: Becoming independent isn\u2019t easy. University life throws a lot at you; figuring out your schedule, handling finances, balancing social life, and making sure you actually show up to things on time. The thing is, no one likes being forced into networking or being told, \u201cYou should go make friends.\u201d That\u2019s awkward and unnatural.We wanted to build something that helps people become more independent without making it feel like a chore. That\u2019s where URide comes in. It\u2019s not just about getting a ride, it\u2019s about making life easier, saving money, and, without even realizing it, helping students build habits of responsibility. Riders commit to scheduled rides due to their low cost, holding themselves accountable to their plans. Drivers not only make money but also maintain consistency by showing up when others are relying on them. And with the events feature, students can casually find themselves in gym meetups, study groups, or weekend soccer games without the pressure of \u201cforced socializing.\u201dThis is how independence should work. Not through pressure, but through organic opportunities that make life better while helping students develop routines, financial awareness, and a sense of accountability. URide was designed to be that low-key life hack; something that saves you money, helps you be more responsible, and gets you where you need to go without the hassle of unreliable transit or expensive rides..What it does: URide is a university-exclusive ridesharing platform that connects student drivers with riders who need a lift. It helps students:Find affordable rides to and from campus without overpaying for Uber.\nEarn money as a driver by filling up empty seats.\nBuild consistency and responsibility through scheduled commitments.\nJoin and organize community events, from study sessions to gym meetups, to make campus life more connected.\nURide also focuses on safety and trust. Every user is verified with a university email, and we built in in-app messaging and ratings to keep things secure. Plus, we integrated AI-driven features that provide financial insights and ride optimization, making the platform more than just a way to get from point A to point B.How we built it: This was our first time working with Next.js, and we quickly realized how much more efficient it is compared to a traditional React setup. We used TypeScript for extra security and built the backend with both TypeScript and FastAPI (Python) to handle ride-matching logic and API requests. Authentication was done through Firebase, which worked fine locally\u2026 until we tried deploying it (more on that later).For location and route optimization, we used Google Maps API, making it easier for drivers and riders to find the best routes. One of the coolest parts was building an AI chatbot using Naive Bayes and Pandas pipelines, which helps students with ride info and financial tips. Hosting and deployment started locally, but due to some unexpected hardware failures, we had to pivot and use Vercel to preview and deploy our platform.This project pushed us to learn API integrations, customize request handling, train AI models, and troubleshoot authentication problems. It was a crash course in building a full-stack app while constantly adapting to unexpected challenges.Challenges we ran into: This project had its fair share of roadblocks. The biggest issue was deployment. Everything ran smoothly on our local machines, but when we moved to Vercel, Firebase authentication completely stopped working. It turned out that the API had permission restrictions that weren\u2019t an issue locally but broke everything once hosted. That set us back quite a bit.On top of that, our original plan was to host everything locally, but then our PC (the \"potato computer\") completely gave up on us. This forced us to find a quick solution, which ended up being Vercel\u2019s preview feature.Another big challenge was ride-matching logic. Getting it to efficiently match drivers and riders based on route and availability took way longer than expected, but when it finally worked, it was a huge relief. Training the AI chatbot was also tough because it required a lot of computing power, which slowed down development at times.Accomplishments that we're proud of: Despite the challenges, we\u2019re really proud of what we pulled off. Successfully implementing the ride-matching system was a huge moment for us, especially after struggling with it for so long. Seeing our AI chatbot actually work and provide insights was another big win.On a technical level, we learned how to use Next.js, integrate APIs, set up authentication, customize backend requests, and train AI models. These are all skills that we\u2019ll take with us beyond this project.What we learned: One of the biggest lessons we learned was that deployment needs to be tested early. If we had checked how Firebase worked on Vercel sooner, we could have saved a lot of time troubleshooting it at the last minute. Another takeaway was that hardware limitations can seriously slow you down. Training an AI model or running a server requires power, and without a solid machine, things can crash unexpectedly.What's next for URide: If we had more time, we would focus on:Integrating a full payment system with Stripe, PayPal, and Apple Pay\nFixing authentication issues so everything works smoothly on any host, and integrating UCalgary Authentication\nHosting on a dedicated server for better performance\nImproving the AI chatbot to provide more helpful and personalized insightsNote:Demo Link is kinda messed up due to deployment issues, but final pres. copy is functional",
                        "github": "https://github.com/spectaboy/uride_v1",
                        "url": "https://devpost.com/software/uride-p63ydi"
                    },
                    {
                        "title": "LeafQuest",
                        "description": "LeafQuest, Explore, Learn and Protect ",
                        "story": "",
                        "github": "https://github.com/Don-Laliberte/CalgaryHacks2025",
                        "url": "https://devpost.com/software/tempname-gi19fb"
                    },
                    {
                        "title": "CashCorn",
                        "description": "Scurry and Save,Cash Corn helps you be more mindful about your spending, making sure you learn financial independence with both savings and critical thinking on your purchases.",
                        "story": "We teach through examples and awareness \ud83d\udcb8: CashCorn takes inspiration from squirrels that learn to stock up over the winter to live an easier and smoother cold season, and we think that individuals striving for financial independence are quite similar. They need to critically think about the time and reasons for them spending money, especially in the digital age where online impulse purchases are all too common.Allows you to think critically about your purchases \ud83d\udd0e: CashCorn is a Google extension that does a couple of things for you. It detects when you're making an impulsive buy, and stops you in your tracks by forcing you to play and reflect on if you truly need the product and showing you the common risks associated with it. With this, participants can think and see if this is a purchase they need, or something they can cook at home.A clean extension built using conventional front-end tools creatively \ud83c\udf32: We built CashCorn as a Chrome extension using react app built with Vite:Frontend:react-app developed through Vite for quick and easy installation with tailwindBuild Process:Vite was used due to its speed and having the most familiarity in the groupExtension Architecture:Content Script:Injects our code into shopping pages to detect purchase button clicks and render the overlay. Popup shows up when a button click is detected to annoy users and provide them time to think about their choicesBackground Script:Handles logging and stores purchase attempt statisticsPopup:Provides a dedicated UI when clicking the extension icon, with a dashboard displaying ho your monthly budgeting goals are fitting up your play and wallTooling:We used Chrome manifest 3 and then went with VS Code from there,Challenges were many and deep, but overcome nonetheless \ud83d\uddfb: Building CashCorn wasn\u2019t without challenge for each of usNew to chrome extensions:We encountered multiple errors as we learned about the difference between browsers and how extensions interact with the user. It's a difficulty we wouldn't have experienced had it not been a challengeCommiting Complexity:Working on multiple features on multiple branches made it difficult to work off each other. With everyone having their own component, it was difficult for inspiration to arise as we were all working on our own things until discussed furtherFile Structure & Integration:We had to refine our project structure to avoid duplicate or unused files, ensuring a clean workspace, mainly because of the confusion from Vite regarding .js, .jsx, .ts and .tsx filesCross-Site Compatibility:Designing selectors to reliably intercept purchase buttons on different websites (like Amazon and Temu) meant we needed to test and adapt our code for varying DOM structures. This presented with other challenges such as finding alternative methods for activation,Accomplishments that we're proud of \ud83c\udf1f: Seamless User Experience:Despite the technical challenges, CashCorn provides a smooth, responsive overlay that gently interrupts the buying process, encouraging users to reflect before making a purchase.Thorough set of Features:We built an extension that integrates multiple modern solutions that all have their own creative and important element towards improving independence for all, especially those looking for financial stability.Flexibility and Scalability:The project\u2019s modular design with components and parts allows the use of updates or changes as time passes, to keep the methods of keeping impulsive buyers aware,What we learned: Throughout this project, we deepened our understanding of:Chrome Extension Development:Navigating the constraints and features of Manifest V3, content scripts, and background service workers. The biggest challenge was understanding the injection and background processes that are needed by a Chrome extensionModern Frontend Tooling:Normally we use Next.js, but we opted for Vite because we were working on an extension, and wanted different tools to use. Overall was the same, but some small nuances forced us to break some habitsCross-Platform Challenges:Adapting our code to work reliably across various online retail platforms with differing HTML structures, especially better known sites that work hard to keep you hooked and have multiple page refreshesMindfulness in Technology:The importance of building tools that are interesting and helpful is to help others by providing a viable solution that doesn't just make money,What's coming up for CashCorn? \ud83c\udf31: Looking ahead, we want to make CashCorn all encompassingEnhanced Analytics:Advanced analytics on site data, to block or hide commonly wasted money on products so that people are not tempted to move towards purchases and know the risksPersonalized Recommendations:Leverage machine learning with more specific user data to give better advice to striving students and independance seekersBroader Platform Support:Expand support to other forms of purchasing and tracking to give better insights and gain more user dataCommunity Features:Foster a community of people trying to become more responsible with their time and money,CashCorn represents our drive to make programs and solutions that are applicable to us, but also ones that can be further used by the community to meet their goals as well. We hope to continue this project to make it more streamlined in the future to understand the technical and societal sides better",
                        "github": "https://github.com/rumezaa/finTrack",
                        "url": "https://devpost.com/software/cashcorn"
                    },
                    {
                        "title": "Cerebro ",
                        "description": "Multi-modal image/text semantic search for wildlife images as fast as thought. Uses embedding models trained from scratch.",
                        "story": "A note: This readme looks better on github:https://github.com/stanleyjzheng/cerebroOur project is live and deployed athttps://sjz.ca(please try it out!)Team: Vivi - UCalgary 2nd year CSStanley - UBC Sciences gapMatt - UCalgary 2nd year CS,Inspiration: In the world of wildlife and climate change education, finding the correct clips and images is critical to one's storytelling. I like X-Men and have always wanted mutant powers... what would be cooler than channeling Charles Xavier's ability to look through the eyes of others and see everything instantly with his Cerebro?How it works: TL;DR: We trained our ownCLIP-style ViT model on a large dataset of 3M image-text pairs and then 153k specialized wildlife photos (scheme in \"Training\" below). We use its embeddings for the distance between the user's text input and the wildlife photos.An embedding is a high-dimensional vector representation of something (a text or an image); the closer two vectors are, the more semantically similar they are. Eg. if you subtract the embedding of \"mother\" from the embedding of \"father\", you get a vector that is similar to the vector of \"parents\". This means that we can use distance to determine the similarity between two embeddings.CLIP has two neural networks: one for images (in this case, a vision transformer) and one for text (a transformer, like GPT).Given an image, the image encoder produces an embedding representing its visual features. Given a text string, the text encoder generates a corresponding embedding that captures its semantic meaning.We scrape wildlife images, and for each image, we precompute its embedding and store it (scheme in \"Similarity Search\" below). When a user inputs a text query, it is converted into an embedding using the text encoder. Then, we calculate the distance between the text embedding and each image embedding.The image with the highest distance is selected as the best match. This shared embedding space allows CLIP to generalize well to unseen image-text pairs, making it highly effective for zero-shot learning and retrieval tasks like ours.Similarity Search Scheme: What is similarity search?Given a set of vectors $x_i$ in dimension d, Faiss builds a data structure in RAM\nfrom it. After the structure is constructed, when given a new vector x in\ndimension d it performs efficiently the operation:$$j = argmin_i||x-x_i||$$where $||\u00b7||$ is the Euclidean distance ($L^2$).In Faiss terms, the data structure is an index, an object that has an add method\nto add $x_i$ vectors. Note that the $x_i$'s are assumed to be fixed.Computing the argmin is the search operation on the index.This is all what Faiss is about. We use it to return the k-th nearest neighbour in a large dataset of 152982 images and tens of thousands of video stills in real-time.Training Scheme: Checkpoints are intraining/.We trained on 4x Nvidia RTX4090 with a VIT-B-32 model (~151m params). Everything is fairly meticulously optimized to use data parallelism and split across multiple GPU's. It's capable of scaling across multiple nodes for larger models (but which would take much more than our 24hr time limit to train).Our training scheme is as follows:For more details on pseudo-labelling, I gavea talkon it 4 years ago. It's fairly authoritative and it's much longer than I can explain in a readme.CC3m was downloaded fromimg2datasetand took ~1 hour. Initial CC3M training took ~6 hours on the 4x RTX4090 GPU's. Then, each pseudo label scheme took ~45min for 152982 images.We used no externally pretrained models. Our model was a random weights initialization which we trained from scratch on CC3M, then fine tuned on wildlife images.How to run the frontend: It's deployed atsjz.cabut you can also run it locally on your own data.How to run training: It's a really long process. Reach out to me!Biggest challenge: We had to write the interface twice because streamlit doesn't support streaming text changes. And I thought it would be cool to have instantaneous inference while a user was still typing. It was a pain.",
                        "github": "https://github.com/stanleyjzheng/cerebro",
                        "url": "https://devpost.com/software/cerebro-zdnqhj"
                    },
                    {
                        "title": "alula",
                        "description": "Empowering bird enthusiasts and protecting our feathered friends - one snap at a time.",
                        "story": "Inspiration: Did you know that over 1200 bird species across the world are currently threatened, vulnerable, or endangered, per the IUCN Red List? Or that the bird population in North America has dropped by 3 BILLION since 1970? These are only two ofmanyunfortunate statistics, of which the root cause is human action - or humaninactionin the face of climate change.This spurred us to createalula- an AI-powered tool to help bring awareness of birds and bird conservation efforts to anyone and everyone. The namealulacomes from the word that refers to a bird's thumb - a small set of feathers on the frontmost edge of the wing. This biological structure prevents wing stalling by creating vortices in the air, streamlining bird flight. In the same way, we aim to streamline education and awareness surrounding avian conservation efforts.What it does: alulauses an image classification model to identify any species of bird from a single image. It allows users to catalogue images of their identified birds and share them with friends.alulaalso features gamification to enhance the user learning experience, with a leaderboard of users ranked by the number of birds identified and achievements that are unlocked by completing specific bird identification tasks.How we built it: alula's image classification model was trained using the NABirds V1 dataset from the Cornell Lab of Ornithology, which features over 48,000 pictures of over 1,000 bird species. The model was trained with Create ML over 25 iterations with noise, blur, crop, expose, flip, and rotate augmentations, then used in Xcode using both the Core ML and Vision frameworks.Friends and achievements were both created as separate tables in a relational database hosted on Supabase, which is accessed by the frontend.Bird information, such as IUCN Red List status and habitat information, was obtained using the Wikipedia API and the GBIF API and stored in a table on Supabase.The frontend was created entirely in SwiftUI, with various assets designed using Affinity Suite.Challenges we ran into: The IUCN Red List API proved difficult to use due to their transitioning of their API from v3 or v4. v4 was not completely fleshed out, preventing us from accessing conservation status using a bird's common name, but v3 was no longer accessible due to being retired in July 2024.Accomplishments that we're proud of: We're proud of how we built this application using a complete Apple stack, from the image classification to the frontend. We were also very excited about how efficient Supabase makes backend work.What we learned: We learned how to use Core ML, Supabase, and the Wikipedia and GBIF APIs over the course of this hackathon.What's next for alula: We'd love to access larger datasets to further improve our model's accuracy, and implement more community-building features such as group birdwatching and bird identification events.We are entering this project under Bounty 1 - Implement an AI/ML system trained using a dataset.",
                        "github": "https://github.com/MrKai77/Alula",
                        "url": "https://devpost.com/software/alula"
                    },
                    {
                        "title": "Bird Vision",
                        "description": "Quickly scan a bird or upload a photo, and see what species it is! You can see information about the bird, as well as if it's endangered and information about climate change, using an AI chat-bot.",
                        "story": "Inspiration: Me, Daniel, and Alvish love the outdoors and learning more about nature. When we saw the prompt about inspiring wildlife conservation efforts, we were reminded of how much we love learning more about the different plants and animals in the world. In particular, I had recently come across an app which lets you scan photos of plants and see what species they are. We believe that in learning more about the environment around you, you feel more connected to it and become more likely to make efforts to protect it.What it does: Bird Vision is a web app that allows you to take a picture of a bird, or upload a photo. Our home-trained AI/ML model analyses the photo and predicts which type of bird it is. From there, you can learn more about whether or not the species is endangered, how species endangerment is connected to climate change, and what you can do to conserve wildlife.How we built it: We built Bird Vision by applying two different AI models. First, we made a completely custom AI model using Teachable Machine, which can take in an image of a bird, and identify it using our extensive dataset of birds. Secondly, we incorporated Gemini as a chat-bot which can interact with the user and open up a discussion. These technologies are hosted on a website running on Django.Challenges we ran into: We found it quite challenging to navigate AI technologies that we were not previously familiar with, and dealing with the specifics of fine-tuning our model to workjustright.Accomplishments that we're proud of: We're really proud of the ease-of-use of our website. I believe in accessibility, and I think that the friendliness of our website could inspire people to go out in nature--- especially children---and learn more about our world.What we learned: We all learned a lot about AI/ML. For myself, at least, this was my first big glimpse into working with AI in a larger project. But what I will say for everyone is that we learned a lot about the importance of teamwork and resilience. We encountered disagreements in terms of design decisions and aesthetics, and many challenges with things not working and stress of time pressure. But I'm proud of the way we pushed through them as a team and managed to create something great.What's next for Bird Vision: Bird Vision still has much room to grow, and we're happy to expand it. For one, the AI/ML model is only trained on the smaller version of our dataset. Given more time and processing power, we could create a model that is not only more accurate, but more expansive -- covering not just birds, but all animals and plants. Something that would really improve the look and feel of Bird Vision would be to port it to a native mobile app. I think that Bird Vision is something that is something that I'd love to share with more people on the iOS and Android stores.",
                        "github": "https://github.com/alvishprasla11/BirdVision",
                        "url": "https://devpost.com/software/bird-vision"
                    },
                    {
                        "title": "Escape The Matrix",
                        "description": "Agent Smith is on his way; Neo and Morbius must work together to escape! Solve interesting puzzles with an asymmetrical cooperation aspect.",
                        "story": "Inspiration: Most of our team had game dev experience, and Shanna in particular had XR experience, which all helped shape the direction of our brainstorming, and ultimately the creation of our game idea. Though we began with brainstorming ideas for each of the three topics, we quickly realized that we were most interested in this particular game idea, which then became Escape The Matrix!What it does: Our game is actually two games, intended to be played in parallel. On the VR side, you play as Neo and mustEscape The Matrix. However, you do not have all the information necessary to escape, which is why you need the help of the second player, who plays as Morpheus, and can decipher the clues that Neo finds. But, you must communicate efficiently, or else you may run out of time!How we built it: Since there was so much to do, we split up and each began working on the parts that we would be most comfortable working on. Tung started writing C++, Aaron wrote a server in Rust, Shanna began fiddling with the VR/AR headsets, and James started composing the soundtrack. Then, towards the end of the 24 hours, we had to work together to integrate all of our systems together.Challenges we ran into: Throughout working on this project, we did run into some hurdles. Particularly, it turns out that VR headsets are quite difficult to develop for, so there was quite a bit of work that went into getting that whole side up and running. We also chose to write the terminal side of the game in a different language than the server, which ended up creating some nasty connection bugs that we had to sort out.Accomplishments that we're proud of: Personally, I'm a big fan of our game idea, and I think there's definitely more to explore if we had more time. Also, I think the fact that we got the XR aspect working is pretty unique. But, overall, we all learned a lot in the process of making this project, and that's what we're most proud about!What we learned: We learned a lot about how to interconnect separate systems, making them work together in an interesting way. We also learned a lot about really weird and specific Rust/C++ bugs! haha. Also, I (James) had never used Unity before, so I've gained some experience not only working with Unity, but I also got to practice the art of learning new things, which is invaluable in life.What's next for Escape The Matrix: Due to the tight deadline, we only got a chance to include a single level, but if we had more time we would have included more than one (since we actually designed more!) I think there's a lot of room for interesting puzzle design, exploiting the unique dynamic between the asymmetric partners.",
                        "github": "https://github.com/shanna1408/CalgaryHacks25",
                        "url": "https://devpost.com/software/escape-the-matrix"
                    },
                    {
                        "title": "Fin Track",
                        "description": "Independent Living: Your guide to financial literacy and personal independence through interactive quizzes and personalized reminders.",
                        "story": "Introduction: Managing finances can be overwhelming, and many students and people lose track of their spending, savings, and recurring payments. Our app provides a seamless way to keep financial information always in sight and never out of mind.What It Does: The app offers a physical display that constantly shows your bank status, balance, transactions, and savings, ensuring full visibility of your finances. Users can also set reminders for recurring payments to avoid missed bills. Additionally, interactive quizzes educate users on financial literacy in a fun and engaging way.How We Built It: We integrated banking APIs to fetch real-time financial data and designed a user-friendly interface for quick access. The physical display syncs with the app, keeping financial insights readily available. The quizzes were carefully curated to make learning about personal finance enjoyable and informative.Challenges We Ran Into: Ensuring secure data handling while displaying real-time financial information.Creating a seamless connection between the app and the physical display.Designing quizzes that are both educational and engaging.,Accomplishments That We're Proud Of: Successfully developing a financial tracking display that enhances user awareness.Implementing an intuitive app that simplifies financial management.Designing quizzes that make financial literacy fun and accessible.,What We Learned: The importance of user experience in financial applications.How to integrate banking APIs securely and efficiently.Strategies to engage users in learning about finance through gamification.,",
                        "github": "https://github.com/MannPatel0/Fin-Track",
                        "url": "https://devpost.com/software/fin-track"
                    },
                    {
                        "title": "Super Scary Wildfire Simulator",
                        "description": "Wildfire spread simulator which utilizes data on Alberta wildfires between 2006-2024 and townships data of humidity, temperature, and wind speed.",
                        "story": "",
                        "github": "",
                        "url": "https://devpost.com/software/project-of-mass-gpa-desctruction"
                    },
                    {
                        "title": "Critically Wild ",
                        "description": "Save the Wild, One Click at a Time. The clock is ticking for endangered species. Explore the world map, learn their extinction timelines, and choose how to save them, because they're on a time crunch!",
                        "story": "",
                        "github": "https://github.com/AbdelrahmanBekhit/EndangeredAnimal.git",
                        "url": "https://devpost.com/software/critically-wild"
                    },
                    {
                        "title": "Wild-Change",
                        "description": "Using historic satellite imagery and wildlife population data we had aimed to create a means of visualizing the impacts of climate change and the environmental impacts of human activity.",
                        "story": "",
                        "github": "",
                        "url": "https://devpost.com/software/wild-change"
                    },
                    {
                        "title": "CanRepay",
                        "description": "CanRepay is a mobile app that helps Canadian students conquer their student loan debt with personalized repayment plans and budgeting tools",
                        "story": "",
                        "github": "https://github.com/asiaao/CanRePay",
                        "url": "https://devpost.com/software/canrepay"
                    },
                    {
                        "title": "Wild Frame",
                        "description": "3d Interactive Globe",
                        "story": "",
                        "github": "https://github.com/sreeragvadde/Calgary-Hacks-2025.git",
                        "url": "https://devpost.com/software/wild-frame"
                    },
                    {
                        "title": "SuiteLife - Find. Love. Rent.",
                        "description": "Moving is stressful enough, your lease shouldn't be. Let SuiteLife handle the hard work.",
                        "story": "Inspiration: The inspiration for this project came from the fact that a few of my friends did not like the terms of their lease and weren't particularly happy with their situation. This happens to millions of people around the world, who don't have the expertise and experience to look for the fine print that can ruin the fun of independence.What it does: SuiteLife analyses your lease agreement and summarises the terms. It checks for any potential issues with the lease and recommends action items to improve the lease conditions. It has a built-in 'fairness score' that evaluates how far the leasing agreement deviates from the 'standard lease'. Additionally, it utilizes the users location to give more relevant responses, that are applicable to the province the user resides in.How we built it: Flask: we used Flask for the backend, we used MongoDB for the database and Gemini API for the analysisFront End: We used HTML, CSS, Bootstrap, Google Fonts, and Jinja2 for the front end.,Challenges we ran into: Debugging the AI Client and the structured response took a few hours, we had to try multiple different AI models and APIs before we had a successful break.,Accomplishments that we're proud of: We are very happy with the way this project looks, from a front-end perspective and we also love how useful it is to us personally.,What we learned: Fix your posture when you code for more than 5 hours at a time.,What's next for SuiteLife - Find. Love. Rent.: Instead of using the Gemini API, we hope to train the model using our own network and data.,",
                        "github": "https://github.com/saqibx/CalgaryHacks25",
                        "url": "https://devpost.com/software/suitelife-find-love-rent"
                    },
                    {
                        "title": "EcoGuardian",
                        "description": "Protecting wildlife through computer vision and AI-powered reporting, adoption, and community volunteerism",
                        "story": "Inspiration: Every year, millions of animals are injured, endangered, or displaced due to human activity and environmental changes. Yet, many people who want to help don\u2019t know how or where to start. We were inspired to create EcoGuardian to bridge this gap, empowering individuals to take meaningful action for wildlife conservation through technology, community, and innovation.What it does: EcoGuardian is a digital platform that empowers users to:By combining AI, computer vision, and community-driven initiatives, EcoGuardian fosters a collaborative approach to wildlife protection and environmental sustainability.How we built it: Frontend:Typescript, React, AxiosStyling:Tailwind CSSBackend:Node.js, Express.jsDatabase:MySQL for user data, adoption records, and conservation opportunitiesAI/ML:TensorFlow for computer vision (species identification) and FastAPI for connecting the AI model to detect animalsTools:GitHub for version control, Figma for wireframes & prototypes and UI design,Challenges we ran into: AI Model Accuracy:Training the computer vision model to accurately identify a wide range of species in diverse environments was challenging. We developed a custom-trained AI model using TensorFlow for species identification, leveraging computer vision to analyze and categorize wildlife in distress. This AI-driven approach enhances rescue efforts and conservation strategies without relying on pre-trained models.User Experience:Balancing simplicity with the need for advanced features (e.g., AI guidance, AR integration) was a design challenge.Data Privacy:Safeguarding user data while maintaining seamless functionality required robust backend architecture.,Accomplishments that we're proud of: Successfully integrating AI-powered, real-time species identification and wildlife reporting.Developing a scalable backend and database to handle user data, adoption records, and volunteer activities efficiently.Building a user-friendly platform that combines reporting, adoption, and volunteerism in one place.Creating a community-driven ecosystem that connects users with local conservation organizations.,What we learned: How to leverage AI and computer vision to solve real-world conservation challenges.The power of community engagement in driving meaningful environmental impact.The challenges of balancing technical complexity with ease of use, and the significance of user-centered design in creating a platform.,What's next for EcoGuardian: Expand AI Capabilities:Improve species identification accuracy and add support for more endangered animals.AR Integration:Allow users to \"see\" their adopted animals in the wild using augmented reality.Gamification:Introduce badges, leaderboards, and rewards to encourage user engagement.Global Reach:Partner with international conservation organizations to expand the platform\u2019s impact.,Eligible Hackathon Tracks: Challenge:Create an application to promote wildlife conservation amidst climate changeChallenge:Develop a resource that supports individuals transitioning to independence, providing tools, guidance, and community connectionsBounty:Your solution involves an AI/ML model trained by your team using a dataset of your choice (no pre-trained models are used),",
                        "github": "https://github.com/CalgaryHacks2025",
                        "url": "https://devpost.com/software/ecopulse-sicyv1"
                    },
                    {
                        "title": "Interlinked",
                        "description": "This website helps young adults who have just gained independence and international students who are new to the country or city, through things like food guides, finances and social spaces. ",
                        "story": "Inspiration: Helping students and new adults learn how to deal with life in an easier way where just like a spiderweb, we have everything linked in one page for people to be able to easily access services and support.,What it does: It links you to websites and services that can help you and support you in your independence journey. Additionally, it has a mental health chatbot which can support you, especially in times of need and struggle as a independent individual who may not be able to get access to mental support.,How we built it: HTML, CSS, JS, Python, Apis: OpenStreetMap (Leaflet.js)\nChatbot.com API,Challenges we ran into: Implementing the chatbotGit Issuesunderstanding how js works,Accomplishments that we're proud of: -Making a real-time tracking system work\n-Successfully integrating multiple APIs into one easy-to-use platform.\n-Creating a clean, user-friendly design that people actually like.What we learned: how to to make a chatbot and tracker, and how to pull on VS code bc we were new to that\n## What's next for Interlinked\n-adding a semi-social network like linkedin to link ppl to connect and bond something like linkedin or instagram, and as well as improving the transit system accuracy and the website overall!,",
                        "github": "https://github.com/Sama-M-M/Hackathon02-15",
                        "url": "https://devpost.com/software/interlinked-h2nct9"
                    },
                    {
                        "title": "Tempo Tactics",
                        "description": "\"Tempo Tactics\", a 2D side-scrolling platformer where one player traverses a vibrant world filled with rhythmic obstacles, while the Composer plays notes that empower the Dancer with unique abilities.",
                        "story": "",
                        "github": "https://github.com/MarkJPC/CalHacks2025",
                        "url": "https://devpost.com/software/tempo-tactics"
                    },
                    {
                        "title": "Love at First Bite",
                        "description": "Do you like meals with long prep time, or are more of a quicky person? This recipe hub is the perfect place to find your match for any kind of person.",
                        "story": "Inspiration: Our app was inspired by the idea that many young adults see recipes on apps like Tik Tok and Instagram, but these recipes often aren't easy to follow, aren't affordable, and often require ingredients that the user doesn't have or cannot afford, so these recipes sit collecting dust in their saved reels. Our goal was to gamify the process of recipe selection, and make it easier for young adults to find cheapWhat it does: Love at first bite allows young adults to browse recipes as though they were swiping through tinder, with the same goal, to find the perfect match! It matches users with recipes that fit their ingredients and budget.How we built it: We used a React front end and a Express and AWS RDS back end, using Duckduckgo scraping techniques to fill our database.Challenges we ran into: Getting the database up and running properly was a massive challenge that caused many issues and greatly delayed the project.Accomplishments that we're proud of: Actually finishing the project, filling it with tons of recipes that are cheap, healthy, and easy to follow.What we learned: How to scrape from the web properly, and set up a database in a usable manner.What's next for Love at First Bite: Matching many young adults with recipes that will last them a lifetime.",
                        "github": "",
                        "url": "https://devpost.com/software/love-at-first-bite"
                    },
                    {
                        "title": "Fledge",
                        "description": "Adulting is hard. Fledge makes it suck less with easy task reminders\u2014like setting up banking or meal prepping\u2014so you can feel like a functional human and get your sh#% together.",
                        "story": "Inspiration: We wanted to create something relatable and practical for students and young adults because, frankly, we were never taught how to be \"adults\". Many of us left home, started school, or moved out, only to realize that basic life tasks like budgeting, setting up a bank account, or scheduling doctor\u2019s appointments felt overwhelming. We were expected to know these things\u2014but no one taught us how.Fledge was born out of that struggle.We wanted to build the tool we wish we had\u2014something to help you get your life together, one small task at a time.What it does: Fledge is a task generator designed to help students and young adults tackle \u201cadulting\u201d one step at a time.Press \u201cGenerate Task\u201d \u2192 Receive a random, achievable adulting task (e.g., \u201cSet up a TFSA,\u201d \u201cBook a health checkup,\u201d \u201cReview your monthly expenses\u201d).Complete it or Task Again \u2192 No pressure. You can mark it as done or get another task.One Small Win at a Time \u2192 You build momentum and confidence in handling life\u2019s responsibilities.Fledge is a pledge to yourself\u2014to make adulting feel a little less impossible.How we built it: Frontend: React with Vite, React Router, Sass for styling.Task Flipper Animation: A \u201cflipper\u201d animation for task generation.Component-based Structure: Built modular components like TaskFlipper, GenerateButton, and pages like DoMorePage for scalability.Collaboration: Used GitHub for version control and coordinated tasks across frontend and backend teams.,Challenges we ran into: Learning new tools quickly: Some of us were new to Vite, Sass, and React Router, so figuring out the best practices while building was a learning curve.Time constraints: Fitting the project scope into 24 hours meant prioritizing core functionality and keeping the design simple.Team coordination: Combining frontend work across multiple contributors while ensuring styling consistency and functionality took careful communication.,Accomplishments that we're proud of: Building the core structure of a React app with a task generator concept in under 24 hours.Designing an intuitive, low-pressure task system that feels encouraging, not overwhelming.Creating an approachable, relatable tool for students and young adults\u2014something that could genuinely help people feel more in control of their lives.,What we learned: React & Vite Setup: Faster development workflows with Vite, component structure, and state management.CSS Organization: Using Sass for global styles and reusable variables to keep the design consistent across components.Team Collaboration: Balancing individual component work while integrating everything smoothly in a short time frame.Understanding our audience: Speaking to the realities of \u201cadulting\u201d helped us design an app that feels realistic and supportive for young adults.,What's next for Fledge: Expanding the Task Database: Adding more task categories (Finance, Health, Career, Home) to cover more areas of \u201cadulting\u201d.Progress Tracking: Let users log their completed tasks and celebrate milestones to build motivation.Community Input: Allowing users to submit their own adulting tasks\u2014building a community-driven list that reflects real experiences.Reminders & Notifications: Gentle nudges for tasks so users can set daily or weekly goals.Improved Task Randomizer: Prioritizing urgent or time-sensitive tasks (e.g., tax season reminders).,",
                        "github": "https://github.com/chantal-delcarmen/fledge/",
                        "url": "https://devpost.com/software/fledge"
                    },
                    {
                        "title": "WildGuard - Let's Save The World Together!",
                        "description": "\r\nWildGuard \u2013 Let's Save The World Together! \ud83c\udf0d\ud83d\udc3e  \r\nAn interactive mobile app that educates, inspires action, and connects people to protect wildlife and fight climate change. Every action counts!",
                        "story": "Inspiration: SO, we all know that wildlife is disappearing at an alarming rate due to climate change and habitat destruction. We wanted to build a digital platform that not only educates but also empowers people to take real action. Our goal was to make wildlife conservation engaging, accessible, and impactful by integrating technology with environmental activism.What it does: WildGuard is an interactive app that:Educates users on climate change and its effects on wildlife.Uses AI-powered image recognition to identify endangered species.Provides real-time climate & conservation updates.Encourages eco-friendly actions through gamified challenges.Connects users with conservation projects & volunteer opportunities.,How we built it: Handling image processing efficiently while keeping the app responsive.Integrating AI models (Gemini 2.0 API) within Flutter for seamless user interaction.Designing an intuitive UI that balances education with engagement.Ensuring real-time updates without performance bottlenecks.,Challenges we ran into: Successfully integrated AI for wildlife recognition.Created an eco-challenge system that gamifies conservation.Designed a community-driven reporting tool for real-world impact.,Accomplishments that we're proud of: The importance of user engagement in conservation apps.How to optimize AI models for image-based queries in Flutter.The power of real-time data in climate change awareness.How gamification encourages positive environmental actions.,What we learned: Expand AI capabilities to provide more accurate species identification.Launch partnerships with wildlife organizations for real-world impact.Develop a reward system where users can earn badges for eco-actions.Introduce a social aspect where users can share conservation efforts.,What's next for WildGuard - Let's Save The World Together!: Together, we can make a difference!** Join WildGuard and be a part of the movement to save our planet. \ud83c\udf0e\u2728",
                        "github": "https://github.com/sanskarjha36/wildguard-app/tree/sanskarjha36-latest-update",
                        "url": "https://devpost.com/software/wildguard-let-s-save-the-world-together"
                    },
                    {
                        "title": "Calgary-101",
                        "description": "Moving to a new city is overwhelming, but Calgary 101 can help! Whether you're a student, worker, or immigrant, it gives you the tools you need to settle in and embrace your newfound independence. ",
                        "story": "Inspiration: We were inspired by the concept of newfound independence that comes with moving away from home. As newcomers ourselves, we are very familiar with many of the struggles that one faces when they have to navigate their way through life in a new city. This application is the type of resource that we would have appreciated when we were trying to figure out what steps we should take after moving in as young adults.What it does: Our app is a one-stop guide for newcomers, helping them navigate daily life, from public transit to local hotspots. Whether you're a student, worker, or immigrant, Calgary 101 gives you the essential tools to settle in and embrace your newfound independence. It includes four categories such as An Essential Checklist for all official documentation, Emergency Contacts, Adventures in the city, and Resources that we think all Calgarians would benefit from.How we built it: We used the Java GUI package JavaFX in IntelliJ Idea to create this project.Challenges we ran into: Some implementations that were thought of were difficult to accomplish with the time constraint and so, we had to cut out many features.Accomplishments that we're proud of: We are proud of the GUI interface and the logging feature that makes the app a little gamified.What we learned: We learnt how to take a project from GitLab to GitHub, complete a project in 24 hours from the planning stage to a complete product that we can present to an audience.What's next for Calgary-101: Potential Future Features Include:Multiple language supportSecurity featuresLogin and User featuresStudent accounts (UCalgary)Point and Reward System for gamification,",
                        "github": "https://github.com/Srijita-Marick/Calgary-101",
                        "url": "https://devpost.com/software/calgary-101"
                    }
                ],
                [
                    {
                        "title": "Calgary Connect",
                        "description": "Calgary Connect is an all-in-one community hub designed to bring local residents together. ",
                        "story": "Calgary Connect: About the Project: Inspiration: Calgary Connect was born out of a desire to create a local digital space where Calgarians could come together, share their voices, and support each other through every aspect of daily life. Inspired by the strong community spirit of Calgary\u2014from its vibrant cultural events to its unique financial challenges\u2014we wanted to design a platform that not only fostered local connections but also addressed everyday needs like budgeting and meal planning.What we Learned: Throughout this project, we delved deeply into:Real-Time Communication: Integrating Django Channels and WebSockets taught us how to build robust, real\u2011time messaging systems.\nFile Handling: Implementing image uploads for posts and messages improved our understanding of Django\u2019s file storage mechanisms.\nUser-Centric Design: Balancing multiple features like posting, direct messaging, following, and financial management challenged us to think about how to best present information in an intuitive, accessible manner.\nDatabase Management: Managing migrations and ensuring data integrity across multiple models (like posts, likes, follows, comments, and financial entries) was both challenging and rewarding.\nHow I Built It\nThe project was built using Django for the backend, with Channels providing the real\u2011time WebSocket functionality. Here\u2019s an overview of the core components:Django & MySQL: Served as the foundation for user management, posts, messaging, and financial tracking.\nDjango Channels: Enabled real\u2011time messaging, replacing traditional polling with WebSocket connections for instant communication.\nFile Uploads: Integrated image uploads for both posts and direct messages, leveraging Django\u2019s built\u2011in file storage system.\nResponsive UI: The front end was styled with custom CSS and Bootstrap to ensure a clean, modern look and a user\u2011friendly experience.\nFinancial Tools: Built-in forms allowed users to track their income and expenses directly on the site, eliminating the need for external spreadsheets.Challenges Faced: Real-Time Messaging: Switching from a JavaScript polling mechanism to WebSockets with Django Channels required rethinking the entire messaging system. Debugging asynchronous code and ensuring a seamless user experience was a steep learning curve.\nFile Handling: Ensuring that images uploaded via posts and messages were stored, served, and displayed correctly involved juggling Django\u2019s media settings, file storage configurations, and responsive front\u2011end design.\nDatabase Migrations: Managing complex migrations for multiple models (including posts, comments, likes, follows, and financial entries) was challenging, especially when introducing new relationships and ensuring data integrity.\nUser Experience: Balancing multiple features (social networking, real\u2011time messaging, and financial management) in one platform required careful UI/UX design to keep the interface intuitive and engaging.\nCalgary Connect is the culmination of overcoming these challenges, and it represents both a technical achievement and a commitment to fostering a strong local community. It\u2019s been a rewarding journey of growth and innovation, and we look forward to continually refining and expanding the platform.",
                        "github": "https://github.com/SYM-Hacks/CalgaryHacks2025",
                        "url": "https://devpost.com/software/calgary-connect"
                    },
                    {
                        "title": "WildTrails",
                        "description": "A hiking app using AI to recommend trails, let users share wildlife sightings, earn points, and donate to conservation, raising awareness about climate change.",
                        "story": "InspirationWe drew inspiration from the growing need to balance outdoor recreation with ecological responsibility. Seeing the impact of climate change on wildlife, we wanted to create a platform that encourages both enjoyment of nature and active conservation efforts.What It DoesWildTrails is a hiking app that uses AI to recommend trails based on weather, safety, and popularity data. It fosters a community around wildlife sightings\u2014users earn points for sharing photos of local fauna, learn about endangered species, and can donate directly to relevant conservation organizations.How We Built ItBackend (Python + Flask): Integrates Google Maps, WeatherAPI, and safety data to power an AI/ML model for dynamic trail recommendations.Frontend (TypeScript/TSX): Displays trail info, user posts, and donation links in a responsive UI.\nCommunity & Gamification: Points and badges for wildlife sightings, encouraging responsible exploration and awareness of at-risk species.Accomplishments We\u2019re Proud OfSeamless API integration and data fusion to deliver real-time trail recommendations.\nAn interactive community feature that not only rewards wildlife sightings but also teaches users about each species and its conservation status.\nA clear path to impact with built-in donation options and educational prompts.\nWhat\u2019s Next for WildTrailsAdvanced AI Verification: Implement computer vision to identify species from photos and award points automatically.\nExpanded Conservation Partnerships: Collaborate with local NGOs and parks to offer volunteer opportunities within the app.\nGlobal Trail Coverage: Extend beyond initial regions to support more countries and varied ecosystems.\nRefined Gamification: Introduce team challenges, seasonal events, and more in-depth achievements to sustain long-term engagement.",
                        "github": "https://github.com/ChetasPatel787/WildTrails.git",
                        "url": "https://devpost.com/software/wildtrails"
                    },
                    {
                        "title": "Catchy!",
                        "description": "Catchy! lets users explore nature, snap wildlife photos, and identify species. Learn about habitats and conservation while making real-world discovery fun and educational! ",
                        "story": "Inspiration: The Catchy App was inspired by the concept of a Pok\u00e9dex, but instead of fictional creatures, it allows users to explore and catalog real-world wildlife. The idea stemmed from a passion for nature, biodiversity, and technology. We wanted to create an engaging and educational tool that encourages people to explore their surroundings while learning about the environment.What We Learned: Throughout the development of The Catchy App, we gained valuable insights into:Wildlife Identification\u2013 Understanding how species recognition works and how to leverage APIs for classification.User Engagement\u2013 Designing features that encourage exploration, learning, and social interaction.Conservation Efforts\u2013 Researching how donations and awareness campaigns can support endangered species.App Development\u2013 Implementing real-time data visualization and AI-based image recognition.,How We Built It: The Catchy App was developed using the following technologies:Frontend: Flutter for a smooth and responsive UI.Backend: Firebase for authentication and database management.Image Recognition: iNaturalist API for identifying species from user-submitted photos.Mapping: Google Maps API to display wildlife sightings worldwide.Social Features: Firebase Firestore for friend system and trading functionality.,Users can take photos of animals or plants.The app utilizes the iNaturalist API to recognize and classify species.Successfully identified species are added to the user's registry.,Each identified species is stored in the user's personal collection, providing information such as:Habitat\u2013 Where the species is commonly found.Behavior & Ecology\u2013 How the species interacts with its environment.Climate Change Impact\u2013 How environmental changes affect the species.Location Map\u2013 Displays sightings of the species worldwide.,Users can add friends within the app.Species can be traded between friends to complete collections collaboratively.,A map interface shows real-time wildlife sightings and distribution data.Users can explore where specific species have been observed.,How It Works: Challenges We Faced: Accurate Species Recognition\u2013 Training the AI to improve classification accuracy for diverse species.Scalability\u2013 Ensuring seamless performance as more users join and contribute data.Data Privacy\u2013 Handling location data responsibly while maintaining user privacy.Encouraging Conservation\u2013 Finding ways to motivate users to donate and engage in wildlife protection efforts.,Conclusion: The Catchy! App bridges technology and environmental awareness, making wildlife discovery interactive and meaningful. With species identification, social trading, and conservation support, the app transforms nature exploration into a fun and educational journey.We hope The Catchy! App inspires people to connect with nature, appreciate biodiversity, and take action toward wildlife conservation!",
                        "github": "https://github.com/marybethsato/calgaryhacks",
                        "url": "https://devpost.com/software/catchy-ecorx1"
                    },
                    {
                        "title": "WildlifeDAO",
                        "description": "A decentralized AI governance platform that empowers donors to directly influence wildlife conservation funding.",
                        "story": "",
                        "github": "https://github.com/GodRishUniverse/WildlifeDAO",
                        "url": "https://devpost.com/software/wildlifedao"
                    },
                    {
                        "title": "Racing Game",
                        "description": "Using the prompt \"collaboration,\" we created a racing game in which the car is controlled using widgets. Two people work together to control the car: one controls speed, the other controls steering.",
                        "story": "Inspiration: We chose to go with a racing game as when we were brainstorming we found that a racing game was the most versatile idea we had since there were many ways we would be able to implement a collaboration component to the game. Additionally, the idea of a racing game also allowed us to easily implement a hardware component to the project as this was something we were keen on doing.What it does: The game we decided on creating is a racing game where two players collectively work on controlling a car. To control the vertical position of the car, a phidgets potentiometer slider is used, while to control the speed of the car the buttons on a phidgets controller are used, red to slow down the car and green to speed up the car. On the screen other cars are present as well, a collision between the user and these cars will result in the game ending.How we built it: We used Pygame in Python to code our project since Python was a programming language that all members of our team were familiar with. Additionally, since we were provided with phidgets hardware we decided to implement these into the controls of our game.Challenges we ran into: A major challenge that we ran into was the merging of two branches in Github. when merging two branches line indexation would not properly carry over resulting in syntax errors in our code.Accomplishments that we're proud of: Implementing the phidgets hardware into our projectCreating code that would spawn in lane markers and other carsBeing able to use Git and Github to collaborate well,What we learned: From this project, our group became more familiar and experienced with using Github and Git commands when collaborating with others on projects. Additionally, we became more familiar with pygame and also learned about how we would be able to implement hardware in future coding projects.What's next for Racing Game: We definitely have other ideas of what can be implemented in the game. For example, we would like to create a better scoring system in the game and possibly other different ways to control the car. We would also like to make the game more difficult for the user when they increase their speed, such as by increasing the size of the car and again reverting to the original size when the user chooses to slow down.To Access Project in GitHub repo: Go to src folder and run the main.py file as this is the finished project",
                        "github": "https://github.com/SamipyaRijal/Racing",
                        "url": "https://devpost.com/software/racing-game-mbcajr"
                    },
                    {
                        "title": "Serenity Quest",
                        "description": "Serenity Quest is a self-improvement RPG where players battle inner struggles and challenges. Upgrade skills, face the Deadly Sins, and build resilience-all in an immersive, AI-enhanced world.\r\n",
                        "story": "Inspiration: Our inspiration for Serenity Quest comes from the belief that a peaceful external world stems from inner harmony. By focusing on maintaining balance within oneself, the game aims to make players reflect on how inner peace can influence the world around them. This idea of harmony connects to both personal growth and societal impact, making the game an interactive journey towards understanding how small actions in daily life can foster a peaceful environment.What It Does: Serenity Quest guides players on two key journeys. The first is a User Upgrade Page where players can engage in personal growth activities\u2014like reading, going to the gym, or meditating. These activities affect their status bars, symbolizing inner peace, strength, and wisdom. The second main feature is the Battleground, where players face the seven deadly sins, each representing an internal or societal challenge to peace. By \"battling\" these personified vices, players learn the power of personal resilience and self-care in overcoming obstacles to achieve tranquility.How We Built It: We built Serenity Quest with:\nPython and Pygame for the core game mechanics and visual interface, allowing us to create animations, interactions, and battles in an accessible yet impactful 2D format.\nAWS for secure data storage, player progress tracking, and cloud infrastructure management, ensuring a reliable gaming experience.\nTerraform to automate our cloud infrastructure on AWS, making deployment and scaling seamless.\nChatGPT API to enhance the player\u2019s journey with interactive dialogues and tailored guidance on achieving peace, as well as providing insight into the impact of actions taken within the game.Challenges We Faced: The development journey wasn\u2019t without hurdles. For many of us, it was our first time building a game, and we had to learn both Pygame and Python. Implementing cloud infrastructure using AWS and automating it through Terraform introduced new technical challenges. Additionally, integrating ChatGPT to provide interactive, meaningful advice required experimenting with conversational AI for a gaming environment, ensuring that responses were helpful and on-topic.Accomplishments We\u2019re Proud Of: We\u2019re proud to have created a unique game that merges self-improvement with gameplay. The User Upgrade system is particularly rewarding, as it encourages players to reflect on their own habits. Our integration of real-time, cloud-based AWS infrastructure was another major success, ensuring player data is safely stored and easily accessible.What We Learned: Throughout this project, we learned not only new programming and cloud skills but also about the meaningful ways a game can influence players\u2019 perspectives on personal well-being. Understanding the balance between functionality and thoughtful design taught us to create experiences that resonate emotionally and philosophically with players.What\u2019s Next for Serenity Quest: We plan on implementing a multiplayer mode, where multiple players work together to beat the seven deadly sins. This will provide a platform enhances a feeling of belonging and unity among the future generation. We envision adding enhanced game dynamics with richer animations and audio that deepen player immersion. Better-defined interfaces on the upgrade and battleground pages will further illustrate the link between actions and outcomes. With additional AI integration, we plan to make Serenity Quest even more insightful and supportive for players on their journey to inner peace. With future ambitions to make it a coop game to increase accountability between peers.",
                        "github": "https://github.com/M-Rehan0/Eleventh-Hour",
                        "url": "https://devpost.com/software/eleventh-hour"
                    },
                    {
                        "title": "HandiGo",
                        "description": "An independent lifestyle is hard \u2013 managing finances, deadlines, job hunting and cooking are all things that we miss not having to worry about. HandiGo is your all-in-one solution to these problems!",
                        "story": "Inspiration: All of us have had to transition from a dependent lifestyle to an independent one first attending university. There were many aspects that could have made this transition easier, like being able to track finances and deadlines all in one place.What it does: This is a mega app that has many features related to our inspiration for the project. Firstly, HandiGo allows you to track your income, expenses, and savings, displaying it in a nice monthly pie chart to give the user a simple and straightforward way to track their finances. Staying organized with deadlines and appointments are also important to thrive in an independent lifestyle, which HandiGo allows you to do as well. You can add and remove tasks for a certain day which is viewable in a sleek interactive calendar.A sustainable independent lifestyle also requires the ability to cook. HandiGo fetches recipes from the internet, showing the user recipes from countries around the world. The user can favorite recipes which are saved for future use.Working a job and living independently form the foundation of an independent lifestyle. We make it easy for users to find jobs with a jobs tab, fetching the most recent job listings in Calgary. Additionally, the user can find houses for rent in Calgary in the renting tab, which personalizes the listings to the users monthly income entered in the finances tab.How we built it: -Python for front-end and back-end development with a variety of imports.\n-APIs to fetch real-time job postings, rental listings, and recipe suggestions.\n-Web Scraping to gather updated housing and job data.\n-GitHub for collaborative development and version control.Challenges we ran into: -Integrating multiple features into a seamless user experience was a challenge.\n-Trying to avoid merge conflicts with GitHub.\n-Fetching and organizing real-time data efficiently using APIs and web scraping required optimization.\n-The limitations of tkinter such as poor animation support and complicated workarounds for modern styling.Accomplishments that we're proud of: -Successfully integrating multiple functionalities into a single application with many views.\n-Implementing real-time data fetching through APIs and web scraping.\n-Learning and applying advanced Python libraries and improving our team collaboration skills.\n-Creating a sleek UI despite the limitations of tkinter.\n-Fixing many bugs within the 24 hour time period of the Hackathon.What we learned: -How to efficiently use APIs for data gathering.\n-Effective project management and team collaboration using GitHub.\n-Enhancing Python development skills to build full-stack applications.\n-The importance of user-centric design in developing a practical, everyday-use app.What's next for HandiGo: -Expand features by adding AI-powered financial insights and automated budgeting.\n-Improve data accuracy and expand job and rental listings.\n-Deploy the app for public use and gather user feedback for future updates!",
                        "github": "https://github.com/jacobbehnam/calgaryhacks2025",
                        "url": "https://devpost.com/software/handigo"
                    },
                    {
                        "title": "FreshStart Kitchen",
                        "description": "FreshStart Kitchen helps individuals transitioning to independence by offering local cooking classes that teach essential life skills and foster community connections for a self-sufficient future.",
                        "story": "Inspiration: Transitioning to independence can be overwhelming, especially when it comes to cooking. Many individuals struggle with meal preparation due to a lack of experience, resources, or structured learning opportunities. FreshStart Kitchen was created to bridge this gap by providing an easy way for users to find and book local cooking classes. Our goal is to help people develop essential cooking skills, promote self-sufficiency, and build a supportive community.What it does: FreshStart Kitchen is a web platform that connects individuals with local cooking classes, making it easier to learn essential life skills. The platform offers:Free Trials: Users can enroll in one free class to get started.Point-Based System: Users earn points by attending classes, leaving reviews, and engaging with the platform.Rewards System: Points can be redeemed for additional classes or purchased directly.Two Account Types: Regular users can find and book classes, while businesses can list and manage cooking sessions.Community Tab: Users can share their cooking experiences, post pictures, and interact with others.,How we built it: The platform was built using a modern, scalable tech stack:Frontend: React, Node.js, Tailwind CSS, and Shadcn UI for a responsive and interactive user interface.Backend: Spring Boot with MySQL for managing data and handling business logic.,Challenges we ran into: Integrating the booking system: Ensuring seamless class reservations while maintaining an intuitive user experience.Balancing user engagement and rewards: Designing a point-based system that encourages participation without being exploited.Ensuring accessibility: Making the platform user-friendly for individuals with varying levels of tech proficiency.,Accomplishments that we're proud of: Successfully built a functional and user-friendly platform from the ground up.Developed a reward system that incentivizes users to engage with classes.Created a smooth booking experience that allows users to reserve spots effortlessly.Designed a community-driven space where users can share their cooking experiences.,What we learned: User experience is key: A simple, intuitive interface encourages engagement.Backend scalability matters: Efficient data management ensures smooth performance.Community features enhance retention: Users are more likely to stay engaged when they can share their experiences.Iterating based on feedback: Gathering user insights early helped refine features and improve the platform.,What's next for FreshStart Kitchen: Authentication: JWT-based authentication for secure user login and session management.Payments: Stripe integration (if needed) to enable class purchases and transactions.Hosting & Deployment: Frontend deployed on Vercel, backend on AWS for scalability.Business onboarding: Encouraging local cooking instructors to list their classes and managing business-side interactions.Live Cooking Sessions: Introducing live cooking sessions for users who wish to join remote, interactive classes.Reward System Enhancements: Adding more reward-based incentives to keep users motivated and engaged, offering more diverse options for redeeming points.,",
                        "github": "https://github.com/goldentoto/CalHack25/tree/main",
                        "url": "https://devpost.com/software/freshstart-kitchen"
                    },
                    {
                        "title": "One Armed Crabs",
                        "description": "A short game about cooperation, puzzles, and crabs! All with one arm!",
                        "story": "",
                        "github": "",
                        "url": "https://devpost.com/software/one-armed-crabs"
                    },
                    {
                        "title": "zemlia",
                        "description": "explore. protect. preserve.",
                        "story": "Inspiration: Living nearby to one of the most beautiful places on earth - Banff National Park makes anyone realize the value of preserving wild life. People come from all over the world not even just all over Canada to appreciate the sheer beauty of the landscape, the wildlife, the terrain, and the outdoorsWhat it does: Zemlia is a platform that lets users explore, connect, learn, and protect by discovering wildlife, engaging in discussions, and accessing expert insights. Through AI-powered species recognition, interactive maps, and conservation partnerships, we empower people to track, share, and safeguard nature.How we built it: Lots and lots of Redbull. We spent hours brainstorming ideas, streamlining everyones incredible suggestions, and quantifying how much we are capable of achieving in only 24 hours. We then delegated roles to one another, and began to hack. We would check in every hour or so with one another to ensure everyone was feeling supported and on track. We'd bounce around asking for votes and opinions on every new feature we implemented, every design change we suggested, and every crash we inevitably caused.Challenges we ran into: git. holy goodness git. 5 people collaborating on one single thing at the same time even with an organized structure can get chaotic when on a time constraint.Accomplishments that we're proud of: Training our very own AI model (appropriately named Zemli) to characterize wildlife posts from users\nIncredibly flushed out UI and UX. With appropriate color pallete, icons, animations, transitions, all taken into account.\nMajority of our starting ideas we were able to implement into our final MVP\nDesigning a wonderful pitch deck and logo, and mockups to showcase our final productWhat we learned: the real zemlia was the friends we made along the way.",
                        "github": "",
                        "url": "https://devpost.com/software/zemlia"
                    },
                    {
                        "title": "Hack The Bomb",
                        "description": "Decode. Defuse. Survive.",
                        "story": "Inspiration: HackTheBomb was inspired by the high-stakes collaborative gameplay of games like \"Keep Talking and Nobody Explodes.\" We wanted to create an experience that tests not just individual problem-solving skills, but also communication and teamwork under pressure. The concept of having one player with the manual and another with the bomb creates an intense dynamic where clear communication becomes literally a matter of virtual life and death.What it does: HackTheBomb is a two-player collaborative puzzle game where players must work together to defuse a virtual bomb. The game features:Player 1 (Defuser): Interacts with a graphical bomb interface containing:Three colored wires (red, green, blue)A symbol keypad with four symbols (%, !, ;, &)A numerical code input systemA countdown timerA detonator buttonVisual feedback for all interactionsPlayer 2 (Expert): Has access to:A terminal-style interface with the bomb defusal manualDetailed instructions for each moduleQuick-message system for urgent communicationCustom message input for detailed instructionsModule-specific puzzle information,How we built it: The game was built using:Technologies:Python as the primary programming languagePygame for graphics and game mechanicsSocket programming for player communication using HamachiFile I/O for sharing puzzle informationComponents:main.py: Game launcher with player role selectiongame_state.py: Central game logic and puzzle generationplayer1.py: Defuser interface and bomb mechanicsplayer2.py: Expert interface and manual systemutility.py: Shared utility functions for file operationsGame Mechanics:Randomized puzzle generation for replayabilityReal-time network communication between playersMulti-module puzzle systemTimer-based gameplayState management for puzzle completion,Challenges we ran into: Networking Complexity: Implementing reliable real-time communication between the two players required careful handling of socket programming and data synchronization.State Management: Coordinating game state between two separate applications while maintaining consistency proved challenging, especially with multiple puzzle modules.User Interface Design: Creating an intuitive interface for both players that could convey complex information without overwhelming them required multiple iterations.Puzzle Generation: Developing a system that could generate random but solvable puzzles while maintaining game balance was particularly challenging.Error Handling: Implementing robust error handling for network disconnections, incorrect inputs, and various edge cases required significant testing and refinement.,Accomplishments that we're proud of: What we learned: Advanced Pygame development techniquesNetwork programming with sockets in PythonState management in multiplayer applicationsUser interface design principlesGame balance and puzzle designError handling in networked applicationsThe importance of clear communication in collaborative games,What's next for HackTheBomb: Built With: PythonPygameSocket ProgrammingHamachi/FortiClientVPNFile I/ORandom Number GenerationCaesar Cipher EncryptionEvent-Driven ProgrammingObject-Oriented Design,",
                        "github": "https://github.com/ShakH00/HackTheBomb",
                        "url": "https://devpost.com/software/hack-the-bomb-v4i20t"
                    },
                    {
                        "title": "WeSave",
                        "description": "Empower Your Wallet, Elevate Your Community.",
                        "story": "",
                        "github": "https://github.com/Charbel12323/WeSave_HackTheChange2025",
                        "url": "https://devpost.com/software/wesave"
                    },
                    {
                        "title": "WildBC",
                        "description": "Through our platform, we aim to raise awareness about the impact of climate change on British Columbia wildlife, offer educational resources, and facilitate community discussions.",
                        "story": "See website here:https://wilf-life-climate-change-crisis.vercel.app/Inspiration: We wanted to create a platform that empowers people to take action against wildlife endangerment in British Columbia. Our goal was to make it easier for users to stay informed, discuss issues, and actively contribute to conservation efforts.What it does: WildBC provides a discussion board, an animal endangerment and event tracker, a quiz system, and a curated list of awareness events. The platform is designed for easy access and engagement, ensuring that taking action is simple and intuitive.How we built it: Frontend: React, Next.js\nBackend: Node.jsChallenges we ran into: We faced difficulties with Git commands and had to quickly get familiar with React fundamentals. Overcoming these hurdles helped us strengthen our technical skills.Accomplishments that we're proud of: We built an interactive and user-friendly website with a wide range of functionalities that make it easy for users to stay informed and take action.What we learned: Along the way, we improved our knowledge of React, collaborative development with Git, and best practices for designing an intuitive user experience.What's next for WildBC: We plan to expand the platform with real-time data integration, enhanced discussion features, and partnerships with conservation organizations to maximize impact.",
                        "github": "https://github.com/vrajdudhat1624/WilfLife_ClimateChange_Crisis",
                        "url": "https://devpost.com/software/wildbc"
                    },
                    {
                        "title": "Save the Animals!",
                        "description": "A comfy and informative game where you save cute animals!",
                        "story": "Inspiration: With climate change rapidly affecting our planet, we wanted to create a game that spreads awareness about environmental issues in an engaging and interactive way. Many people, especially younger audiences, may not fully understand the consequences of pollution and habitat destruction. Save The Animals! aims to bridge that gap by turning education into an interactive experience where players actively participate in saving wildlife and reducing environmental harm.What it does: Save The Animals! is a video game where players take on the role of an environmental activist, working to rescue animals and stop pollution. The game simulates real-world environmental issues, allowing players to complete tasks such as cleaning up oil spills, reducing carbon emissions, and protecting endangered species. The player wins by successfully stopping pollution, while failure to take action results in reaching the point of no return.How we built it: We developed Save The Animals! using Python and Pygame, utilizing Pygame\u2019s 2D rendering capabilities to create an immersive experience. The game features:A dynamic environment that reflects the player's actionsAnimal rescue tasks, where players work to protect endangered speciesA win/lose condition, where the world can either be saved or reach irreversible damage,Challenges we ran into: Building a complete game within the hackathon timeframe came with its challenges, including:Optimizing Pygame performance for smooth animations and interactionsImplementing a pollution system that visually reflects environmental changesEnsuring the game effectively educates players while remaining engaging,Accomplishments that we're proud of: Successfully creating a game that spreads awareness about environmental issuesDeveloping a functional pollution system that visually shows the impact of player actionsCompleting a working prototype within the hackathon timeframe,What we learned: How to integrate real-world environmental concepts into game designOptimizing Pygame for performance and interactivityEffective teamwork and time management in a hackathon setting,What's next for Save The Animals!: Expanding the game with more interactive elements to enhance engagementImplementing AI-driven NPCs that react to the player\u2019s actionsPartnering with environmental organizations to integrate real-world data and solutions,We hope Save The Animals! will inspire players to take action and make a difference in the real world!",
                        "github": "https://github.com/Flaryiest/CalgaryHacks-2025",
                        "url": "https://devpost.com/software/calgary-hack"
                    },
                    {
                        "title": "EcoPal",
                        "description": "A gamified, animal adoption app to incentivize the protection of animals and raise awareness about climate change",
                        "story": "",
                        "github": "https://github.com/MohammadHashmi/EcoPal",
                        "url": "https://devpost.com/software/ecopal-3cnaq4"
                    },
                    {
                        "title": "NextChapter",
                        "description": "Finance Project",
                        "story": "",
                        "github": "https://github.com/fajxc/calgaryhacks",
                        "url": "https://devpost.com/software/nextchapter-oxte1k"
                    },
                    {
                        "title": "StockEd",
                        "description": "StockSim is a fun, competitive stock market simulation with real-time data, leaderboards, and challenges. Learn, trade, and compete with friends in a risk-free environment. Ready to invest? ",
                        "story": "Inspiration: The inspiration for StockEd came from the need to make financial literacy and stock market analysis more accessible. Many investors struggle to interpret market trends, and beginners often find traditional stock analysis tools overwhelming. We wanted to create a platform that simplifies stock education through interactive data visualization and AI-driven insights.What it does: StockEd is an intelligent stock simulation platform that helps users understand stock market trends through real-time data analysis and . It provides:Real-time stock price tracking with interactive graphsGame-like simulation with ongoing leaderboardUser-based account achievements based on an individual's portfolio,How we built it: We built StockEd using:Frontend: React, Tailwind CSS for an intuitive UI\nBackend: Python, Django for REST API Consumptions\nDatabase: SQLite\nAPIs: Integrated financial data APIs like Polygon for real-time stock prices and news aggregationChallenges we ran into: CORS Issues: Encountered restrictions when fetching stock market data but resolved them through server-side proxying.Data Visualization: Ensuring smooth rendering of large datasets in an interactive format without performance lag.,Accomplishments that we're proud of: Successfully implemented real-time financial data tracking with interactive visualizations.Implementing a fully fleshed-out backend server and completing integrations with a well polished frontend within a span of 24h.Starting with an ambitious idea and relentlessly improving our project and fixing bugs until the last minutes.,What we learned: We learned how to efficiently handle and visualize large financial datasets in a web application, as well as integrating a complex backend server structure to bring an entire project full circle. Another thing that was difficult in the beginning was coordinating our changes and keeping a steady level of communication to prevent merging over one another and creating numerous conflicts.What's next for StockEd: LLM Integration: Implementing predictive analytics to forecast potential market movements, and provide educational explanations based on real-time stock patterns.Stripe Integration to allow users to test the simulation with a fraction of real cash. This can between a cent to a dollar, and the simulation scales up their purchases to buy stocks in game. This gives a slight return-on-investment for learners to understand the gain and loss abstraction of trading.,",
                        "github": "https://github.com/maostar1010/stock-simulation",
                        "url": "https://devpost.com/software/stocked-e54cu1"
                    },
                    {
                        "title": "BreaktheEnigma",
                        "description": "I am interested in cybersecurity, knowledgeable in java, and a topic of collaboration. I made Break the Enigma. An educational game where you learn the basics of the Enigma Machine and its history.",
                        "story": "",
                        "github": "https://github.com/kevathin/BreaktheEnigma",
                        "url": "https://devpost.com/software/breaktheenigma"
                    },
                    {
                        "title": "Forsaken",
                        "description": "You got here due to your greed. ",
                        "story": "Inspiration: We wanted to make a rouge lite dungeon crawler, using inspiration from Hades, Noita and Project \nZomboid.What it does: The game is a wave survival game which uses a shared health bar between players to force cooperation between risky undertakings and casual plays.How we built it: We built it using Godot and other softwares such as libresprite, we also integrated an AWS EC2 server, through the use of AI, for a client-server multiplayer infrastructure.Challenges we ran into.: A major challenge we had was proper time management, leading to a full overall of the entire game at the 20 hour mark. We were far underprepared for creating a game within the Godot engine, so we fell back to a wave-survival game.Accomplishments that we're proud of: We were very proud of the art and style of pixel art we were able to achieve, we were also quite proud of the teamwork and cooperation we were able to foster. We were also felt quite proud of our ability to learn networking for games.What we learned: We learned to manage out time, figuring out a new coding language through the using the benefits of AI, in turn helping us to learn how to create 2D games and helping us create features closer to the very end. We also learned how to network for games. Finishing the Hackathon, we learned the importance of creating minimal viable products before creating large final versions, allowing for the refinement of specific mechanics within a game.What's next for Forsaken: We do not currently plan to continue development, however, if given more time we would have turned the game into a rogue lite (our original idea) using a weighted randomized loot system with procedurally generated rooms that would appear around the main room, allowing for randomized rooms such as trap and boss rooms. The game, with more time, would have been complete with 2 bosses, as well as puzzles, paired with the shared health allowing for a variety of strategies to be played.",
                        "github": "https://github.com/FlameCrown/Forsaken---CalgaryHacks",
                        "url": "https://devpost.com/software/forsaken"
                    },
                    {
                        "title": "Peerfect",
                        "description": "Moving out is exciting, but no one teaches you how to live independently. Peerfect connects people based on the skills they have and need, whether it\u2019s cooking, budgeting, or fixing a leaky sink.",
                        "story": "Inspiration: Moving out for the first time is exciting, but it also comes with some unexpected challenges. Many people lack essential life skills like cooking, budgeting, or basic home repairs like fixing a leaky sink - but someone else always has that knowledge. Instead of struggling alone or searching endlessly online, we wanted to create a peer-to-peer skill-sharing platform to help people navigate independence, together.What it does: Peerfect connects users based on the skills they have and the skills they need. UsersCreate a profile listing skills they can teach and ones they want to learn.Post and browse requests for help with specific life skills.Match with others who have relevant experience.Chat directly to exchange knowledge.\nBy fostering a community-driven approach, Peerfect makes it easy to get hands-on guidance and share what you know.,How we built it: We built Peerfect using:Next.js for the frontendSupabase for authentication and database managementTailwind CSS + Shadcn/UI for a clean and responsive interfaceReact hooks for state managementNix for an efficient development environment and cohesive CI,Challenges we ran into: Matching users effectively: Finding an intuitive way to match people based on their skills was tricky. We iterated on different approaches before settling on a structured taggingAuthentication setup: Integrating Supabase authentication while ensuring a smooth user experience took some tweaking.Balancing UI simplicity and functionality: We wanted to keep the interface clean while making it easy to navigate, especially for first-time users.,Accomplishments that we're proud: Fully functional matching system that lets users connect based on skill gaps.Seamless authentication flow with Supabase.Intuitive and responsive UI that makes Peerfect perfect to use (see what we did there).Building this monster in under 24 hours!,What we learned: How to effectively integrate Supabase authentication and manage real-time data.The importance of user experience in peer-to-peer platforms - users need a frictionless way to find and connect with others.How to optimize skill-matching logic to ensure relevant connections.,What's next for Peerfect: Better matching algorithms to improve skill recommendations.Reputation system to encourage participation and build trust.Expanding categories beyond basic life skills to cover more niche areas.Mobile-friendly optimizations for easier access.Potential integrations with learning resources or mentorship features.,",
                        "github": "",
                        "url": "https://devpost.com/software/peerfect"
                    },
                    {
                        "title": "GreenerMiles",
                        "description": "GreenerMiles makes exploring nature rewarding! Explore parks, complete activities, and earn points to grow a virtual plant. Every step connects you to nature and supports wildlife conservation.",
                        "story": "Inspiration: With climate change causing more forest fires, we wanted to create an engaging app to promote wildlife conservation. GreenerMiles encourages outdoor exploration through a point-based game system. By completing activities and growing their virtual plant, users may become more aware of nature and want to take action to protect wildlife and their habitats.What it does: GreenerMiles lists parks across Canada and suggests activities like hiking, birdwatching, and clean-up efforts. Users earn points by completing activities, which they can use to grow and nurture a virtual plant.How we built it: We used React Native to build the app and a database to store the park locations so that users can see them when searching for them.Challenges we ran into: Connecting the app with a Firebase database,Accomplishments that we're proud of: To have the plants show different phases as it is given more food and wilt over time as well.,What we learned: We learned how to design and develop a functional appWhat's next for GreenerMiles: Connect it to a database and implement a user sign-up/log-in page to store user information.,",
                        "github": "https://github.com/daadhaymour/calgary-hacks-2025",
                        "url": "https://devpost.com/software/greenermiles"
                    },
                    {
                        "title": "SoloSense",
                        "description": "SoloSense is your all-in-one personal management tool, designed to help you budget smarter, file taxes with confidence, and stay on top of life\u2019s essential tasks.",
                        "story": "Inspiration: When leaving home for the first time, so many people don't know what to prioritize, leaving them clueless on what to do and most often vulnerable. SoloSense helps lift some stress from those individuals by including a task tracker to maintain daily/weekly priorities, enabling the clients to budget effectively. Another way SoloSense makes the life of the user easier is by walking them through the rigorous process of filing your taxes by walking you through the entire process and simplifies each step.What it does: SoloSense represents the new coming of independence when moving out for the first time. It provides the tools and knowledge needed to manage finances, file taxes, and handle responsibilities effectively to help with the stress of moving out.How we built it: We used Svelte and JavaScript as the foundation for a fast, reactive user experience, and integrated it with HTML and CSS for a clean, user-friendly design.Challenges we ran into: Our first challenge came when we spent too much time trying to set up different UI libraries, only to find out none of them worked. Another struggle came from trying to connect Svelte to Firebase, due to the server-side rendered nature of Svelte. Throughout the hackathon, we found we spent too much time on small things so the final project was not all that we wanted.Accomplishments that we're proud of: In today's world, AI is commonly integrated into project development. However, we made it our mission to avoid using AI in our project, relying instead on basic coding skills. This demonstrates that, although AI integration is often used and can make our lives easier, it is not always necessary for every project.What we learned: Building this project without AI strengthened our fundamental coding skills in JavaScript, Svelte, HTML, and CSS. This experience reinforced the value of collaboration, clear documentation, and intuitive design, proving that AI is helpful but not essential for creating well-built applications.What's next for SoloSense: We plan to add many additional features, such as customizable budgeting tools and advanced tax resources, which will further improve functionality. We also plan on making this into a mobile app so users have more accessibility to the app. Future updates may incorporate data analytics to provide personalized financial insights while maintaining our focus on fundamental coding practices.",
                        "github": "https://github.com/untold-titan/calgaryhacks-budgetingapp",
                        "url": "https://devpost.com/software/solosense"
                    },
                    {
                        "title": "BombBlast",
                        "description": "BombBlast is a 3D cooperative rhythm game designed to promote collaboration between players. The goal is to diffuse a bomb by filling out secret codes, with each player controlling a set of keys.",
                        "story": "Inspiration: This project was inspired mainly by Helldivers II, which is a cooperative third-person shooter where players can summon weapons using arrow and keyboard commands similar to the ones used in this project. The environment and the bomb itself was inspired by \nTemple Run, a game we all still a great deal of nostalgia for.What it does: BombBlast is a game designed to promote a collaborative experience between players in real life, with the goal being to prevent a time bomb from exploding. Players can control different sections of the keyboard \"WASD\" and \"789\" to fill out secret codes presented on screen. If both players enter their codes correctly, they get an additional 5 seconds added onto the timer on the bomb. If one of them enters their code successfully but the other one does not, or neither of them do, nothing happens and the time continues to run out. If the time runs out, the bomb explodes and the players lose. The game also features haptic-like feedback where the codes bounce up and down when entered correctly, and various UI elements show the players that they are on the right track.How we built it: We built BombBlast using the Unity game engine and the C# programming language. Additional asset packs (3D models) were used to speed up development, which were acquired from the Unity Asset Store. All of the code, logic, and game was made by us.Challenges we ran into: This game was not our first idea. For the first 18 hours of this hackathon, we worked on a web app designed to help young adults become more independent, but we ran into so many issues during development that we decided to abandon that project and pursue this idea instead. Even with this idea, there were a lot of challenges that rose when developing the game loop, audio, and particle system.Accomplishments that we're proud of: By far the biggest accomplishment we are proud of is developing this game from start to finish between 3 AM and 9 AM, in only six hours. It took an incredible amount of effort to build this project, and an even greater amount of perseverance and discipline to stay focused.What we learned: We learned how to rapidly implement ideas into a fully functional video game in a matter of hours, working under great pressure and having a lot at stake.What's next for BombBlast: BombBlast will remain a hobby project for now, but we may develop it further in the future.",
                        "github": "https://github.com/alexshagadev/BombBlastRepo",
                        "url": "https://devpost.com/software/bombblast"
                    },
                    {
                        "title": "Reliance Hub",
                        "description": "Imagine you are alone as a new independent student and you need to know if there are disasters. Where do you go? Our app can assist you with locating resources that you need for your emergencies.",
                        "story": "",
                        "github": "https://github.com/MyLoverisTheMoon/CobaltCrushers",
                        "url": "https://devpost.com/software/reliance-hub"
                    }
                ],
                [
                    {
                        "title": "WealthWise",
                        "description": "Our platforms allow young adults to engage with their finances and learn how to become financially independent , without the risk of losing a lot of money or making big mistakes",
                        "story": "Inspiration: What inspired me was my own experience, where I had a hard time understanding how to properly invest and grow my money.What it does: It helps individuals be more financially savvy , without the required risks/dangers associated with itHow we built it: I built using node js and ,tailwind css and viteChallenges we ran into: I ran into a challenge of trying to get the app to completely deployAccomplishments that we're proud of: I was able to finish a website on my ownWhat we learned: I learned a lot about web development practices and issues.What's next for WealthWise: Completing the app fully , adding secure and reliable authentication as well as user Id- verification.",
                        "github": "",
                        "url": "https://devpost.com/software/wealthwise-yviagc"
                    },
                    {
                        "title": "MoneyNext",
                        "description": "Making Money Work for You",
                        "story": "MoneyNextis a tool that aims to target the financial independence and personal growth aspect of the prompt that was given to us in Calgary Hacks; by serving as amobile financial consultantwhich helps you make descisions based on your monthly expenditure.It not only helps a student track his/her expenses through our easy to use UI/UX, but it also budgets your expenses accordingly and presents forward tailored solutions based on their monthly spending in order to help money grow and work for you. It uses generative artificial intelligence to make personalized reccomendations to allieviate the financial  burdens of students.Inspiration: Many currentor future university students like ourselves and many others constantly struggle with their finances. Whats troubling is that we, and many others do not understand how to budget our earning properly and even if we do, we do not have the skills for it to grow.For such a tangible issue, we made a tool which not only helps you track your expenses and budget it efficiently: it also serves as your robo-business consultant tailored to meet your needs. Such a tool is very necessary in this day and age, so that students such as ourselves dont spend all of their savings on the new upcoming trends. But instead spend it wisely on the things that they actually need.Given the immaturity of our skills, we practically bootstrapped the entire project and learned each and every skill to wing the best we can.The frontend of the project is built on React, a Javascript library, It also uses Tailwind in order to make the website look aesthetically pleasing. Moreover, in order to produce solutions that are tailor-made for students, we use Gemini API in order produce generative AI responses within our website.Challenges we ran into: A prevalent challenge amongst our group members were the gaps in our collective knowledge, as well as the languages we were capable of coding in. For the majority of our group, this was their first hackathon, posessing little to no skills whatsoever.To add onto that, we were not able to execute the XGBoost model due to data problems intially, so had to think on our feet and eventually came up with a slighly modified version of our project. And we ended up spending the duration of 24 hours hustling in order to learn new frameworks such as React, along with some complex machine learning models, and working with APIs.Debugging and testing was one of the few challenges which created roadblocks for us. Moreover, putting all of the newly learned skills together into a pipeline which produces an end result was a challenging task as well. Despite these challenges, we managed to bootstrap an end product that we are proud of.Accomplishments that we're proud of: We are proud of the fact that we completed the project in time and that we were able to come to a consensus despite our knowledge disparities . We are also proud that we have inculcated completely new skills into our feathers. Teamwork and efficient communication skills with collaboration are some soft skills that we have picked up through this hackathon which will help us excel at a bigger stage.What we learned: Firstly, we have learned a lot about different Javascript libraries such as React, Node Js, Next Js, and Tailwind. On top of that we also learnt about different types of Machine learning Models such as XgBoost and CNNs.Secondly, we also picked up the essential skills of teamwork and communication, alongside collaboration and willpower; which propels to complete our goals. Through this hackathon, we have realized that it is very important to think on your feet and not let a roadblock stop you.What's next for MoneyNext: We aim to keep working with MoneyNext and make improvements to its UI/UX.Secondly we also aim to backtrack and successfully train our machine learning model based on XGBoost in order for it to read CSV files and make financial decisions based on that, which will not only make it more efficient but also more tailored towards the needs of the customer.Thirdly we aim to use AWS within the backend to make it more secure and then venture onto connecting banking information within the website.",
                        "github": "https://github.com/M-Valdy/CalgaryHacks-Project.git",
                        "url": "https://devpost.com/software/financial-advisor-znlkrp"
                    },
                    {
                        "title": "ACT & ABB",
                        "description": "In ACT & ABB a small creature that must work together with a ruined, abandoned supercomputer in a post-climate change apocalyptic world for both their mutual interests.",
                        "story": "Inspiration: The fragility of nature and of our constructed environment. Specifically on how we need to work collaboratively to face the challenges we are facing.What it does: In this game, two players take on the roles ofAbandoned Complex Temple * (ACT), and *A baby(ABB), to move through an abandoned computer system overrun by the natural elements.How we built it: We created this project using the Godot game engine, used procreate to create the art and Fruity Loops Studio for the OST.Challenges we ran into: Art direction and narrowing down a theme that we wanted to explore. Our music producer also never fully completed a project, but despite that, made all the sounds for every element of the game. Additionally, Git was unfamiliar as none of us use it very often and had to learn to use it during our time. Lasty, our two programmers found that using a newer beta version of the game engine we used was both a blessing, and curse in disguise, as it altered nodes that we once were confident in.Accomplishments that we're proud of: The physics for the tail was very frustrating but fulfilling once competed. It was also our artist, Nina's first time animating, which was a big accomplishment. We managed to implement everything we wanted, except for more levels. Most of the unique mechanics required techniques we hadn't used before so it was a slow process and we weren't sure we were gonna make it. However, what was most important to us was creating a shared vision including what we all wanted to see in this project.What we learned: The importance of teamwork and collaboration. Our artist learned how to properly format artwork for games after a few time consuming mistakes. Music guy learnt how to use a diminished seventh. And all of us increased our understanding of Godot systems, nodes, and scripts.What's next for ACT&ABB: We are going to add a few more levels and publish it on itch.io. Also, use it as an example for the Game Design and Development club because one of our members are apart of as marketing to reach out to more potential game devs, and invite more people to join next year.",
                        "github": "https://github.com/Daniel-M-C/CalgaryHacks2025",
                        "url": "https://devpost.com/software/act-abb"
                    },
                    {
                        "title": "Wolflings: Peril of the Pack",
                        "description": "A Lemmings clone where you must guide wolf pups through perilous environments caused by climate change and irresponsible human behaviour.",
                        "story": "Inspiration: As Calgarians, our group experienced warmer winters and frequent heat waves throughout the summer. Climate change hit us hardest especially during the summer, with forest fires and extreme heats that were previously foreign to us. \nIt made us realize how climate change could make winters a thing of the past, and we wanted to raise awareness about how climate change impacts not humans, but the wildlife that inhabit the woods.Through our game, Wolflings: peril of the pack, we aim to inform the players on actions to take in order to prevent the further destruction of the earth. You are not a wildlife conservationist, nor a big politician. But you still can make a change to make the earth a habitable place for humans and animals alike.What it does: You, as a wildlife conservationist, must help these wolf pups through their hazardous environment to get back to their den and reunite with their mother. As the wolf traverse through the terrain, drag and drop the tools onto the hazards to ensure the wolves can reach their den safely.How we built it: The game itself was built using the Godot Game Engine. All art was made by hand using Aesprite.Challenges we ran into: The main challenges we ran into were due to our lack of recent experience in game design. Several of us have designed games before, some even for previous hackathons, but it had been a while since we last made one. As well, the game engine we were using released a major version a few years ago which changed a lot of the syntax and methods we were used to.More significantly, none of us had ever worked in a group together before. So, we had to take a bit of time to learn about each other and figure out how best to approach the hackathon.Accomplishments that we're proud of: Eunsoul - I felt proud of the creation of the art within a short deadline. I got to play around with aesprite and learn how to animate through pixel art for the first time. I feel like through this experience I was able to gain new skills regarding design in pixel art, and I had a great time working with fellow students from Mount Royal University!Richard - I am proud that we\u2013a group of students who had never collaborated before\u2013were able to finish up a prototype of a game. Not only that, but the game has fairly nice hand-made assets. It is quite an accomplishment for a short amount of time.Abdullah - I\u2019m proud that we were able to work together as a team despite not having collaborated before. We struggled with branch conflicts but we didn\u2019t fight during the hackathonWhat we learned: Through CalHacks2025, we got to further develop our coding and design expertise.What's next for Wolflings: Peril of the Pack: After CalHacks2025, we look forward to further developing Wolflings: Peril of the Pack. Aspects we intend to focus on are aesthetic design, implementation of additional hazards and tools, whilst polishing current code.",
                        "github": "https://github.com/TechPowerAwaits/calgaryhacks-2025.git",
                        "url": "https://devpost.com/software/wolflings-peril-of-the-pack"
                    },
                    {
                        "title": "Words That Hurt",
                        "description": "Words can break relationships, but what can break words? Love and TeamWork\r\n\r\n",
                        "story": "",
                        "github": "https://github.com/bobforzolu/CalHacks-2025/tree/main/Assets/Assets",
                        "url": "https://devpost.com/software/words-that-hurt"
                    },
                    {
                        "title": "WildVision",
                        "description": "Empowering wildlife conservation through AI\u2014instantly identify animals from images and, in the future, provide extinction risk data to raise awareness about climate change\u2019s impact on biodiversity.",
                        "story": "",
                        "github": "https://github.com/adhillon192/CalgaryHacks2025",
                        "url": "https://devpost.com/software/wildvision"
                    },
                    {
                        "title": "Lorax - Acoustic Anti-Logging System",
                        "description": "Lorax leverages real-time audio monitoring and machine learning to detect illegal tree cutting and suspicious human activity, safeguard habitats, and protect our wilderness.\"",
                        "story": "Inspiration: Industrial-scale deforestation remains a pressing global issue, threatening the habitats of countless species and accelerating climate change. Inspired by Dr. Seuss's The Lorax, who spoke for the trees, our team set out to create a real-time acoustic detection system that could help identify illegal logging events in remote wilderness areas and empower local communities, environmental agencies, and conservationists to respond swiftly.What it does: Lorax - Acoustic Anti-Logging System constantly monitors ambient sound levels in a forest using a sound sensor. If noise surpasses a certain threshold\u2014potentially indicating chainsaws, heavy machinery or high levels of human activity\u2014the system automatically captures a brief audio clip, transforms it into a spectrogram, and runs it through a machine learning model trained to detect the distinctive audio signatures of illegal logging activities and other forest noises. Upon detection, Lorax triggers real-time notifications on our dashboard, providing both the suspected logging event label and the associated audio visualizations for quick verification.How we built it: We employed a Phidget sound sensor to monitor continuous SPL (Sound Pressure Level) data in real time. This sensor provides a rapid stream of decibel readings, allowing us to detect if the environment goes above our threshold for suspicious noise (e.g., 57\u202fdB). Upon reaching this threshold, a separate high-fidelity microphone is triggered to record a 5-second audio clip. We chose a sensitive microphone to capture detailed acoustic signatures, ensuring better accuracy when identifying specific sounds like chainsaws.Threshold Triggering: As soon as the SPL crosses the defined threshold, we automatically record a short audio clip via the microphone.\nSpectrogram Conversion: We use librosa to transform the raw audio data into a log-mel spectrogram, which is then visualized with matplotlib. This spectrogram provides a time-frequency representation crucial for training and inference with our CNN.We trained a convolutional neural network (CNN) on a labeled dataset of forest audio clips, featuring both benign sounds (wind, birds, rain) and illicit activities such as chainsaw noise. The CNN processes the spectrogram and outputs a probability distribution across possible classes. If the model assigns a high probability to \u201cchainsaw,\u201d the system flags the audio event as suspicious.To tie everything together, we built a Flask-based web app. The interface:Displays a live chart of SPL values from the Phidget sound sensor.Shows the current classification results (e.g., \u201cArea is CALM\u201d vs. \u201cSuspicious Activity Detected\u201d).Renders the most recent spectrogram images for visual inspection.Allows users to start/stop monitoring or observe the environment in real time from a browser, providing an interactive dashboard for quick verification and decision-making.,Challenges we ran into: Data Collection: Sourcing high-quality, real-world chainsaw audio samples alongside benign forest noises proved challenging. We had to carefully curate diverse training data for robust performance.Threshold Tuning: Determining the optimal dB threshold for \u201csuspected activity\u201d required iterative testing, so that we neither missed potential illegal events nor flooded the system with false positives.Remote & Real-Time Constraints: Designing a system that could operate reliably in remote areas, potentially with limited connectivity, called for efficient data processing and minimal reliance on external compute resources.Accomplishments that we're proud of: End-to-End Deployment: We integrated hardware, signal processing, machine learning, and a user-friendly interface into a cohesive system capable of automatically identifying suspicious logging sounds in real time.Accurate Classification: Despite data constraints, our model demonstrated a solid accuracy in detecting illegal chainsaw operations over various background forest sounds.Conservation Impact: Above all, we\u2019re proud to contribute a practical tool that can be leveraged by conservation groups and local authorities to protect forests and wildlife habitats.What we learned: Importance of Domain-Specific Data: Training an accurate model for chainsaw detection required carefully selected audio samples from real-world or closely simulated forest environments.Rapid Iteration & Testing: Integrating hardware with an AI-driven pipeline taught us the value of iterative testing\u2014especially threshold adjustments\u2014to refine detection accuracy.Real-Time System Design: Managing asynchronous streams (sound sensor vs. microphone vs. web dashboard) underscores the necessity of well-structured, event-driven architectures.What's next for Lorax - Acoustic Anti-Logging System: Edge Implementation: We aim to deploy the ML model on edge devices like Raspberry Pi, making Lorax even more self-sufficient in areas with unreliable internet.Extended Sound Library: Beyond chainsaws, we plan to classify other illicit activities (e.g., gunshots, vehicles in restricted areas) and track wildlife presence for broader conservation insights.Satellite/UAV Integration: Linking the acoustic alerts to drone or satellite-based imaging could offer visual confirmation of illegal activities, enhancing the system\u2019s reliability and response capabilities.",
                        "github": "https://github.com/muzman123/Calgary-Hacks-2025",
                        "url": "https://devpost.com/software/lorax-acoustic-anti-logging-system"
                    },
                    {
                        "title": "SafeHaven",
                        "description": "For many immigrant women, seeking help in abusive situations feels impossible due to language barriers, cultural isolation, and fear of legal repercussions. We are addressing this.",
                        "story": "Inspiration: Immigrant women facing domestic violence often struggle to access help due to language barriers, cultural isolation, and fear of legal repercussions. Traditional support systems fail to provide real-time, accessible, and culturally sensitive assistance. Inspired by real stories and research on domestic violence among immigrant communities, we built SafeHaven\u2014a platform that breaks these barriers and provides a safe space for women in need.What it does: SafeHaven is a mobile app designed to support immigrant women facing domestic violence by offering:\n\u2705 Live chat with real-time translation \u2013 Speak with trained advocates in any language.\n\u2705 Community support chats \u2013 Private, culturally sensitive groups for connection and healing.\n\u2705 Resource hub \u2013 Legal, financial, and shelter resources tailored to immigrants.\n\u2705 Discreet safety features \u2013 Quick-exit buttons, encrypted messaging, and hidden access modes to ensure privacy.How we built it: We used React Native for the front-end, ensuring a smooth and responsive mobile experience. Firebase powers our real-time chat, while Google Translate API enables seamless multilingual communication. We also integrated secure encryption to protect user data and ensure safety. We also used clerk for the low level authentication of our users, mongodb for our database management, AWS s3 for cloud storage of the data.Challenges we ran into: \ud83d\udd39 Implementing real-time translation while maintaining chat accuracy and security.\n\ud83d\udd39 Designing a discreet UI that protects users from potential harm.\n\ud83d\udd39 Ensuring our resource hub is comprehensive and trustworthy.\n\ud83d\udd39 Managing time effectively in a 24-hour hackathon while balancing innovation and functionality.Accomplishments that we're proud of: \ud83c\udfc6 Building a fully functional prototype in such a short timeframe.\n\ud83c\udfc6 Successfully integrating real-time translation for multilingual support.\n\ud83c\udfc6 Designing a safe, discreet, and user-friendly interface.\n\ud83c\udfc6 Creating something that can truly make a difference in people\u2019s lives.What we learned: \ud83d\udd39 The importance of user-centered design in sensitive applications.\n\ud83d\udd39 How to balance security and accessibility when working with vulnerable communities.\n\ud83d\udd39 The power of real-time communication and translation in breaking barriers.\n\ud83d\udd39 The significance of teamwork and adaptability in a high-pressure environment.What's next for SafeHaven: \ud83d\ude80 Expanding language support to include more dialects.\n\ud83d\ude80 Partnering with non-profits and advocacy groups for real-world impact.\n\ud83d\ude80 Adding AI-powered support bots for instant crisis guidance.\n\ud83d\ude80 Refining security features for even greater protection.\n\ud83d\ude80 Expanding the provided services to reach more users and handle different situations\n\ud83d\ude80 Including volunteer and advocacy options for contributing users\n\ud83d\ude80 Including functionality to enhance real life user privacy",
                        "github": "https://github.com/rohitNair21/CalgaryHacks",
                        "url": "https://devpost.com/software/safehaven-rz4536"
                    },
                    {
                        "title": "HomeRun",
                        "description": "HomeRun \u2013 Gamify Your Savings, Hit Your Home Run!\r\n\r\nA smart budgeting app that rounds up your leftover daily budget and helps you save for a home down payment\u2014one home run at a time. \ud83d\udcb0\u26be",
                        "story": "Inspiration\nWe took inspiration from the Forest app, which gamifies focus and productivity. Similarly, we wanted to make saving money feel rewarding and engaging. With the rising difficulty of buying a home, we designed HomeRun to help users save through a fun and interactive approach.What it does\nHomeRun sets a daily budget limit, and if you spend under it, the leftover amount is rounded up and saved automatically. Users can also contribute additional savings on the side. The goal is to \"hit a home run\" every week, and after a set number of home runs, they reach their down payment savings target.How we built it\nWe used Python FastAPI for the backend, Firebase as our database, and React for the frontend.Challenges we ran into\nOne of the biggest challenges was integrating the Plaid API to connect users' bank accounts. We also faced hurdles with setting up parts of the UI and implementing certain features due to time constraints.Accomplishments that we're proud of\nWe\u2019re proud of the all-nighter we pulled to bring this project to life. Despite the challenges, we managed to build a functional prototype in a short time.What we learned\nWe learned that you only improve with experience and that hackathons require a lot of preparation to maximize productivity. This was a fun and rewarding experience, but we took away many lessons for future projects.What's next for HomeRun\nWe believe this is a great idea with real potential. There\u2019s a possibility we will pursue it further and refine it into a fully developed product.",
                        "github": "https://github.com/WanderingWalnut/HomeRun/tree/main",
                        "url": "https://devpost.com/software/homerun-gyvw2h"
                    },
                    {
                        "title": "Dino and Duck Game: A Snow Duck Adventure",
                        "description": "Inspired by snow ducks and Rex, this game follows the characters as they play to their strengths, working together in a collaborative effort. The Duck and Dino team up on a quest to create Snow Dinos!",
                        "story": "Inspiration: I was inspired by the snow ducks around campus! Recently saw a fun video about rex, \"duck guy\" and the snow ducks and I thought it was a perfect fit when I saw the theme of collaboration and game.What it does: The game lets players control Duck and Dino as they work together to collect snow and create Snow Dinos! It\u2019s a fun, cooperative experience that highlights teamwork and strategy. Although rex starts of solo and a bit jealous, their teamwork makes gameplay much more fun and challenging! Right now it is designed for one player or multiplayer on the same computer.How I built it: I built it using godot. I have never made a full game before. I learnt from YouTube videos and godot documentation. I knew I didnt have time but I wanted to showcase how the levels would differ so I have very easy (one character), medium challenge with building snow ducks and lastly an enemy attack which is harder. I wanted to make my own assets but decided to use premade ones or modify them to save time.Challenges I ran into: I couldn't get the camera to work for a while only to realize I forgot to check a box. It did take a while to debug but it was a good learning experience. Also for a while I was also brainstorming to make sure the game was collaborative but also fun.Accomplishments that I'm proud of: I am really proud to have made a game and start a project that I would like to continue past the hackathon to make it better and more complete!What I learned: how to use godot / godot scriptgames programmingimproved my debugging skillsasset creationplanning a projecttime management,What's next for Dino and Duck Game: A Snow Duck Adventure: I would like to make cut scenes to engross players in the story more then textshooting snow ballsrapid fire rounds of building snow duckstimer, health, etc.more collaborative work opportunities (ex. levers, carts, doors, keys, etc)more abilitiesmore charactersoriginal artwork/musicmultiplayer mode,",
                        "github": "",
                        "url": "https://devpost.com/software/dino-and-duck-game-a-snow-duck-adventure"
                    },
                    {
                        "title": "Simple bridge game",
                        "description": "Work together to cross to the other side in the shortest amount of steps.",
                        "story": "Inspiration: co-op childhood games,What it does: encourages collaboration through teamwork,How we built it: lots of googling and self-teachingbottom up programming,Challenges we ran into: learning swing and creating GUI from 0 prior knowledgetime crunch (stayed up all night)debugging,Accomplishments that we're proud of: GUIlearning git on the fly,What we learned: swing, utilizing git with multiple people,What's next for Simple bridge game: fix some bugsadd real time movement (keybindings, keylistening, jnativehook, etc...),How to play: both players trying to get to the other side by placing islandstry to use as little islands as possible for the max scoredeliberate on the best course of action with your partner and choose whether to go for power upstake turns placing islands for your partner to cross,",
                        "github": "https://github.com/jinhao0716/calhacks2025",
                        "url": "https://devpost.com/software/simple-bridge-game"
                    },
                    {
                        "title": "Career Navigator",
                        "description": "Career Navigator is an AI-powered mock interview platform designed to help users improve their interview skills through interactive, real-time feedback. ",
                        "story": "\ud83d\ude80 Inspiration: In today's job market, finding the right career path and preparing for it can be overwhelming. We wanted to create an AI-driven platform that helps job seekers optimize their resumes, prepare for interviews, and identify skill gaps efficiently. By leveraging AI and NLP, we aim to make career planning more accessible and effective.\ud83c\udfaf What It Does: Career Navigator is a web-based tool that offers:AI Resume Optimization\ud83d\udcc4\u2728 - Upload your resume and job description to receive AI-enhanced suggestions.Mock Interviews with AI Feedback\ud83c\udfa4\ud83e\udd16 - Get real-time feedback on clarity, confidence, and structure.Skill Gap Analysis\ud83d\udcca\ud83d\udd0d - Identify missing keywords and areas for improvement based on job descriptions.Interactive UI\ud83d\udda5\ufe0f\ud83c\udf1f - A user-friendly interface that makes career development seamless.,\ud83d\udee0\ufe0f How We Built It: Frontend:HTML, CSS (Tailwind), JavaScript (GSAP for animations)Backend:Flask (Python), Google Gemini API, OpenAI's NLP modelsDatabase:NoSQL (Future implementation)AI Models:Spacy for NLP, SpeechRecognition for audio analysisTools:PyMuPDF (PDF processing), PyDub (audio handling), TfidfVectorizer (text similarity analysis),\ud83d\udea7 Challenges We Ran Into: Integrating AI-powered resume optimizationwas challenging due to parsing inconsistencies in different resume formats.Handling real-time speech analysisrequired optimizing our pipeline for clarity detection.Deploying and hostingthe Flask app while managing API key security.,\ud83c\udfc6 Accomplishments That We're Proud Of: Successfully implementing AI-powered resume analysis.Building a real-time mock interview system with speech analysis.Creating a clean and responsive user interface.,\ud83d\udcda What We Learned: How to integrateAI APIs (Google Gemini, Spacy, OpenAI)into a Flask application.The importance ofdata preprocessingfor NLP models.Best practices forfrontend and backend integrationin a full-stack AI project.,\ud83d\ude80 What's Next for Career Navigator: Job Matching System\ud83c\udfe2 - AI-based job recommendations based on user profiles.Personalized Career Roadmaps\ud83d\udcc5 - A tailored learning path for skill development.Live Video Mock Interviews\ud83c\udfa5 - AI-powered facial expression and body language analysis.Deployment\ud83d\ude80 - Hosting the application for public access.,",
                        "github": "https://github.com/divakargaba/Career-Navigator",
                        "url": "https://devpost.com/software/career-navigator"
                    },
                    {
                        "title": "Sustainability Game Draft",
                        "description": "Humans love simplicity. Inspired by our younger siblings and cousins, we transformed complex ideas about climate change into a game even kids can resonate with. Made with html, css and javascript.",
                        "story": "Inspiration:: Our younger siblings and cousins who love to play and learn from games understandable to them.What it does:: The game allows the user to experience how the economic and environmental intersection of the energy sector impacts our lives but visualized in a very simplified way, which could be understood by kids as well. The objective is to save the bear by purchasing a freeze ray, which was built in a factory that emits emissions. The user for simplicity, earns an income just by saving the bear, but also has to spend quite immediately to keep the polar bear safe. The game exits if the iceberg melts or if the factory emission targets reach capacity. Keeping the game in \"equilibrium\" is our gateway to allow users of any age to explore thinking of better ways we can keep the earth in economic and environmental equilibrium as well.How we built it:: We used html, css and javascript for the basic functioning of the game. We styled the web application to have a video game theme, drew some figures and pngs, and wrote javascript functions to implement counters for income/money spent, a button control on the freeze ray to reset the polar bear after being saved, and for some animations of the sun and carbon emissions.Challenges we ran into:: Html is mainly used for simple web design so our project is simplistic which is what we needed in terms of representation but the overall aesthetic could have been more advanced. In participation for the CalgaryHacks2025, we weren't able to complete our ai ideas in time, so we resorted to a quick way to demonstrate our overall idea.Accomplishments that we're proud of:: Being able to implement our idea, create a game and having our siblings play the game to prove whether or not it is kid-understandable.What we learned:: The irony behind the game. It reflects our everyday lives as the products we purchase to improve the environment, actually contribute to the environments worsening. The game is quite difficult to keep running for a long time since natural factors such as not having enough income to buy a freeze ray make it easy to lose. For development, we learned games involve recursion a lot.What's next for Sustainability Game Draft:: We intend to create an AI system that can transform complex case studies into kid-friendly stories, animations, and games.",
                        "github": "https://github.com/hewan-geb/Sustainability-Game-Draft-CalgaryHacks2025-",
                        "url": "https://devpost.com/software/sustainability-game-draft"
                    },
                    {
                        "title": "WildDex",
                        "description": "Spot a furry friend? Wildex lets you share with your community, raise awareness and help you connect with the ecosystem around you. Stay informed, stay engaged\u2014discover local wildlife like a game!",
                        "story": "Inspiration: Given the topic of wildlife conservation, we reflected on our own experiences of encountering wildlife out in nature. We wanted to capture the excitement of the moment so that it becomes a rewarding memory. Being aware of the difficult task of cataloguing and collecting data on wildlife, we wanted to create a fun app that allows users to record their encounters with wildlife while contributing to data collection.What it does: The app's experience is supposed to simulate the excitement of discovering Pokemon and indexing them, it is your personal \u201cWildDex\u201d to index the wildlife you encounter.The app's users will be able to record their encounters with wildlife using their smartphone\u2019s camera and save the location the sighting occurred at.The users will be able to crowdsource data on wildlife habits by tracking their encounters, which can then be useful for conservationists to seek patterns on how certain wildlife is affected by climate change and human actions.The wildlife will then be identified by an image classification model that uses machine learning.Animals that the user captures will be posted under their account and be available to view on a community feed.The user will receive special badges based on interaction on their posts in the community feed through upvotes.,How we built it: Secure user authentication with ClerkMobile application built with ReactPostgreSQL for the app database storageMachine Learning models trained with TensorFlowSupabase used as a bucket for image storage and retrievalGoogle Maps API integration for geo-taggingDocker for build containersAPI server created with Express,Challenges we ran into: Image classification becomes difficult when there are many classes to identify.Creating a neural network architecture to correctly classify images of animals took a lot of fine-tuning and research.Hosting the machine learning model in a server so that it can be used alongside a web interface.,Accomplishments that we're proud of: We have a very cohesive and easy-to-use interface that allows users to quickly snap a photo and geo-tag their capture.Integration with Google Map's API.Machine learning applications.,What we learned: Power of teamworkDiscovered integrating new technology, such as Google Maps API, and authentication with Clerk.,What's next for WildDex: We would like to create a way for authorized users to access the database of animal sightings for research.Expand animal classification capabilities to include more animals and geographical regions.,",
                        "github": "https://github.com/suxxmjz/calgary-hacks-2025",
                        "url": "https://devpost.com/software/wildex"
                    },
                    {
                        "title": "Cook N' Plot",
                        "description": "Cook meals, grow your virtual garden, and discover new recipes\u2014all in one app that turns cooking into a rewarding experience, helping you become more independent!",
                        "story": "Inspiration: Many students and young adults struggle with transitioning to independence, especially when it comes to managing food, budgeting, and meal planning. Cook N' Plot is designed to gamify this process\u2014making cooking and gardening engaging while teaching users valuable life skills. Inspired by cozy simulation games like Stardew Valley, our web app encourages users to grow their own food, track ingredients, and discover budget-friendly recipes, all while creating a fun and interactive way to become self-sufficient.What it does: Helps students and young adults learn basic cooking and gardening skills.Enables budget-friendly meal planning based on available ingredients.Introduces gamified elements (like interactive chickens and plants) that act as reminders of past meals\u2014helping users build sustainable habits.Encourages financial literacy by teaching users how to maximize ingredients and minimize waste.How we built it: Front-end: React with Vite, using Tailwind CSS for styling.Back-end: Node.js and Express with PostgreSQL for storing garden and recipe data from Kaggle, using SupaBase to host our data.State Management: React hooks to handle animations and interactivity.Animations & UI: Integrated sprite-based movement for interactive elements like the chicken and plant growth cycles.Challenges we ran into: Aligning interactive elements like plants with garden plots required precise CSS tuning.Managing real-time updates for ingredient tracking and garden progress.Integrating animations smoothly within the React component structure.Ensuring an intuitive user experience that balances fun game mechanics with practical cooking tools.Accomplishments that we're proud of: Successfully implemented interactive gardening mechanics.Designed an engaging UI with pixel-art aesthetics, keeping a fun and cozy feel.Created dynamic elements like the animated chicken and plant cycle.Built a functional ingredient-to-recipe system that personalizes recommendationCreating a working user base system with Supabase, where users can be created and logged in using sates.Working with a dataset of over 10000 rows.What we learned: Fine-tuning animations and layout in React to create an immersive experience.Managing a large-scale back-end with Supabase.Handling complex UI interactions while maintaining performance.Improving state management for tracking planted crops and ingredient availability.Balancing game-like elements with practical cooking tools.What's next for Cook N' Plot: Budgeting & Financial Planning:- We'd like to add a financial calculator that helps users track grocery spending.Nutritional Education - A of way of providing nutritional insights for each recipe.Community Support: Enable ingredient sharing and gardening tips among users.",
                        "github": "",
                        "url": "https://devpost.com/software/cook-n-plot"
                    }
                ]
            ]
        },
        {
            "title": "Deerhacks IV 2025",
            "location": "UTM",
            "url": "https://deerhacks-iv-2025.devpost.com/",
            "submission_dates": "Feb 15 - 16, 2025",
            "themes": [
                "Beginner Friendly",
                "Machine Learning/AI",
                "Web"
            ],
            "organization": "MCSS",
            "winners": false,
            "projects": [
                [
                    {
                        "title": "DiscoverDex",
                        "description": "Explore the natural world with DiscoverDex, your personal pokedex to capture the biodiversity of planet earth. ",
                        "story": "",
                        "github": "",
                        "url": "https://devpost.com/software/discoverdex"
                    },
                    {
                        "title": "DeeroGraphy",
                        "description": "Do you want to expand you knowledge of the world through daily games?",
                        "story": "Inspiration: We wanted to gamify the joy of discovery, making learning about the world an engaging and immersive experience. A word game is simple, universally accessible, and naturally encourages discovery of new things. Each puzzle is designed to be both fun and educational, introducing players to fascinating facts about different places. The challenges are tailored to specific regions, helping users connect with the culture, history, and languages of the world. As players progress, the puzzles become more difficult, keeping them engaged while expanding their knowledge of new places and traditions.What it does: DeeroGraphy is an interactive word puzzle game that takes players on a journey of discovery through daily challenges called \"Daily Quests.\" Each quest presents a word puzzle tied to the culture, history, or geography of a specific location. Players start in their chosen home region and gradually expand their reach by completing challenges, unlocking new cities, countries, and eventually entire continents. As they progress, they build a map of the world filled with the places they\u2019ve explored through gameplay. The ultimate goal? WORLD DOMINATION! (At least in terms of geographical knowledge.)How we built it: The user interface was crafted using JavaScript, React, Tailwind CSS, and HTML. We prioritized a sleek, user-friendly design that ensures accessibility while maintaining a fun and engaging experience for players. The game\u2019s backend runs on Python Flask and JSON are used to store and manage data so that user authentication, progress tracking, and AI-generated trivia are all handled efficiently. Each team member played a key role in bringing DeeroGraphy to life, Amber designed the logo and developed the main pages users see before and after logging in to track their progress. Khushi developed the Daily Quest system, integrating AI to generate tailored trivia questions. Ryan built the login system and handled backend logic, ensuring seamless user authentication and AI interactions.Challenges we ran into: It took us a long time to get setup. While we all held basic knowledge in Javascript, HTML and CSS, learning React to create the frontend proved to be a huge challenge.Accomplishments that we're proud of: Despite some frustrations with setup, getting the project to compile and figuring out how to setup multiple webpages with React provided a lot of excitement for the team!What we learned: Throughout this project, we strengthened our technical skills and gained experience in web development and AI Integration. We also strengthened our technical knowledge with the languages and frameworks used.What's next for DeeroGraphy: We hope to develop more types of \"Daily Quests\" for users to use, and add friending to see how your friends discover the world! We also want to add more encouraging factors like streaks, scores, and achievement levels that ignite the competition and push users to be their best.",
                        "github": "https://github.com/Khushi-Malik/deerography.git",
                        "url": "https://devpost.com/software/deerography"
                    },
                    {
                        "title": "Eterna",
                        "description": "Ever wondered what you were thinking last week or ate last month? \ud83e\udde0\ud83d\udd0d Eterna finds past thoughts, notes, and images instantly. Rediscover yourself and scale AI-driven memory search to industries! \ud83d\ude80",
                        "story": "Inspiration: We started with a simple question\u2014how often do we forget what we were thinking about last week, what we had for lunch a few days ago, or even what we were working on last month?As we joked about memory loss, we realized that AI is already helping people find information quickly, so why not use it to help peoplerediscover themselves?This year\u2019s hackathon theme isdiscovery, and Eterna fits in by:Discovering History\u2013 Searching and summarizing past experiences.Discovering the Internet\u2013 Using AI to retrieve insights beyond personal data.Discovering Yourself\u2013 Helping users track their thoughts, habits, and routines over time.,With this, we built Eterna\u2014anAI-powered search engine for personal memories.What it does: Eterna is designed to help usersstore and retrieve their memories\u2014whether that\u2019s photos, notes, or past thoughts\u2014quickly and intelligently.Image Memory Retrieval\u2013 Users can uploadphotos, allowing Eterna totag, sort, and retrieve them using AI.Smart Summarization\u2013 Lecture notes, journal entries, and documents can besummarized into concise, meaningful insights.Personal Timeline\u2013 Users canscroll through past events, thoughts, and saved datain a structured, chronological format.AI-Enhanced Search\u2013 Instead of just keyword searches,Eterna understands natural language queries, so users can ask things like\u201cWhat was I working on last Friday?\u201dand get relevant results.,How we built it: We followed aScrum workflow, managing tasks throughuser storiesand usingGitHub for version control.Frontend:React.js + Tailwind CSSBackend:Python (FastAPI) + Spring Boot (for API handling)AI Processing:Google Gemini API (for summarization, tagging, and retrieval),We split intofrontend and backend teams, working in parallel.Thefrontendfocused on UI/UX usingReact.js + Tailwind, making itresponsive and easy to navigate.Thebackendhandleddata processing, AI requests, and image storage.Once both parts were functional, weintegrated them and optimized performance.,Challenges we ran into: Tailwind CSS\u2013 Most of us had never used it before, so we had tolearn utility-based styling quickly.AI Image Processing\u2013 Figuring out how toconvert uploaded images into binary datafor AI analysis was more complex than expected.React Structure\u2013 Deciding onhow to organize the projectfor scalability took time.,Accomplishments that we're proud of: The UI turned out clean and functional, and everything isfully responsive.We successfully integrated AI APIsand made Eterna retrieve and summarize datain a meaningful way.We built a working MVPthat\u2019s actually useful and can be expanded further.,What we learned: How to build a full-stack AI applicationfrom the ground up.How to use APIs for AI-driven search and summarization.How to manage a project in a short time, balancing development speed with quality.How to structure a React.js project effectively.,What's next for Eterna?: Expanding AI capabilities\u2013 Improvingcontext-aware memory retrievaland addingvoice memo transcription.Scaling the development\u2013 Bringing in more engineers to improvefrontend UX and backend optimization.Industry Use Cases\u2013 Exploring how Eterna\u2019sAI-powered search enginecould be adapted for knowledge management ineducation, research, and businesses.Potential Startup\u2013 With additional features,Eterna could become a real product, offering premium AI-powered memory search.Database Upgrades\u2014 AWS DynamoDB (for scalable storage)Convenience and Security Upgrades\u2014 Cloud & Auth: Google OAuth (optional for user authentication),Eterna is just the beginning. The future ofAI-powered memory retrievalis possible, and this project is a step in that direction.",
                        "github": "https://github.com/Dawgsrlife/DeerHacks-IV-Project.git",
                        "url": "https://devpost.com/software/eterna-tzl81q"
                    },
                    {
                        "title": "RealPG: Real-Playing Game ",
                        "description": "The Real-Playing Game intends to get players outdoors, moving, and discovering by incentivizing them to take the path less traveled \u2014 literally. ",
                        "story": "Inspiration: Our Real-Playing Game was inspired by an annoyance we have here at UTM: despite most of us being enrolled for over a semester, it still feels like we do not fully know the campus. UTM has a strong argument for being the most beautiful of all the University of Toronto campuses, with modern buildings and incredible nature trails. However, this remains useless if we do not seek out new places and instead just follow our daily routine going between classes. We wanted to make this app to ensure we make the most of our short stint here at UTM. While our initial goal was to make the most out of our short time at UTM by getting to know the campus, we later realized that the Real-Playing Game could also help us explore other places, such as the other campuses or even Toronto as a whole.What it does: Our Real-Playing Game follows the player as they walk around and discover new things on campus. The app tracks where the player has already been and displays new, unadventured paths for them to check out. It also provides the player with suggestions on where to go, indicated by the markers with popular locations on campus with the goal of encouraging the player to go there, following a different route than they would have. In turn, the app calculates what percentage of the area explored, offering the user the ability to not only compete with themself to see as much as possible but also with friends using the leaderboard.How we built it: We built our game using several technologies, including React for front-end and Flask for back-end development. In addition, we chose to use Leaflet.js and MapTiler for our mapping system and Gemini for our confirmation that the player indeed actually visited the tasked locations. Our process of building involved first and foremost a lot of planning on what exactly we wanted to create, including what we wanted the user to experience before even creating our repository. This was followed by a significant amount of research into the documentation of the technologies we wanted to use which was unimaginally helpful in completing the project.Challenges we ran into: During our project, we ran into quite a few hurdles. For one, few of us had much experience with all of the tools we were using and as a result, we spent a lot of time learning instead of actually programming which would have helped by the end. In addition, we encountered many obstacles while working on the path calculation system since the MapTiler documentation was difficult to understand at times.Accomplishments that we're proud of: We are most proud of the mechanisms we implemented for the player to gain rewards. For one, there is the new area explored reward which we thought was innovative compared to many of the current offerings since our game actually encourages going somewhere new as opposed to the same place repeatedly. We are also proud of our verification of task completion system as it makes it harder for people to illegitimately gain rewards.What we learned: In the process of creating this project, we learned things both technical and not. One important thing we learned was how to better delegate work. Throughout the process, there were few times (asides from sleep!) that any of us were not working on the project or learning from an event at DeerHacks. On the technical side, we also learned about the way mapping tools deal with elements like roadways, something we did not understand nearly as well prior.What's next for RPG: Real-Playing Game: Something we all want to do to improve upon our app is include augmented reality (AR). We feel that by including this technology, it would dramatically improve the imersiveness of our game. AR would enable us to do this by enabling us to make the real life locations shown in the game not just feel like places on a map. We also want to extend it far beyond UTM. Our goal not only includes the other University of Toronto campuses, or even other universities, but cities and other areas of the world as well.",
                        "github": "https://github.com/freq1062/deerhacks-iv",
                        "url": "https://devpost.com/software/rpg-real-playing-game"
                    },
                    {
                        "title": "Logify: Mood Meets Music",
                        "description": "Bored with journaling? Logify's AI therapist analyses your mood, maps emotions on a dynamic calendar, and turns your thoughts into personalized soundtracks to truly discover yourself. ",
                        "story": "Inspiration \ud83d\udcad: According to studies, regular journaling can reduce stress by up to 28% and improve overall well-being. Yet, many people find traditional journaling tedious and uninspiring. That\u2019s why we reinvented it. With Logify, you get the perfect song at the perfect moment\u2014no more endless searching. Our app tracks your emotions with every entry and provides real-time mood ratings and feedback. Logify turns your diary into an engaging, interactive experience that not only boosts mindfulness but also propels personal growth.What it does \ud83d\udc40: Logify is a journaling app that connects with leverages OpenAI's API to analyze and quantify your mood score of that journal on a scale of 1 to 100 and provide real time personalized feedback. Based on your entry, the AI not only comments on your feelings but also recommends a song that captures your mood and plays it directly in your journal through the Spotify API. In addition, Logify tracks your mood evaluations daily and visually represents them on a dynamic calendar. Days when you\u2019re feeling down appear in red hues, while happier days glow in vibrant greens. With built-in streak tracking, Logify encourages you to journal every day by gamifying the experience, reinforcing positive habits and promoting self-reflection and personal growth.How we built it \ud83d\udca1: First, we designed our UI in Figma to map out the core pages and to create our HTML and CSS structure. After a working prototype and feedback from the mentors, we built the UI using HTML and CSS. We then implemented backend functionality with JavaScript starting with the entry webpages and implementing the OpenAI API to provide real-time, personalized feedback on your entries and score of the user's mood. We've then used the OpenAI API to parse through the message and suggest keywords, which we then fed into the Spotify API to recommend and play songs directly on the web app based on the user's mood. When the AI returns feedback, we store the numerical mood value along with the entry date in the browser\u2019s cache using Local storage. Later, we retrieve this data to dynamically color-code our calendar (red for lower moods and green for higher moods) and track journaling streaks.Challenges we ran into \ud83c\udf0b: Some challenges we encountered included coordinating multiple APIs. OpenAI for mood analysis and Spotify for song recommendations required asynchronous handling and error management. Ensuring that mood scores, dates, and attachments were stored and retrieved consistently from localStorage to drive our dynamic, color-coded calendar and streak tracking was another challenge. Plus, translating our Figma Designs into a responsive UI using HTML, CSS, and JavaScript solve unexpected caching issues with service workers.What we learned \ud83e\udd20: We learned how to integrate OpenAI and Spotify APIs to transform raw journal entries into real-time mood analysis and personalized music, dynamically visualized on a responsive calendar.What's next for Logify \ud83d\ude80: Our next steps include refining the core experience. We want to expand Logify by integrating physical health data, tracking more detailed mood analytics, and even correlating those insights with physiological metrics like heart rate. We\u2019re also exploring the idea of a personalized chatbot that remembers your journal entries and offers tailored suggestions. For now, our focus is on making the current product as useful and user-friendly as possible, with lots of room for growth down the line.",
                        "github": "https://github.com/takatoshilee/Logify.git",
                        "url": "https://devpost.com/software/logify"
                    },
                    {
                        "title": "GeoVenture",
                        "description": "Discover the tiny facets of our city that make it special,  enrich our community, and support local businesses!\r\n",
                        "story": "Inspiration: Our inspiration came from our desire to encourage people to engage with their local surroundings. Indecisive users can interact with GeoVenture to look for hidden gems and discover new spots, turning everyday exploration into a fun and rewarding experience. We wanted to create an engaging way for users to interact with their surroundings and discover new locations.What it does: This web app provides opportunities to discover new local businesses/entertainment/food. GeoVenture presents users with an image of a location within a set radius (1km, 5km, 10km) and challenges them to find it. Once they reach the spot, users would then earn points as a reward.GeoVenture Features:Provides real-time Google Maps directions to the mystery location.A leaderboard system to track top explorers and reward users for their activity.Review the history of all previously explored areas and save them as \"favourites\" whenever users want to revisit locations.Can filter specific categories such as entertainment, food, or cultural landmarks to adhere to user's interests.How we built it: GeoVenture is built using a combination of front-end and back-end technologies:Front-End: HTML and CSS for a responsive user interface.Back-End: JavaScript and Django (Python) handles user requests, processes location data, and interacts with the Google Maps API.Google Maps API: Used for retrieving location data, generating routes, and obtaining images of potential destinations.Challenges we ran into: Connecting the front and back end seamlessly took the longest time, and I had to figure out how to debug.Accomplishments that we're proud of: Successfully integrating Google Maps API to generate meaningful and engaging locations.Creating a user-friendly interface that encourages exploration in an interactive way.Implementing a leaderboard and points system to motivate players.What we learned: Figure out how to use Google Maps API for place search and navigation.What's next for GeoVenture: Add a Utility Mode for users who want to use the random location feature without the point system. This mode would also allow users to see reviews of locations and recommend them to others.",
                        "github": "https://github.com/Navam04/DeerHacks4Project",
                        "url": "https://devpost.com/software/geoventure-roh1sl"
                    },
                    {
                        "title": "TAMatch",
                        "description": "Your perfect TA is just a match away\u2014where learning styles meet teaching styles. Get personalized guidance, tailored support, and a study experience that fits you perfectly every step of the way!",
                        "story": "Inspiration: Education is a journey of discovery - new knowledge, new perspectives, and new ways of thinking. But one of the hardest parts of this journey is finding the right guide. Every student learns differently, and every TA teaches differently.\nTAMatch transforms thefrustrating search for a compatible TA into seamless discovery. Instead of guessing, students can instantly uncover the TA who best supports their learning. No more wasted time\u2014just the right match, right away. Learning should be about growth, andTAMatch helps students discover their ideal guide from the start.What it does: TAMatch is a smart matching platform thatconnects students with TAs based on learning and teaching styles.\ud83d\udd0d: Personalized quizzes: Students and TAs discover their learning and teaching styles.\ud83d\udcda: See TAs for Your Courses: View a list of TAs teaching the courses you're enrolled in.\u2728: Compatibility Scores: See each TA\u2019s compatibility score, which shows how well their teaching style aligns with your personal learning style.\u23f1\ufe0f: Save Time: No more attending multiple tutorials to find the right fit. Discover your ideal TA right away!\ud83c\udfaf: Efficient Learning: Focus on what matters most - your education - by connecting with the TA that can help you learn best.How we built it: Our project was built using React for the frontend and Node.js with Express for the backend. We used PostgreSQL as our database to store user preferences, quiz results, and potential matches.\nFor our frontend, we designed an interactive quiz using React Hooks (useState, useEffect) to collect user responses dynamically. The UI is styled with CSS to ensure a smooth user experience.\nAs for our backend, we used Node.js and Express to handle quiz submissions and TA-student matching logic. We used PostgreSQL to store user responses and TA preferences. The backend processes the quiz data and calculates the best TA matches for each student. The system compares learning styles and teaching preferences to generate a compatibility score and suggest the most suitable TAs.Challenges we ran into: 1) Connecting to PostgreSQL\nInitially, setting up and integrating the database was tricky due to authentication issues. We ran into role permission errors and had to manually create the correct database roles.\nUsing environment variables (.env) to securely store database credentials helped streamline the process.2) State Management in React\nManaging quiz progress and user authentication in a single-page React app required careful state management. Using useState and conditional rendering helped us handle different user flows efficiently.3) Quiz Logic and Data Processing\nStoring quiz responses, calculating percentage matches, and determining the best TA for each student required complex logic.We also optimized our matching algorithm to ensure accurate results based on user preferences.Accomplishments that we're proud of: It was pretty tough configuring some of the routing logic, as we were all relatively new to the languages and frameworks that we were using. But, that meant it was a great learning opportunity, and we got everything working in the end! Also, configuring the algorithm to match students to TAs was tricky, albeit fun, and a very rewarding experience to see it through to completion in the end.What we learned: A lot of new languages, frameworks, and debugging skills!What's next for TAMatch: Maybe getting UofT to use it.. :)",
                        "github": "",
                        "url": "https://devpost.com/software/tamatch"
                    },
                    {
                        "title": "Discover UofT",
                        "description": "Tired of missing out on campus events? Discover UofT is your one-stop shop for finding all the club events happening at UofT.",
                        "story": "Frustrated by the lack of a website where you can view all the club events happening at our campus, we wanted to create a solution. Thus we came up with Discover UofT, your one stop to find all club events happening at your campus. Now Finding your next event is just a click away.There are three main functionalities of Discover UofT:Visit the main page to find all the events happening soon. Get recommended events chosen specifically for you using complex algorithms that take in your preferences and your recently viewed club events. Want to see more events? Simply scroll down and use any filters or sorting you would like to find more events happening.Want to broaden your reach for your club or events to more students? Simply sign up through our website where you can access a simple posting platform that with the power of ai automatically tags your posts in order to reach the right audience. You also get your very own dashboard where you can monitor and delete any of your previous events postings.Don't want to change your current workflow for how you announce your events? We got you! Simply add our discord bot to your server in a simple 2 clicks, and you now have access to a whole new audience. Our discord bot auto detects any new events announced in your server and with the help of AI parses your text and posts it on Discover UofT without you having to do anything extra.Built with Next.js and TypeScript, this app uses modern React features, Tailwind CSS, Framer Motion for animations, and Lucide-react icons.  NextAuth handles authentication.  Key features include a dynamic Gallery carousel, Post component with social sharing, and asynchronous event data fetching with filtering/sorting/pagination. React Toastify handles errors, and the app uses a component-driven architecture.Integrated a NextJs backend with API calls to an MySQL backend. Used the openai api to tag each event from a pre-defined list of tags, and to choose the user's preferences using the questionnaire.Used the users preference alongside their recently viewed events to create weighted vectors. Then used those vectors to score each event and picked the top 5 events with some weighted randomness as to not always have the same suggestions. The similar events algorithm works in a similar way.(All you reyaan idk what to put at all)Our biggest problem was with pull requests. Sometimes we would be so focused on coding that we forget to push our code regularly which caused a lot of conflicts when it came to merge our branches, which cost us precious time.An accomplishment we are proud of is the fact that we were able to identify a problem within our community and we were able to build a viable solution to that problem within 36 hours. Not only were we able to solve this problem but we were also able to add on more features to make the experience of our users even better. \nAnother thing we are proud of is that we made sure that we did not rush through our code just to create something that \"works\". We wanted to make sure our product was scalable and robust and planned for the future when designing this project.One major thing we learnt is the importance of staying on top of your version control and git merges. If you just took a couple minutes every hour or two, you could save yourself hours of conflicts in the future. That is one lesson we definitely won't forget in the future.As discussed earlier when we designed this project, we had the future in mind. We hope to release Discover UofT as a real product and partner with clubs to increase their reach to more students. Additionally we are looking at the possibility of presenting this project to the University of Toronto to incorporate this as their official website for club events.\nAs to what features we hope to add to Discover Uoft, we have a couple in mind. One thing we want to add is an option to also post through multiple mediums such as discord, instagram and on our website through one click.",
                        "github": "https://github.com/corgi-in-tights/post-aggregators",
                        "url": "https://devpost.com/software/discover-utm"
                    },
                    {
                        "title": "Club-Connect",
                        "description": "Think of it as Tinder... but for discovering your perfect club match.\r\nSwipe, connect, and join your new favourite UofT community!",
                        "story": "Inspiration: The University of Toronto has nearly 1,500 clubs, making it overwhelming for students to find ones that align with their interests. With so many options, students often miss out on clubs that could enhance their university experience. Our goal was to simplify this process by leveraging AI to categorize clubs and implementing a Tinder-like swiping system for easy discovery.What it does: Club-Connect helps UofT students discover clubs that match their interests. Users create an account, select their initial preferences, and then swipe left or right on clubs to indicate interest. The app utilizes AI to categorize clubs and a matchmaking algorithm that refines recommendations based on user interactions, ensuring personalized suggestions over time.How we built it: Frontend:Built using React and TailwindCSS for a responsive and visually appealing UI.Backend:Developed with Flask, handling authentication, recommendations, and AI integration.Database:SQLAlchemy for managing user accounts and preferences.Data Collection:We webscraped UofT\u2019s club directory to gather club names, descriptions, and other details.AI Categorization:Used OpenAI\u2019s API to automatically categorize clubs into different interest groups.Matchmaking Algorithm:Analyzes user preferences and previous swipes to refine recommendations, ensuring better matches over time.,Challenges we ran into: Data Processing:Extracting relevant information from UofT\u2019s club directory was complex due to inconsistencies in formatting.AI Categorization:Ensuring that clubs were categorized correctly required fine-tuning prompts and handling edge cases.Matchmaking Logic:Balancing personalization while maintaining diversity in recommendations.Authentication & Storage:Implementing a secure and scalable user authentication system with SQLAlchemy.,Accomplishments that we're proud of: Successfully webscraped and processed data from UofT\u2019s club directory.Integrated AI to categorize clubs, making the discovery process more intuitive.Designed a seamless Tinder-like swiping system for club matching.Built a matchmaking algorithm that continuously improves recommendations based on user interactions.Developed a fully functional and visually appealing app within the hackathon timeframe.,What we learned: Improved our skills in web scraping and handling large datasets.Gained experience with AI integration for categorization and personalization.Learned how to balance user preferences with discovery in a recommendation system.Strengthened our ability to build full-stack applications efficiently.,What's next for Club-Connect: More Detailed Club Profiles:Adding club meeting times, social media links, and contact details.Event Integration:Allowing clubs to post upcoming events that match user interests.Enhanced AI Matching:Further refining the matchmaking algorithm with more user data and feedback.Mobile App Development:Expanding the platform to mobile for a better user experience.Social Features:Enabling users to see mutual interests and connect with club members directly.,",
                        "github": "https://github.com/juan-josue/club-connect",
                        "url": "https://devpost.com/software/club-connect-8x9bsg"
                    },
                    {
                        "title": "Geminaut",
                        "description": "The browser that can uncover hidden sites using the GEMINI protocol. Search for those amazing sites blogs or personal sites. The indie web is full of precious gems waiting to be uncovered...",
                        "story": "Inspiration:: The web is a truly wonderful thing, connecting the world together while surrounding us everywhere we go. Despite this, there are hidden 'gems' of websites on the web that are not normally accessible through standard browsers... Specifically, small and niche websites hosted on the Gemini(not Google's AI LLM)protocol are not normally accessible via https browsers, yet may contain very unique and valuable information from indie devs across the world. The current means of accessing Gemini protocol websites is very lackluster with immensely poor structure and usability, so with our goal to promotediscovery, we sought out to build a solution.What it does: Geminaut is a browser application that provides better accessibility, navigation, performance, UI/UX for viewing the web via the Gemini protocol, while also promoting discovery for new small and niche webpages (such as blogs).How we built it: The backend is powered by Golang, acting as an HTTP server that handles Gemini URLs, parses Gemtext, and returns a clean JSON DOM representation. For the frontend, we used Next.js with server-side generation, ensuring blazing-fast performance. We wrapped the app with Electron, allowing it to run seamlessly as a desktop application, and styled it with Shadcn, giving the interface a sleek, responsive feel. The result is a fast, efficient, and visually polished browsing experience for the Gemini space.Challenges we ran into: We experienced numerous challenges in the attempt to build a browser from the ground up. The largest challenge was the lack of initial knowledge related to niche web protocols. Some of the minor inconveniences we ran in to were bugs related to nextron (electron) rendering two separate instances of our browser instead of one.Accomplishments that we're proud of: As a team, we are immensely proud of building a sophisticated backend and browser application that handles niche web protocols.What we learned: We learned a great deal about how different web protocols work, how we can build a browser from the ground up, and how we can generally improve user experience on the web.What's next for Geminaut: We would be excited to make Geminaut open-source for the future, and promote accessibility/awareness about niche protocol webpages.",
                        "github": "https://github.com/krishpdev/Deerhacks-IV",
                        "url": "https://devpost.com/software/gem-browse"
                    },
                    {
                        "title": "SomnoScope",
                        "description": "SomnoScope is a hackathon project using NLP and brain mapping to explore dreams, uncovering patterns in neural activity. Join us in exploring the mind of ourselves!\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
                        "story": "\ud83d\udcad InspirationSomnoScope was inspired by the idea of bridging the gap between science and self-discovery through the analysis of dreams. We wanted to explore how technology, specifically NLP and brain mapping, can provide users with insights into their subconscious. The addition of AI-generated dream imagery enhances this self-discovery process, creating a more immersive and personal experience for the user.\ud83d\udcbb What it doesSomnoScope analyzes dreams submitted by users, extracting key themes, emotions, and sentiments through NLP techniques. It then correlates those themes with different regions of the brain, visualizing this data on an interactive brain map. The optional AI image generation feature creates visual representations of the dream based on the analysis, offering a creative interpretation of the user's subconscious thoughts.\ud83d\udd27 How we built itWe used Django as the back-end framework to manage user data, views, and interactions. On the front-end, we utilized Python, HTML, and CSS to build a clean and intuitive interface for users to interact with the system. We also integrated brain mapping Public API to visualize how different emotions and themes are linked to brain regions. Using Databases, we stored the data of past users into the Database to show the summation of everyone's dreams and our analysis of their dreams. Finally, we incorporated AI-generated prompts and images using Groq, Hugging Face and Python Regular Expression Model to further enhance our application of SomnoScope.\u2699\ufe0f Challenges we ran intoOne of the biggest challenges was integrating the different components, especially aligning the dream analysis with the brain mapping visualization. There were also technical challenges in ensuring the front-end was responsive and interactive while still handling complex data from the back-end. Additionally, ensuring the AI-generated imagery was relevant to the dreams was tricky, as it required careful text prompting.\u2b50\ufe0f Accomplishments that we're proud ofWe're proud of how the dream analysis pipeline came together, with the NLP components accurately identifying keywords and emotions from the text. The interactive brain map visualization exceeded our expectations, providing users with a visually appealing and insightful way to explore their dreams. We're also proud of successfully integrating the AI-generated images into the user experience, adding a creative layer to the dream interpretation process. We are most proud of the SomnoScope project, as we feel it is a unique, creative and innovative project in contribution to Deerhacks.\ud83e\udde0 What we learnedWe learned a great deal about integrating multiple technologies, especially how NLP can be used to extract and interpret complex psychological data. We also gained experience working with Django's flexible back-end and learned the nuances of creating responsive, interactive front-end visualizations. Finally, the project gave us the skills to integrate with AI while using python, leading to a overall excellent composition of data.\u2764\ufe0f What's next for SomnoScopeIn the future, we'd like to refine the dream analysis pipeline, adding more sophisticated machine learning models for deeper insights. We're also interested in expanding the brain map visualization to be more interactive and detailed, potentially incorporating 3D elements. Additionally, adding features like user accounts for tracking dream history, as well as expanding the AI imagery to more personalized dream visuals, could be exciting directions to explore.",
                        "github": "https://github.com/Deva-101/deerhacks2025",
                        "url": "https://devpost.com/software/somnoscope"
                    },
                    {
                        "title": "JourneyMatch",
                        "description": "Google maps meets Tinder! An exploration app that promotes discovery of new places based on what YOU like!",
                        "story": "Inspiration: Given the theme of \"discovery\" we wanted to make an app with a focus on discovering new places to visit based on what the user finds interesting.What it does: We used a Tinder-like system where a user can swipe left or right on photos of different destinations, or \"journeys\" to express their interest or disinterest for any given destination. Based on the users likes and dislikes, more or less destinations of a specific type (ie. similar location or attraction type) will be suggested to the user. A user can view the destinations that they have \"liked\" by visiting their profile tab and clicking/tapping on the photo of the destination which will open its location in Google maps. Users may also upload their own photos and tag them with data such as the location where the photo was taken using the Google Places API for other users to see.How we built it: We built the front end using react native with Typescript, which allows for JourneyMatch to have both mobile and web views. The backend was built using Django for its support of SQLite which we intended to use to store user data and the set of user uploaded photos. Additionally, we also used the Google Places API to allow users to search and select specific locations to tag their photos with.Challenges we ran into: Our two biggest challenges were implementing the Google places API and linking the backend of the app to the front end. For a lot of us, this was our first fullstack project and there were quite a few gaps in our knowledge leading to several features we had planned but ultimately never completed. These include features such as SQLite database integration to read and write data.Accomplishments that we're proud of: We are really proud of how we managed to implement the Google places API after hours of trial and error. Additonally, we are really happy with how the card element on the home view UI turned out since it is the central part of our app.What we learned: JourneyMatch taught us a lot about fullstack development and the diverse skillset required to deliver a product from start to finish. It also forced us to get comfortable with a handful of unfamiliar frameworks and languages (Typescript) which are commonly used in industry.What's next for JourneyMatch: If we have the time, we may revisit JourneyMatch to finish implementing all the unfinished features.",
                        "github": "https://github.com/arnavnagzirkar/JourneyMatch",
                        "url": "https://devpost.com/software/journeymatch"
                    },
                    {
                        "title": "MediScan",
                        "description": "Stop overpaying for medicine! Scan any over-the-counter drug\u2019s barcode, and our app finds a cheaper generic alternative\u2014same ingredients, lower price!",
                        "story": "Inspiration: The rising cost of over-the-counter (OTC) medications often makes it difficult for people to access affordable healthcare. We wanted to create a simple, effective solution to help consumers find cheaper alternatives without compromising on quality. Our idea was inspired by price comparison apps and the need for greater transparency in drug pricing.What We Learned: Throughout this project, we gained valuable insights into:Barcode Scanning Technology\u2013 Implementing fast and accurate barcode recognition.Drug Databases & APIs\u2013 Understanding how to retrieve and compare medication data.User-Centered Design\u2013 Creating an intuitive interface for seamless user experience.Cost Savings & Healthcare Access\u2013 Recognizing the impact of affordability on public health.,How We Built It: We developed our project using:Tech Stack:Python (Flask) / JavaScript (Lambda) for the frontend and backend.Barcode Scanner:Integrated with open-source libraries for quick scanning.Medicine Database:Utilized APIs to fetch brand-name and generic drug equivalents.,Challenges We Faced: Database Accuracy:Finding a reliable and comprehensive OTC medicine database.Barcode Recognition:Ensuring accurate scanning across different packaging.User Experience:Making the process smooth and accessible for all users.,Despite these challenges, we successfully built a tool that empowers consumers to make smarter, more affordable choices for their healthcare.",
                        "github": "https://github.com/FalconXYX/DeerHacks2025",
                        "url": "https://devpost.com/software/mediscan-vqrbnx"
                    },
                    {
                        "title": "Smart Compass",
                        "description": " Explore with a custom walking plan based on your interests in any city around the world. Discover landmarks along the way with real-time detection and brief summaries to enrich your journey.",
                        "story": "Inspiration: Learn and discover new cities.What it does: It uses location data to give the user a guide on local activities based on desired preferences.How we built it: We built it using Android Studio and Java. We also took advantage of Google Cloud and ChatGPT API'sChallenges we ran into: Ensure that API calls are properly integrated into our code so that they display and run properly. Connecting the information between multiple classes that were both running.Accomplishments that we're proud of: Overcoming many errors revolving around API's. Working together as a team to complete different areas of the project to complete objectives efficiently.What we learned: We learned how to create a mobile app using Android Studio and how to leverage multiple API calls dynamically.What's next for Smart Compass: Allow users to create an account and share their location guide with others. Creating a more efficient algorithm to plan out a trip as well as adding more preference and route options.",
                        "github": "",
                        "url": "https://devpost.com/software/smart-compass"
                    },
                    {
                        "title": "Deervolution",
                        "description": "Turn your everyday surroundings into a wildlife adventure. Explore nature with Deervolution. ",
                        "story": "Inspiration: With UTM being a commuter-heavy campus, many students tend to stay indoors or speedwalk through familiar paths. Recognizing students' love for the deer that roam the campus, we wanted to create an engaging way to encourage exploration of everyday surroundings (campus-related or not) and appreciation of nature. By gamifying wildlife photography, Deervolution fosters a deeper connection with the environment while subtly raising awareness of climate change and conservation efforts. But wait, there's more \u2014 the game creates an opportunity for students to bond over friendly competition, making campus exploration a shared and exciting experienceWhat it does: Deervolution is a mobile-friendly web app that motivates students to explore their surroundings through a Pok\u00e9mon-style game. Users earn points by capturing photos of animals they encounter while walking. The app includes:Secure sign-up and log-in to track user progressIn-app map to display the user\u2019s locationReal-time animal icons on the map that appear when users (yourself or others) submit an animal picture, incentivizing others to walk to that location (icons despawn after about an hour)Image upload and recognition to verify animals in submitted photosAnimal tracking system that logs captured species and assigns point valuesLeaderboard ranking to display top users based on points earnedPersonal profile tracking and displaying the number of each animal type captured,How we built it: Frontend:Typescript, CSS, Figma, Vite, React, Google Maps API \nThe frontend was built with React + Vite, and the usual HTML components with our own CSS styling. We used TypeScript to ensure that types are declared for all variables and objects, ensuring reliability of our code. We mocked up designs of the app first in Figma, then used this as a guide to designing the app in code.Backend:Node.js, Express.js, PostgreSQL, Typescript, Python\nThe backend is a Node.js server using the Express framework. We used Python to interact with our pretrained image classification model. Tying everything together is a PostgreSQL database that stores user authentication and information essential to running the app.Challenges we ran into: Integrating the database was difficult, as we needed to determine a balanced level of efficient table relationships and indexingUnexpected errors and bugs arose when deploying the web app, requiring heavy troubleshooting and debugging,Accomplishments that we're proud of: Deployed a working prototype of the mobile-friendly web appImplemented a secure database system that manages user authentication, stores submitted pictures, and tracks user progress,What we learned: How to use SQL and Supabase to securely manage user authentication and track submissionsHow to train an existing image recognition model for specific animals,What's next for Deervolution: Develop a mobile app version for a more seamless user experienceIntroduce a competitive game mode, allowing users to challenge each other to capture the most animals within a set time,",
                        "github": "https://github.com/emily-su-dev/Deervolution",
                        "url": "https://devpost.com/software/deervolution"
                    },
                    {
                        "title": "DiscoverMe - Discover the World through You",
                        "description": "DiscoverMe is an AI-powered travel discovery platform that matches you with global destinations based on who you are. Take a short quiz and explore places that truly resonate with you!",
                        "story": "Inspiration: What inspired us to create DiscoverMe was our passion for both technology and travel. However, we have differing personalities and we have our own ideas of where we want to visit in the future. What fascinated us is how our personal experiences shaped our perceptions of the world, and how our personalities cause us to gravitate to certain types of places. This sparked up a conversation how we could connect personalities with discovering niche places in the world, which brought up the idea of using personality tests. While personality tests are widely used for career guidance and self-improvement, we wondered... what if they could alsohelp people discover places that truly resonate with them?With advancements in AI and APIs like Google Street View, we saw an opportunity to create an interactive and personalized way for users to explore the world. The goal was simple: take a personality quiz, and based on the results, get matched with global destinations tailored to your traits, and learn a little about the place to see if it fits your vibe.What it does: DiscoverMe is an AI-powered web app that helps users explore global destinations based on their personality. Users take a short quiz, and AI generates personalized travel recommendations, displaying them through Google Street View for an immersive experience. The platform also provides cultural insights, events and food tips tailored to each recommended location.How we built it: The project was built using the following technologies:Front End: React - through NextJSBack End: JavaScript - through NextJSAI Integration: OpenAI\u2019s API to generate personalized travel recommendations.Map & Street View: Google Maps and Street View API to provide an interactive exploration of suggested destinations.Deployment: VercelChallenges we ran into: Every project comes with its challenges, and DiscoverMe was no exception:Tuning AI Recommendations: Ensuring that OpenAI\u2019s responses were relevant and personalized required careful prompt engineering and iteration.API Rate Limits: Both OpenAI and Google APIs had usage limits, so we had to optimize calls to stay within quotas while maintaining performance.Balancing Personalization and Generalization: Making sure that the recommendations felt unique to each user without being overly biased was a tricky balance to achieve.UI/UX Design: Presenting travel suggestions in an engaging and intuitive way was another hurdle. We iterated on different layouts to create a seamless experience.Accomplishments that we're proud of: Successfully integrating OpenAI and Google Street View APIs to create an engaging and interactive experience.Building a smooth and user-friendly interface that makes discovering new destinations enjoyable.Creating a scalable system that can be expanded with more features in the future.Delivering personalized recommendations that resonate with users.What we learned: Building DiscoverMe reinforced our skills in API integration, prompt engineering, and frontend-backend coordination.Some key takeaways from the project include:Working with OpenAI\u2019s API \u2013 Learning how to generate meaningful and personalized location recommendations through well-structured prompts.Optimizing API Usage \u2013 Managing rate limits effectively while maintaining performance.User Experience Matters \u2013 Designing an intuitive UI significantly enhances user engagement.What's next for DiscoverMe: Moving forward, we plan to:Enhance AI Personalization \u2013 Improve recommendation accuracy with more refined personality analysis.Add More Travel Data \u2013 Integrate real-time travel information, weather, and local events.User Feedback Mechanism \u2013 Allow users to rate and refine their recommendations.Expand Social Features \u2013 Enable users to share their results and compare destinations with friends.We\u2019re excited to continue refining DiscoverMe and making travel exploration more personalized and engaging!",
                        "github": "",
                        "url": "https://devpost.com/software/personality-places"
                    },
                    {
                        "title": "SkillSwap",
                        "description": "Learning isn't about watching videos and buying courses, it's about connecting with the right people with the right experiences. A skill-for-skill exchange that makes learning personal and rewarding.",
                        "story": "Inspiration: We wanted to create a platform where learning is built on human connection, rather than a transactional exchange. Traditional learning platforms either require money or put one person in a mentor role, but we believe everyone has something to offer.What it does: SkillSwap connects users looking to exchange skills on a one-to-one basis. Instead of paying for lessons, users find others who have the skills they want and can offer to trade a skill in return. Users can make listings where they make it clear what skill they want to learn and what skill they can teach others in return, then they can connect with users who see their listing and fill out a request to initiate a skill swap. Once connected, users can chat, schedule sessions, and exchange knowledge in a mutually beneficial way. By fostering direct exchange, SkillSwap removes any financial barriers to the user and allows anyone to learn any skill.How we built it: We built SkillSwap using Flask for the backend, handling user authentication, database interactions, and search functionality. Our frontend is built with HTML, CSS, and JavaScript, creating an intuitive interface for users to browse and post skill exchanges. We used SQLite for storing user listings and session data.Challenges we ran into: Building an Effective Search System: We had to ensure search results only displayed users who both had the skill the searcher wanted to learn and needed a skill the searcher could teach. This required designing complex SQL queries and optimizing database performance.Creating an Intuitive UI: We aimed for a simple yet effective design that clearly displays what skills a user is offering and looking for.,Accomplishments that we're proud of: Developed a functional prototype within the hackathon timeframe.Designing the UI to make finding and posting for skills simpleSuccessfully implemented a matching algorithm that ensures relevant connections.Built a foundation for expanding into a full-fledged platform.,What we learned: The importance of a user-centred design\u2014people want connection, not just features.A well-thought-out business idea with an execution plan is much better than a technically advanced product with no real purpose.,What's next for SkillSwap: Group skill swaps - One group swaps skills with anotherLive Chat System \u2013 So users can discuss skill swaps before committing.5-Star Rating System \u2013 To build trust between users.Custom User-Made Skill Tags \u2013 Allowing more flexible skill categorization.Discussion Forums \u2013 For community interaction and knowledge sharing.,",
                        "github": "https://github.com/nafaytashfeen/DeerHacksHackathon",
                        "url": "https://devpost.com/software/skillswap-p52ajo"
                    },
                    {
                        "title": "Dormigo",
                        "description": "The fastest way for students to discover housing and roommates\u2014no more endless searching, just the best options, instantly.",
                        "story": "Project Website:https://deerhacks-iv--kappa.vercel.app/\ud83d\ude80 Theme: Discovery: \ud83d\udca1 Idea:A one\u2011stop platform that helps students discover rental listings and roommates by aggregating listings from Zillow and Toronto Rentals\u2014all while using roommate matching and trust scoring to reduce scams.The Problem: Student Housing is Broken: Due to fragmented and unreliable platforms, students struggle to find safe, affordable, and convenient housing. Current options are inefficient, resulting in wasted time, scams, and difficulty finding roommates.Students search across multiple websites such as Zillow and Toronto Rentals.Listings are often duplicated, outdated, or missing key details (e.g., utilities, furnished status).No smart search\u2014students must manually filter through dozens of unrelated listings.,\u2705Aggregated Listings:Combines data from Zillow and Toronto Rentals into one platform.\u2705Smart Filtering & Search:Quickly sort by rent, location, lease type, while filtering by price.\u2705Roommate Matching:Matches students based on lifestyle habits, sleep schedules, study preferences, and cleanliness levels.,\ud83c\udfaf Core Features for MVP: \u2699\ufe0f Tech Stack: Frontend:React + ViteTailwind CSSBackend:Python & FastAPIPostgreSQLData Collection:BeautifulSoup and Selenium (for Zillow & Toronto Rentals scraping),\ud83e\uddd0 Meaning Behind the Name: Dormigois a fusion of two words:Dorm+Amigo.Dorm:Reflects the core focus on student housing\u2014dormitories and other student living spaces.Amigo:Spanish for \"friend,\" conveying the platform's commitment to creating a friendly, trustworthy community where students can find reliable roommates and feel at home.,Together, Dormigo suggests a supportive, community\u2011driven environment that helps you find a place to live and connects you with like\u2011minded roommates\u2014making the often challenging search for safe and affordable student housing a more personal and reassuring experience.\ud83c\udf1f Inspiration & Reflection: Inspiration:We were inspired by the real\u2011life challenges students face when searching for safe and affordable housing, as well as the difficulty in finding compatible roommates. We wanted to create a solution that not only aggregates listings from various sources but also makes the roommate matching process simple and reliable.What We Learned:Through this project, we gained valuable insights into full\u2011stack development, integrating web scraping with modern web frameworks, and building a user\u2011friendly interface. We learned the importance of validating diverse data sources and creating an intuitive search experience that builds trust among users.How We Built the Project:We began by outlining the key issues in the student housing market and prototyping a solution. We then set up a backend using Python, FastAPI, and PostgreSQL for data management and implemented data collection using BeautifulSoup and Selenium to scrape Zillow and Toronto Rentals. Finally, we built the front end using React, Vite, and Tailwind CSS. Roommate matching was implemented based on user\u2011specified lifestyle preferences to help connect students with like\u2011minded roommates.Challenges Faced:One of the biggest challenges was dealing with inconsistent data formats across multiple listing sources and ensuring data freshness. Additionally, fine\u2011tuning the roommate matching algorithm to deliver accurate matches required extensive testing and iteration. Balancing these technical challenges while maintaining a smooth user experience was a significant learning curve for us.",
                        "github": "",
                        "url": "https://devpost.com/software/dormigo-hnu04k"
                    },
                    {
                        "title": "PaperOrbit",
                        "description": "Navigate the cosmic network of research",
                        "story": "Inspiration: Research papers are often difficult to navigate due to the sheer volume of academic work published daily. Traditional databases rely on keyword-based search, which can make it hard to discover related works intuitively. We wanted to create a tool that helps researchers, students, and professionals explore papers through a visual, citation-based network\u2014making research more engaging and efficient.What it does: PaperOrbit is an interactive graph-based research paper database that allows users to search for academic papers and explore related works based on citations. When a user searches for a topic or a specific paper, the tool generates a graph visualization showing direct citations, forming a web of related works, and enabling users to navigate research landscapes intuitively.How we built it: We structured the database using a graph database called Neo4j, where nodes represent research papers and edges represent citations. The backend is built with TypeScript and Node.js, handling search queries and graph traversal efficiently. The frontend uses Sigma.js for interactive graph visualization, allowing users to explore relationships dynamically.Challenges we ran into: Data acquisition: Finding an accessible and comprehensive dataset of research papers and citations was a challenge.Graph performance: Handling large-scale citation networks efficiently required optimization techniques like indexing and caching.User experience: Designing an intuitive graph visualization that is both informative and easy to navigate took several iterations.,Accomplishments that we're proud of: Successfully integrating a large-scale citation network into an interactive graph structure.Implementing an intelligent search that suggests related papers beyond direct keyword matches.Creating a visually appealing and user-friendly interface that enhances research exploration,What we learned: What's next for PaperOrbit:",
                        "github": "",
                        "url": "https://devpost.com/software/paperorbit"
                    },
                    {
                        "title": "Rap Battle AI",
                        "description": "Unleash your lyrical skills with AI-powered rap battles, spit bars and level up your flow! Battle against AI rappers, generate freestyle verses, and refine your rhythm with real-time analysis.",
                        "story": "Inspiration: Hip-hop and freestyle rap have long been a platform for self-expression, creativity, and lyrical mastery. We were inspired by rap battles, where artists engage in fast-paced lyrical duels, and wanted to bring that experience into the world of AI. The idea was to create an AI-powered opponent that could generate creative rhymes, analyze user input, and provide an engaging rap battle experience.What it does: Rap Battle AI allows users to freestyle against an AI rapper that generates dynamic responses based on their lyrics. Users can:Spit bars using text or voice inputGet AI response at similar skill level,How we built it: Frontend: Created using PygameAI and lyrics generation: Leveraged GPT-based models prompted for freestyleSpeech recognition and synthesis: Integrated FFmpeg and Speech-to-Text APIs to allow voice-based rap battlesScoring system: Developed an AI-powered lyrical evaluation model to assess rhymes, rhythm, and word complexity,Challenges we ran into: Generating meaningful, coherent rap responses that match the user\u2019s styleReal-time feedback processing without delays affecting the flow of the battleSpeech-to-text accuracy, especially for fast-paced rapping and slangMaintaining a balance between AI-generated lyrics and creative spontaneity,Accomplishments that we're proud of: Successfully developed an AI that can generate structured rap lyrics on the flyCreated an interactive rap battle experience that provides real-time feedbackIntegrated speech recognition to enable voice-based freestyling,What we learned: Natural language processing techniques for generating and evaluating rap lyricsThe challenges of real-time AI response generation and keeping latency lowHow to fine-tune AI models to make them more context-aware and creative,What's next for Rap Battle AI: Beat synchronization, making AI raps flow seamlessly over instrumentalsAdaptive AI rappers that learn from user styles and improve over timeMore rap personas,",
                        "github": "",
                        "url": "https://devpost.com/software/rap-battle-ai"
                    },
                    {
                        "title": "RoadMapr",
                        "description": "\r\nYour roadmap, your way...",
                        "story": "Inspiration: Our original idea was to build aUniversity of Toronto (UFT) alumni networkusing the LinkedIn API. We wanted to help students connect with alumni to find career opportunities. However, we quickly hit a roadblock\u2014LinkedIn\u2019s API was extremely limited, providing only basic profile information (name, email, and image) andno search functionality. We stayed up until2 AM on Friday nighttrying to make it work but ultimately had to pivot.The next morning, inspired by our frustration and our shared passion for career growth, we came up with a new idea:What if we could use your resume to map your future career path and show you how to reach your dream job?That\u2019s howRoadMaprwas born.What it does: RoadMapris an AI-powered career planning tool that:Analyzes your resumeto understand your skills, experiences, and career trajectory.Generates a personalized career roadmap, showing potential roles, companies, and skill gaps.Provides actionable insightswith company rationales to help you choose the right path.Stores your career roadmapfor future updates and adjustments.You simply upload your resume, and RoadMapr usesLLMsto map out your journey step-by-step.How we built it: Backend:Built withPython, usingCohere's APIto generate career roadmaps from resumes.Database:We usedSupabaseto store resumes, career roadmaps, and user profiles.Frontend:Developed withReact and Tailwind CSS, providing an interactive experience with career phases and animations.LLM Integration:We refined prompts to improve the quality and relevance of the career roadmaps.,Challenges we ran into: Pivoting from our original idea:The LinkedIn API\u2019s limitations were a huge disappointment, forcing us to scrap our original project after hours of work.Prompt Engineering:Refining the prompts for the LLM was tricky. We needed the AI to output structured JSON with clear career phases, which required multiple iterations.Frontend Animations:We faced issues with rendering smooth animations for the roadmap phases but resolved them after experimenting with different libraries.Time Crunch:Losing almost a full day to the LinkedIn API setback meant we had to work under extreme pressure to finish the project.Accomplishments that we're proud of: Creative Pivot:Turning a major setback into a new, exciting project overnight.LLM Integration:Successfully generating structured career roadmaps with company rationales.Frontend Animations:Creating a smooth, interactive roadmap experience.Teamwork & Resilience:Pushing through challenges and working together to ship a fully functional MVP.What we learned: Adaptability:Sometimes, the best ideas come from setbacks.Prompt Engineering:Getting structured, high-quality outputs from LLMs requires experimentation and iteration.Time Management:Rapidly building an MVP under pressure taught us the importance of prioritizing features.API Limitations:It\u2019s crucial to research API capabilities deeply before building around them.What's next for RoadMapr: Resume Parsing Improvements:Use advanced NLP to extract skills and achievements from resumes more accurately.Interactive Roadmaps:Allow users to customize their career paths by adding or removing roles.Skill Gap Analysis:Suggest certifications, courses, and projects to help users reach their next career goal.Company Insights:Provide real-time insights into company hiring trends using web scraping and job boards.Alumni Network (Long-Term):Revisit our original idea using verified alumni databases and other networking APIs.RoadMapr:Your roadmap, your way.",
                        "github": "",
                        "url": "https://devpost.com/software/roadmapr"
                    },
                    {
                        "title": "Heritrace",
                        "description": "\ud83d\udd0d Heritrace \u2013 Discover the story behind your name! \ud83c\udf0d Enter your name and explore its origins, cultural roots, food, fashion, and history. Your name is more than words\u2014trace its heritage today! \u2728",
                        "story": "Inspiration: Canada is a diverse country with many people living in the diaspora. Some may not fully know their roots, and we wanted to create an easy-to-use solution that helps them trace their heritage effortlessly.What it does: Heritrace takes a user\u2019s name and, using the OpenAI API, analyzes its origins and meaning. Based on the country of origin, it provides insights into the culture, language, and foods of that region.How we built it: We used React + Vite for the frontend and built a custom API endpoint to communicate with OpenAI\u2019s inference servers for name analysis and cultural insights.Challenges we ran into: Getting the map to work was quite hard. Setting up the inference servers for OpenAI took time. We encountered (and battled) multiple merge conflicts along the way.Accomplishments that we're proud of: Successfully building a working product! \ud83d\ude80 Implementing real-time name analysis with meaningful cultural insights. That we learnt and adapted to languages/frameworks that we never used beforeWhat we learned: Learned React, as well as using the maps component of React. Also learned how to use Vite. Learned how to use the OpenAI API, and use inference servers. Also learnt how to navigate merge conflicts efficiently.What's next for Heritrace: Probably add an interactive chatbot option, so that after a response is given from Heritrace, the user will be able to ask more questions about their culture.",
                        "github": "https://github.com/arsencameron/deerhacks25",
                        "url": "https://devpost.com/software/heritrace"
                    },
                    {
                        "title": "Unite\u2122",
                        "description": "Events on campus, made simple.",
                        "story": "Inspiration: Events and important dates on campus is an important aspect of being a student at the University of Toronto. However, we believe that with a more simple interface and an interactive map, navigating campus and making connection could be much easier. With this in mind, we decided to create Unite\u2122, a simplistic and interactive event discovery website.What it does: Unite\u2122 uses a database that stores information about users, events, and clubs in order to effectively sort and display them to students at UTM. Unite\u2122 includes filtering and search options, to ensure you find events that best suit you, and your timetable.How we built it: We built the app with React on the front-end and Python, Flask, and MySQL as the back-end.Challenges we ran into: The major challenge we encountered was integrating the front end with the back end. Figuring out how to communicate data from the MySQL database and display it on the site was surprisingly difficult. Additionally, source control with Git made it challenging to merge both sides of the web app, as the front end and back end were developed separately for testing, leading to many merge conflicts.Accomplishments that we're proud of: We are proud of completing our respective parts within the limited time we had. The frameworks and languages used in this project were outside our comfort zones, so being able to learn new tools and successfully develop a working web app is something we take pride in. Finally, having a working version the whole webapp is the biggest accomplishment out of everything.What we learned: We learned the importance of clear communication between the back end and the front end. Ensuring both sides of the project are aligned and minimizing source control conflicts made merging significantly easier.What's next for Unite\u2122: We plan to expand Unite\u2122 by incorporating features found in other scheduling and event planning apps. One of our first next steps is integrating the web app with external third-party applications such as Google Calendar. Additionally, we aim to implement user authentication through the UofT dashboard, allowing us to access timetable data and help students identify scheduling conflicts with their classes, exams, and other commitments.",
                        "github": "https://github.com/etpans/deerhacks-2025",
                        "url": "https://devpost.com/software/unite-jh2kl1"
                    },
                    {
                        "title": "StarLink",
                        "description": "Welcome to StarLink! This app uses Pygame to render an interactive star map. Explore the night sky, zoom, pan, and highlight stars. Perfect for astronomers and education. Discover the universe!",
                        "story": "Inspiration \ud83e\udde0: The inspiration for StarLink \ud83c\udf0c came from our fascination with the night sky and the desire to make astronomy more accessible to everyone. We wanted to create an interactive tool that allows users to explore and learn about the stars and constellations in a fun and engaging way. \ud83d\ude00What it does \ud83d\udcbb: StarLink is an interactive star map application that allows users to explore the night sky. Users can zoom in and out, pan across different regions, and highlight specific stars and constellations. The app provides a seamless and engaging experience for both amateur astronomers and educational purposes.How we built it \ud83d\udee0\ufe0f: We built StarLink using Pygame \ud83c\udfae for rendering the star map and handling user interactions. The project involved several key components:StarMap: Manages the data and logic for the star map, including scaling and panning.Renderer: Handles the drawing of stars, constellations, and other celestial elements.Selection: Allows users to select and highlight specific stars and constellations.,We also implemented features like zooming, panning, and caching to enhance the user experience and performance. \ud83d\udca1Additional Feature \ud83d\udd79\ufe0f: We implemented a MediaPipe-based hand gesture tracking feature to control map movement and zoom. However, due to time constraints, we couldn't integrate gesture-based star selection and constellation connection. This remains a key focus for future development.Challenges we ran into \ud83d\udea7: One of the main challenges we faced was optimizing the rendering pipeline to ensure smooth performance, especially when handling large datasets of stars and constellations. We also had to carefully manage user interactions to provide a seamless and intuitive experience. Debugging and fine-tuning the selection and highlighting features were also challenging but ultimately rewarding.Accomplishments that we're proud of \ud83d\ude0e: We are proud of creating a visually appealing and highly interactive star map that provides a smooth user experience. Successfully implementing features like zooming, panning, and star selection were significant milestones. Additionally, optimizing the rendering pipeline to handle large datasets efficiently was a major accomplishment. \ud83d\ude0aWhat we learned \ud83d\udcda: Throughout this project, we learned a lot about Pygame and its capabilities for rendering graphics. We also gained a deeper understanding of astronomical concepts and how to represent them visually. Additionally, we improved our skills in handling user interactions and optimizing rendering performance.What's next for StarLink \ud83d\udca1\ud83d\udcad: In the future, we plan to add more features to StarLink, such as detailed information about stars and constellations, support for different celestial events, and integration with real-time astronomical data. We also aim to enhance the user interface and make the app available on multiple platforms.Appendix: The constellations data set is from:https://github.com/eleanorlutz/western_constellations_atlas_of_space/tree/mainThe public python package we used:pygame: 2.6.1mediapipe: 0.10.20opencv-python: 4.11.0.86pyautogui: 0.9.54numpy: 1.26.4panda: 2.2.1,",
                        "github": "https://github.com/chr1sren/DeerHack-2025",
                        "url": "https://devpost.com/software/starlink"
                    }
                ],
                [
                    {
                        "title": "AI Therapist",
                        "description": "Discover Yourself, One Conversation at a Time.",
                        "story": "Inspiration: The theme of the hackathon was \"Discovery,\" and we wanted to focus on the discovery of oneself. Mental health is a topic that affects everyone, yet many struggle to find a safe space to express their thoughts. Traditional therapy can be expensive, inaccessible, or intimidating, so we set out to create a virtual AI therapist\u2014a tool that encourages self-reflection and personal growth through conversation.What It Does: AI Therapist is a 3D virtual companion that interacts with users in real-time, helping them reflect on their thoughts, emotions, and challenges.Conversational AI: Users type a message, and the AI therapist provides thoughtful and supportive responses.Lifelike Expressions & Voice: The AI responds with animated facial expressions and natural speech, making the interaction feel real.Self-Discovery & Reflection: The AI guides users through introspective conversations, helping them better understand themselves.Always Available: Unlike traditional therapy, AI Therapist is accessible 24/7 to provide emotional support anytime.,How We Built It: We used a modern tech stack to ensure a smooth and interactive user experience:Front End: React \u2013 To build an intuitive, user-friendly interface.Back End: Node.js \u2013 To handle user interactions and AI responses.AI Engine: ChatGPT/Gemini API \u2013 To generate meaningful and personalized replies.3D Modeling & Animation: Implemented a virtual avatar with facial expressions and animations to enhance engagement.Deployment: Vercel \u2013 To host our application and ensure fast performance.,Challenges We Ran Into: Accomplishments That We're Proud Of: Successfully integrated AI with a 3D model to create an engaging and interactive therapist.Built a real-time chat system that delivers thoughtful and personalized responses.Overcame technical challenges to make the therapist expressive and relatable.Deployed a working version of the app that is accessible to users anytime, anywhere.,What We Learned: How to fine-tune AI-generated conversations to make them feel meaningful and supportive.Techniques for integrating 3D animations with AI responses.Best practices for building a scalable and responsive AI-driven web app.The importance of user experience in mental health applications.,What\u2019s Next for AI Therapist: More Personalized Responses: Enhancing AI prompts to provide deeper, more tailored interactions.Emotion Detection: Implementing sentiment analysis to adjust responses based on tone.Mobile App Version: Expanding to mobile for on-the-go access.Expanding Mental Health Resources: Partnering with professionals to ensure responsible and effective AI support.,We believe AI can play a big role in mental well-being, and this is just the beginning of our journey. Thank you!",
                        "github": "",
                        "url": "https://devpost.com/software/ai-therapist-5vuojz"
                    },
                    {
                        "title": "Letterfly",
                        "description": "Write a letter. Learn a language.",
                        "story": "What it does: Letterfly is a letter writing app that allows you to write letters to anyone in the world, with the aim of helping you practice learning the languages of your choice. If you want to practice reading in Japanese, but want to write in English, Letterfly can send your letter to a person with the opposite goal as you, and you can mutually benefit! You aren't on your own though - Letterfly has a built in translation feature if you ever get stuck reading a complex letter from your pen pal. While you're waiting for a response for your letters, you can discover open letters from others and continue learning and connecting with new people there. Overall, we aimed to create a fun and interactive way to improve your language skills while building connections with people on the other side of the world through letter writing.How we built it: We hosted this website on Flask, with an HTML/CSS/JS front end. We used an API called Quill.js for a clean letter text editor, the Google Translate API, and an API called Beautiful Soup to help us handle HTML formatting. The project is hosted locally, with a database written in SQL.Challenges we ran into: Integrating the Google Translate API and ensuring accurate translations was tricky, especially with idiomatic phrases. Handling different languages' formatting (like Japanese scripts) also posed some challenges, and creating an intuitive design for users of all linguistic backgrounds took extra effort.Accomplishments that we're proud of: We\u2019re proud of creating an app that connects people globally through language learning via letter writing. The translation feature helps users tackle complex letters, and the user interface is simple and easy to use, making the experience enjoyable.What we learned: We gained experience with APIs like Google Translate and Beautiful Soup, and learned how critical it is to focus on user experience. We also learned how to handle language-specific formatting and character encoding to ensure the app works well across cultures.What's next for Letterfly: In the future, we aim to have more features on the website! We would like to have added learning features such as a dictionary to help people check definitions for the words on the spot. We'd also like the app to have more fun letter writing features, such as the option to add stamps and customize your envelope.",
                        "github": "https://github.com/CloudyKrypton/letterfly",
                        "url": "https://devpost.com/software/letterfly"
                    },
                    {
                        "title": "It's Canadian, Eh?",
                        "description": "Our grocery prices are going to skyrocket just because someone decided so. Why let that be when we can buy local products? Discover Canadian products with us. Find alternate products, buy local.",
                        "story": "Inspiration: We were saddened hearing the news about the tariffs that are about to strike us. To prepare ourselves anddiscover our inner Canadian spirit, we have decided that buying Canadian products instead of other countries' would be a great way of supporting our community.What it does: It's Canadian, Eh?\" has two main functionalities. The first is abarcode scannerthat identifies your product, determines if it is Canadian, and gives you Canadian alternatives if it is not. The second is aLLMthat allows you to inquire about general topics related to Canadian products.How we built it: We built this webapp using nextjs, building react components and making many api calls. To name a few major components in our backend:Barcode scanner uses Quagga, JS plugin that works across different platforms to parse the barcode from the video streamed from the user's camera.Product identification uses the barcodelookup API, it takes the barcode number and tells us all the relevant product information.LLM we used is Gemini. We make API calls to it to identify the country of origin of the product, suggest alternatives, and respond to the user's prompts in general.,Challenges we ran into: Next.js's server and client side architecture was particularly troublesome for us, especially since we don't have a lot of experience with it. Sometime we would think the code works but because some part is in client side in a server sided function, it gives us errors. Luckily after mentors' help and reading through documentations, we have learnt the way to properly use our components.Accomplishments that we're proud of: We are proud of completing the project in such a tight deadline. We were feeling pretty strong against the tariffs which prompted us to work harder (and maybe pull all-nighters).What we learned: Discovering new technologies are cool but maybe it will be cooler when we are not stressed about it.What's next for It's Canadian, Eh?: We plan to add more local small businesses into our database through fine-tuning the LLM to truly support the Canadians.",
                        "github": "",
                        "url": "https://devpost.com/software/it-s-canadian-eh"
                    },
                    {
                        "title": "NomiChan",
                        "description": "Discover more of yourself and grow with NomiChan",
                        "story": "Inspiration: Journaling has always been a powerful tool for self-discovery. It helps oneself untangle their thoughts, reflect on their emotions, and make sense of their experiences. Journaling is a way to navigate life's challenges while cultivating mindfulness, creativity, and self-awareness.But sometimes, I wish journaling felt a little less lonely. There are moments when I want to talk through my thoughts, have someone respond, or even just feel like I'm being heard. That\u2019s why we created NomiChan\u2014an AI-powered journaling companion.She\u2019s more than just a chatbot. She understands what I write, offers insights, and engages in meaningful conversations about my journal entries. She\u2019s a safe space\u2014someone I can confide in, brainstorm with, and reflect alongside. Whether it\u2019s helping me process emotions, guiding me through self-exploration prompts, or simply being there, she makes journaling feel more interactive and personal.What it does: NomiChan isn\u2019t just a journaling app\u2014it\u2019s an immersive experience in self-discovery. With an AI-powered companion by your side, journaling becomes more than just writing\u2014it\u2019s a safe space conversation.\u2728 Your AI Companion \u2013 Your AI companion will understand, analyze, and engage with your thoughts. She recognizes patterns, emotions, and themes to offer insights that help you see the bigger picture.\ud83d\udde3\ufe0f Real-Time Dialogue \u2013 Stuck on a thought? Need a fresh perspective? Talk to your AI companion\u2014she\u2019ll respond with thoughtful questions, validation, or even creative prompts to deepen your reflection.\ud83d\udcd6 Interactive Reflection \u2013 Your AI remembers past entries, helping you track your personal growth, uncover recurring emotions, and gently guide you toward new realizations.Side-by-Side Journaling \u2013 Write while your AI companion sits at her desk, responding in real-time. It\u2019s like having a thoughtful, always-present friend to navigate your thoughts with you.\ud83c\udfa8 Personalized Expression \u2013 Highlight key moments, add aesthetic stickers, and visually organize your entries to make them feel yours.With NomiChan, journaling isn\u2019t just about recording the past\u2014it\u2019s about shaping the future, one meaningful conversation at a time.How we built it: We built NomiChan to be more than just a simple journaling app. Inspired by the Open-LLM VTuber chat, we integrated the GPT model to power the dynamic and context-aware conversation of your 2D avatar. To bring conversations to life, we incorporated Fisher AI for realistic and expressive voice interactions.To make interactions even more meaningful, we developed an algorithmic memory system that feeds past journal content into GPT. This allows NomiChan to randomly but naturally prompt conversations about past journal topics, helping users reflect on their thoughts, recognize patterns, and discover more about themselves over time.On the frontend, we designed two intuitive pages using Vanilla Javascript, HTML, and CSS, ensuring a smooth and user-friendly experience. For the core journaling feature, we leveraged PSPDFKit, enabling full customization\u2014users can highlight text, add stickers, and personalize their entries to make their journal truly their own.On the backend, we implemented a Flask server to locally log user chat history and journal content in JSON files, ensuring seamless integration between the AI conversations and journaling experience.Challenges we ran into: Building NomiChan came with its own set of challenges. One of the biggest hurdles was creating a 2D AI companion that feels human and natural. We wanted the avatar to engage in meaningful conversations, respond fluidly, and recall past journal entries in a way that felt organic. Finding the right balance between realism and responsiveness while integrating GPT LLM and Fisher AI took significant fine-tuning.\nAnother challenge was managing server deployments efficiently. Since the app runs multiple main servers simultaneously, we had to carefully track and manage ports to prevent conflicts. Ensuring seamless communication between the Flask backend, React frontend, and AI processing systems required careful orchestration.\nDespite these challenges, we worked through each obstacle, refining the AI's conversational flow and optimizing the infrastructure to provide a smooth and immersive journaling experience.Accomplishments that we're proud of: We\u2019re proud of bringing the AI companion to life with GPT LLM for natural conversations and Fisher AI for expressive voice interactions where one could have not just a personal journal, but a friend who could grow with them as time goes on.What we learned: Throughout the development of NomiChan, we deepened our understanding of several key technologies. We gained more experience with Flask in managing backend logic and handling data storage, while refining our skills in Vanilla Javascript for frontend communication and real-time interactions. Working with PSPDFKit enhanced our knowledge of PDF manipulation, allowing us to create a fully customizable journaling experience. Additionally, Docker became an invaluable tool in managing development environments and simplifying deployment.\nWe also explored technologies we couldn't fully apply, like Three.js. While we didn't integrate it this time, we gained insights into its capabilities for future projects, particularly in enhancing 3D interactions and visual elements. This experience expanded our technical toolkit and opened new doors for future innovation.What's next for NomiChan: We will also train the avatar to recognize user emotions during the conversation, fostering a sense of understanding and comfort for users as they reflect on their thoughts. Given the sensitive nature of journaling, enhancing data security and privacy features will also be a priority. We will implement end-to-end encryption, secure cloud storage, and customizable privacy settings to ensure that journal entries remain confidential and protected. These improvements will make NomiChan a secure and emotionally aware companion for self-reflection.",
                        "github": "https://github.com/nfldty/journalingbuddy",
                        "url": "https://devpost.com/software/reflecta"
                    },
                    {
                        "title": "CityAid - DeerHacks 2025 Submission",
                        "description": "CityAid is a web-based platform that helps individuals quickly locate essential emergency services based on location.",
                        "story": "Inspiration: Many individuals in crisis whether experiencing homelessness, facing domestic violence, or needing urgent medical assistance struggle to find nearby emergency services quickly. Existing tools like Google Maps are not designed for life-threatening situations or real-time shelter availability. Inspired by this gap, we built CityAid to provide a fast, reliable, and location-based solution for those in urgent need.What it does: CityAid is a web-based emergency resource locator that helps users find essential services near them, including:\n-> Emergency Shelters \u2013 Locate safe spaces for overnight stays.\n-> Free Medical & Mental Health Support \u2013 Find urgent care clinics and crisis centers.\n-> Food Banks & Survival Essentials \u2013 Get access to free meals, water, and clothing.\n-> Crisis Hotlines & Domestic Violence Safe Houses \u2013 Immediate access to life-saving contacts.\n-> Disaster Relief Centers \u2013 Locate aid stations for floods, wildfires, and extreme weather.With an emergency mode for quick access to critical contacts, CityAid ensures help is always within reach.How we built it: -> Frontend: React.js (v19.0.0), Material-UI (MUI v6.4.4), CSS-in-JS for UI components, React Router DOM (v7.1.5) for routing, Axios for HTTP requests, Papa Parse for CSV parsing\n-> Backend: Node.js, Express.js framework, Middleware: cors (Cross-Origin Resource Sharing), body-parser dotenv (for environment variables)\n-> Data: CSV files for storing service data, Python scripts for data processing\n-> Data Sources: Government open data (211 Canada, municipal listings, canada.com).Challenges we ran into: The biggest and most difficult part of the build was data collection \u2013 Finding accurate and up-to-date emergency resource data required manual scraping and verification.Accomplishments that we're proud of: -> Successfully built a fully functional prototype in just 35 hours while working Solo\n-> Integrated location-based emergency listings with an intuitive UI.\n-> Implemented an Emergency Mode for instant access to crisis contacts.\n-> Created a platform that can truly make a difference in people\u2019s lives.What we learned: -> The importance of verified data in emergency situations.\n-> How to integrate Google Maps APIs.\n-> The different ways of processing Data with python for efficiency\n-> How to work under extreme time constraints.What's next for CityAid - DeerHacks 2025 Submission: -> Expanding to a Mobile App \u2013 Bringing CityAid to iOS & Android.\n-> Community-Verified Listings \u2013 Allow users and volunteers to submit and validate emergency services.\n-> Partnerships with NGOs & Governments \u2013 Integrate official APIs to keep resources updated in real-time.",
                        "github": "",
                        "url": "https://devpost.com/software/cityaid-deerhacks-2025-submission"
                    },
                    {
                        "title": "AR Museum",
                        "description": "A way to leave augmented-reality based text messages at any location in the world for others to discover",
                        "story": "Inspiration: We wanted to build something fun and interactive using Augmented Reality (AR). The idea was to let people add text, drawings, and media into an AR space. We also wanted features like messaging, live location tracking, and Google login to make the project more useful.What it does: This project is a dashboard app where users can:Log in using Google or manually with email and password.Toggle between light and dark mode.See their live location on a map.Send and receive messages.Use AR to add floating text and drawings in a real-world space.,How we built it: Frontend: Built using React and CSS for styling.Authentication: Uses Google login (OAuth).AR Feature:Uses A-Frame & AR.js to display text and drawings in AR.Users can type a message or draw on a canvas and see it appear in AR.Backend:Uses a Firebase NoSQL database to store AR messages with location data.When a user adds a message or drawing in AR, it is saved in Firebase.,Challenges we ran into: Making AR work smoothly was difficult. We had to figure out how to add text and drawings properly.Connecting authentication and navigation in React took time to set up.Keeping the live location accurate was tricky, as GPS updates can be slow.,Accomplishments that we're proud of: We successfully made an AR experience where users can add text and drawings.Google login works properly, making it easy for users to sign in.The dark mode toggle saves the theme preference for users.The app has a clean and simple dashboard UI.,What we learned: How to use React hooks like useState and useEffect to manage data.How to set up Google login in a React app.How to use A-Frame and AR.js to create simple AR experiences.How to save and retrieve data from a Firebase NoSQL database.How to use Google Map's API to integrate with out project,What's next for AR Museum: More AR features: Add images, videos, and 3D objects.Better messaging: Make messages update in real time.User profiles: Let users save their AR creations.Location-based AR: Show AR content at specific real-world locations.,",
                        "github": "https://github.com/mirasimali5005/DeerHacks.git",
                        "url": "https://devpost.com/software/ar-museum"
                    },
                    {
                        "title": "DiscsoverEase",
                        "description": "Discover new locations with ease.",
                        "story": "",
                        "github": "https://github.com/Franco-Aparicio/DiscoverEase",
                        "url": "https://devpost.com/software/discsoverease"
                    },
                    {
                        "title": "Pathway",
                        "description": "Pathway is an AI tool which helps students pick their university courses based on their interests. The UofT website is scraped and the AI creates the most suitable course list.",
                        "story": "",
                        "github": "https://github.com/49M/Pathway_App",
                        "url": "https://devpost.com/software/pathway-9ne2sq"
                    },
                    {
                        "title": "Studdy Buddy",
                        "description": "An App for finding a study buddy instantly on Campus based on schedule overlap and interests. ",
                        "story": "What it does: Looking for a study buddy? Studdy Buddy Matcher will match you to a study buddy according to the classes you are taking and your lecture/practical/tutorial section! Just copy and paste the courses you are taking from ACORN and Study Buddy will find your perfect study match!How we built it: We build this web application using Flask to create API routes to access database information, Python to calculate match rates, and React to create a dynamic front end and user flow.Challenges we ran into: Merging the front end and back end so that data from the user gets sent to the database and back and forth\nValidating password entry for the user while keeping computer security in mind was also a challenge on our side.Accomplishments that we're proud of: We managed to get the pages rendering and they look nice and welcoming. We created the database and managed to establish the connection to the database. The app is not far away from being fully functioning, we just need a little bit of extra time to integrate all of our partsWhat we learned: We learned to write API with Flask as well as navigating the REACT frontend framework.What's next for Studdy Buddy: What's next for the Study Buddy: We still need to connect out parts and make it work, and afterwards, we will improve the app's security and add more features",
                        "github": "https://github.com/zainah234/StuddyBuddyMatcher",
                        "url": "https://devpost.com/software/studdy-buddy-tp4mzr"
                    },
                    {
                        "title": "DreamScape",
                        "description": "DreamScape: A Journey of Self-Discovery Through Your Dreams.",
                        "story": "Inspiration: Dreams are often a reflection of our subconscious, filled with emotions, symbols, and messages that can guide us towardself-discovery. We wanted to create a tool that helps peopleunderstand their dreams in a structured way, using AI to uncover deeper insights.What It Does: DreamScape allows users toinput a dream, either by typing or speaking, and receivethree different interpretations:Mind Door \ud83e\udde0\u2013 A psychological and emotional analysis of the dream.Spirit Door \ud83d\udd2e\u2013 A symbolic or spiritual interpretation.Action Door \u26a1\u2013 A practical step or task related to the dream.,The interpretations are generated usingNatural Language Processing (NLP) and AIto providemeaningful and personalized insights.How We Built It: DreamScape was developed using afull-stack approach:Frontend:Next.js, Tailwind CSS, and React for an interactive UI.Backend:Express.js to handle API requests and pass dream inputs to a Python NLP script.NLP Processing:Tokenization and filtering usingNLTKto extract meaningful words from the dream.Removal of stopwords, punctuation, and common filler words to improve analysis.AI Interpretation:The processed dream is sent toGoogle Gemini AI ** to generate interpretations for **mind, spirit, and action.AI prompts are structured togenerate concise and meaningful responsesbased on the dream\u2019s content.,Challenges We Ran Into: One of the biggest challenges wasensuring the AI-generated interpretations were relevant and concise. Since dream analysis is highly subjective, craftingeffective NLP pre-processingwas crucial to improve AI responses.IntegratingGoogle Gemini AI with the Python NLP scriptalso required fine-tuning prompts to keep interpretations within astructured 50-word limitwhile maintaining coherence.Another challenge wasreal-time Speech-to-Text transcription, ensuring users could narrate dreams with high accuracy.Accomplishments That We're Proud Of: Successfully integratingAI-powered dream interpretationusing NLP and Google Gemini AI.Creating ascroll-based medieval UIfor an immersive and thematic experience.Implementingspeech recognitionto allow users to narrate their dreams instead of typing.Fine-tuningAI-generated responsesto stay concise and meaningful.,What We Learned: This project deepened our understanding of:NLP techniquesfor extracting meaningful words from unstructured text.AI model integration, specifically how to optimize prompts for Gemini AI.State management and UI designfor a seamless user experience.Handling user input across multiple modalities(text vs. speech).,What's Next for DreamScape: To further enhance DreamScape, we plan to:Improve AI modelsby incorporating deep learning-based NLP techniques for more accurate dream interpretations.Introduce a dream journal featureso users can save and track past dream analyses.Enable community-driven dream sharing, allowing users to compare interpretations with others.Expand AI-generated insights, possibly integrating Jungian or Freudian analysis models.,DreamScape is just the beginning of alarger visionto help peopleunlock the deeper meanings of their dreams. \ud83d\ude80\u2728",
                        "github": "https://github.com/JahangirMinhas/dreamscape",
                        "url": "https://devpost.com/software/dreamspace"
                    }
                ]
            ]
        },
        {
            "title": "Winter Wonderhack 2025",
            "location": "Opie Van Pelt Memorial Library",
            "url": "https://wwh-2025.devpost.com/",
            "submission_dates": "Feb 14 - 16, 2025",
            "themes": [
                "Beginner Friendly"
            ],
            "organization": "ASCII at MTU",
            "winners": false,
            "projects": []
        },
        {
            "title": "Innovo SSGMCE",
            "location": "SSGMCE campus",
            "url": "https://innovo-ssgmce.devpost.com/",
            "submission_dates": "Feb 14 - 15, 2025",
            "themes": [
                "Education",
                "Health",
                "Social Good"
            ],
            "organization": "SSGMCE, Shegaon",
            "winners": false,
            "projects": []
        },
        {
            "title": "JourneyHacks 2025",
            "location": "Applied Sciences Building, SFU",
            "url": "https://journeyhacks-2025.devpost.com/",
            "submission_dates": "Feb 14, 2025",
            "themes": [
                "Beginner Friendly"
            ],
            "organization": "SFU Surge",
            "winners": false,
            "projects": [
                [
                    {
                        "title": "SmartMeal",
                        "description": "Your Culinary Intuition, Amplified",
                        "story": "Inspiration: Tired of recipe boredom and endless scrolling? We were too.  SmartMeal was inspired by the frustration of finding truly delicious and personalized meal ideas.What it does: SmartMeal is your personal AI recipe recommendation engine.  Tell us your taste and dietary needs, and we instantly suggest craveable recipes tailored just for you. Discover new favorites and simplify meal planning!How we built it: We built SmartMeal using NextJS for the backend, React for a user-friendly frontend, and a PostgreSQL database.  Our core recommendation engine is powered by Perplexity AI.Challenges we ran into: Building a truly personalized engine with a limited initial recipe database was a challenge.  We overcame this by focusing on smart algorithms and user feedback to ensure relevant recommendations from day one.Accomplishments that we're proud of: We're proud to have a functional MVP that delivers personalized recipes, a smooth user experience, and a working AI recommendation engine.  The core features are all working and ready for user testing!What we learned: We learned valuable lessons about applying machine learning to recommendations, the importance of MVP feature prioritization, and the power of user-centric design even in early development.What's next for SmartMeal: Next for SmartMeal: We'll expand our recipe database, enhance our AI for smarter suggestions, and add meal planning features.  Excitingly, we're integrating with our previous project, SmartExpense!  This means SmartMeal will estimate recipe costs, and you can track actual spending via SmartExpense.  This powerful combination will help you eat better and manage your food budget effectively.",
                        "github": "https://github.com/qvd808/Smart-Meal",
                        "url": "https://devpost.com/software/smartmeal"
                    },
                    {
                        "title": "Pastry Panic",
                        "description": "Pastry Panic is a fast-paced game where players help a penguin stack the tallest cake, avoiding obstacles and collecting ingredients for bonus points. How high can you stack before it all crashes?",
                        "story": "Inspiration: We were inspired by the theme of the Journey Hacks 2025 websiteWhat it does: The website is a game similar to, \"stack\" the goal is to stack cake layers on top of each other as high as possible. The website hosts the game which was created in Unity as well as displays the leaderboard.How we built it: The website portion of the project was created in React whereas the game portion was created in Unity. In order to combine these we had to use Unity's WebGL which helped us to embed the game into our React app.Challenges we ran into: The biggest challenge we ran into was combining the game with the website. This was the biggest learning curve for us. We also ran into some challenges with React and Node at first when creating the framework for the website.Accomplishments that we're proud of: We're proud of our teamwork. We were able to split into teams of 2 and work on the game and the website. We faced some challenges when it came time to combine the Unity game and React app together, but we were able to figure them out.What we learned: We had experience with React and Unity separately but none of us had experience with using them together. This was the biggest learning curve for us and defiantly took up the most time for our project.What's next for Pastry Panic: In the future we'd like to fix the bugs that we didn't have time to get to during this hackathon. We also want to add a multiplayer PvP mode to the game and some backstory to make it more engaging.",
                        "github": "https://github.com/RavdeepAulakh/SFUSurgeHacks2025",
                        "url": "https://devpost.com/software/pastry-panic"
                    },
                    {
                        "title": "Leftover Love",
                        "description": " Restaurants can effortlessly list available food (that would be wasted), while charities can quickly schedule pickups, ensuring no meal goes to waste. ",
                        "story": "Inspiration: We wanted to create something meaningful that helps both businesses and people in need. Food waste is a huge issue, and we saw an opportunity to turn it into a positive impact for communities.What it does: Leftover Love connects restaurants with charities and food banks to donate excess food. Restaurants list their available food, and charities can claim and schedule pickups easily.How we built it: We used Next.js for the frontend, FastAPI for the backend, and PostgreSQL for storing data. The platform is designed to be simple and efficient.Challenges we ran into: We faced time constraints and couldn't implement all the features we wanted, like real-time notifications and geolocation tracking. Another issue was our conflicts between branches set us back a lot.Accomplishments that we're proud of: A polished UI with complete dashboards for restaurants and charities to track their status. A semi-functional backend that allows log in and sign up.What we learned: We learned a ton about the pains and joys of frontend development, while struggling with some new frameworks.What's next for Leftover Love: Make it extremely accessible for all entities, and connecting new charities and restaurants to our network.",
                        "github": "https://github.com/Bazinator/journey-hacks2025",
                        "url": "https://devpost.com/software/leftover-love-jtf8ip"
                    },
                    {
                        "title": "Rottify: Perplexedly Rotten",
                        "description": "TikTok meets ChatGPT: Transform any document (PDF, text, markdown) into addictive short-form videos automagically! \ud83d\udcda\u2192\ud83e\udd16\u2192\ud83c\udfa5  using bleeding-edge AI (Perplexity Sonar + ElevenLabs + ZapCap) \ud83d\udca5",
                        "story": "\ud83d\udcd6Project Story: From Mindless Scrolling to Microlearning: We noticed something:\ud83d\udcf1 Our friends were spendinghoursmaking \"StudyTok\" summaries, trying to make learning engaging.\ud83c\udfa5Existing tools?Clunky.Professional video editors?Expensive.AI voiceovers?Uncanny valley nightmares.\u26a1 Meanwhile, TikTok\u2019s algorithm wasoptimizing for brain rot\u2014pumping outsnappy,high-energy,chaoticcontent.So, during a10 AM to 6 PM hackathon, fueled bywater and existential dread, we had a thought:And so,Rottifywas born.\ud83d\udd25The Breakthrough: Rottify\u2019s Unholy Trinity: We combinedstate-of-the-art AI modelsto make textunreasonably engaging:\ud83e\udde0Perplexity Sonar\u2013 Shreds documents into viral hooks (\"Shakespeare\u2019s rizz vs. Newton\u2019s trauma\")\ud83c\udfa4ElevenLabs\u2013 AI voiceovers trained on69,420 hoursof \u201cslay queen\u201d ASMR compilations\ud83c\udfa5Remotion + FFmpeg\u2013 GeneratesTikTok-stylevideos withhypnotic captions & meme timingThe result?Rottify makes 60-second videos faster than an over-caffeinated YouTuber.\ud83d\udee0\ufe0fHow We Built It: Bonus:We built anEdge-Cached PipelineinNext.js, so Rottify runs3x fasterthan industry tools.\ud83c\udf1fWhat We Learned: \ud83d\udca1Remotion is underrated.We hadzeroprior AI/video experience, but in8 hours, we built afully automated content pipeline.\u26a1AI storytelling is hard.Fine-tuningtext-to-video pipelinestonotsound robotic tookexperimentation & memes.\ud83d\udd04Syncing AI-generated voices to visuals is pain.We learned how toadjust timing algorithmsusingFFmpeg.\ud83d\udea7Challenges We Faced: AI Syncing Woes:MakingAI voiceoversmatchcaption timingrequiredblack magic (and subbae lib).We hackedFFmpeg scriptstoauto-align subtitlestovoice pitch changes.Campus Wi-Fi = Pain:Training AI models onWi-Fi slower than a sloth on melatoninwas... frustrating.We offloadedvoice generationtoEdge Functionsforfaster processing.TikTok Algorithm is a Mystery:We testedwhich video stylesgotthe most engagement.Turns out,flashing captions + absurd sound effects=content goldmine.,Rottify Team \u2013 Turning Your PDFs into Personality Since 10AM Today \ud83e\uddc3",
                        "github": "",
                        "url": "https://devpost.com/software/rottify-perplexedly-rotten"
                    },
                    {
                        "title": "NomNomAI",
                        "description": "NomNomAI provides an AI chatbot to help with cooking needs!",
                        "story": "Inspiration: A handsfree cooking assistant to help us cook at homeWhat it does: Summarizes and answers questions about the recipe using AI.How we built it: Using React.js and OpenAI APIChallenges we ran into: Deploying to VercelAccomplishments that we're proud of: Finishing all our tasksWhat we learned: How to integrate API into React.jsWhat's next for NomNomAI: Formatting and chatbot response efficiency",
                        "github": "https://github.com/IsithaT/NomNomAI.git",
                        "url": "https://devpost.com/software/nomnomai"
                    },
                    {
                        "title": "DocQ Journey Hacks",
                        "description": "AI-powered patient queue system.",
                        "story": "",
                        "github": "https://github.com/ajayunnikrishnan/JourneyHacks2025",
                        "url": "https://devpost.com/software/docq-journey-hacks"
                    },
                    {
                        "title": "Resume Genie",
                        "description": "Maximize your career potential with AI-Powered Resume Matching and Advice.",
                        "story": "",
                        "github": "https://github.com/amir-roshan/client-side.git",
                        "url": "https://devpost.com/software/resume-genie"
                    },
                    {
                        "title": "Cover Letter Cooker",
                        "description": "Got beef with writing cover letters for job applications? No need to crash out, Cover Letter Cooker got you covered FRFR. Just upload your resume, paste a job description, and let us COOK!",
                        "story": "",
                        "github": "https://github.com/camblsoup/JourneyHacks",
                        "url": "https://devpost.com/software/cover-letter-cooker"
                    },
                    {
                        "title": "Smile Please",
                        "description": "Smile Please is a Web 3.0 facial recognition project promoting the power of smiles. Built with Next.js, TypeScript, Tailwind CSS, Privy, and ethers.js, it blends tech and positivity seamlessly.",
                        "story": "Inspiration: The idea behind Smile came from a simple thought: What if technology could encourage happiness? In a world where stress and negativity are prevalent, we wanted to create something that rewards people for a simple, natural act\u2014smiling. Inspired by behavioral psychology and incentive-driven platforms, we designed Smile to blend AI, facial recognition, and blockchain technology into a meaningful experience.What it does: Smile Please is an AI-powered Web3 platform that rewards users with small cryptocurrency payments when they smile. Using facial recognition and sentiment analysis, the system detects and verifies genuine smiles, then triggers a micro-payment in crypto. The goal is to encourage positivity and well-being while showcasing the potential of AI and blockchain in a fun and engaging way.How we built it: We developed Smile Please using:\nNext.js with TypeScript for a fast and scalable frontend.\nTailwind CSS for a sleek and responsive UI.\nPrivy for seamless Web3 authentication, enabling secure user logins.\nethers.js for blockchain interactions, handling transactions and smart contract interactions on the Solana or Ethereum network.\nAI-powered facial recognition and sentiment analysis to detect genuine smiles.Challenges we ran into: Smile Detection Accuracy: Ensuring the AI correctly identifies genuine smiles without false positives required extensive model tuning.\nBlockchain Transaction Costs: Optimizing gas fees for micro-payments was a challenge, so we explored batch transactions and layer-2 solutions.\nWeb3 Authentication: Integrating Privy smoothly into the Next.js app while maintaining a great user experience.Accomplishments that we're proud of:: Successfully combining AI, blockchain, and Web3 authentication into a seamless product.\nAchieving high accuracy in smile detection through AI model optimizations.\nBuilding an interactive and rewarding platform that promotes positivity.What we learned: Best practices for integrating Web3 authentication with Next.js.\nHow to optimize AI models for real-time facial recognition.\nEfficient ways to manage blockchain interactions for micro-transactions.What's next for Smile Please: Expanding to a mobile app for broader accessibility.\nEnhancing AI to detect different positive emotions beyond smiling.\nIntroducing gamification features like streaks and leaderboards to boost engagement.",
                        "github": "https://github.com/shivangjain03/Smile_Please",
                        "url": "https://devpost.com/software/smile-please-3nrwb6"
                    },
                    {
                        "title": "tidbit",
                        "description": "Tik-tok like app for easy recipe finding and cooking inspiration",
                        "story": "",
                        "github": "",
                        "url": "https://devpost.com/software/tidbit-8swjhk"
                    },
                    {
                        "title": "Food Sensi",
                        "description": "Can you eat this food? Analyze your food before eating.",
                        "story": "Overview: Food Sensi is an AI-powered food analysis platform that helps you understand what's in your food and how it might affect you. By simply uploading a photo of your food, you can get detailed insights about ingredients, nutritional content, and potential sensitivities.Key Features: AI-Powered Food Analysis:Instantly identify ingredients in your food through image recognitionMultiple Analysis Modes:FODMAP Analysis for digestive sensitivitiesUSDA Nutritional AnalysisGeneral Food Sensitivity AnalysisRecipe Sharing Platform:Share and discover recipes from other usersPersonalized Insights:Get tailored information about how foods may affect you,Technology Stack: Frontend:React, Next.js 15 (App Router)Authentication & Database:FirebaseImage Storage:UploadThingAI Analysis:Clarifai APIStyling:Tailwind CSS,Local Development: Our technology choices reflect our commitment to robust and efficient solutions:React and Next.js:Dynamic and responsive web application.Firebase:To allow users to store food into our database and authentication.UploadThing:To allow users to upload images to the database.Clarifai:A pre-trained AI model that analyzes food images to identify ingredients and nutritional content.,The Experience: Food Sensi provides an intuitive interface where users can upload food images and receive instant analysis of ingredients and nutritional content. Users can share their recipes, explore others' contributions, and get detailed insights about food sensitivities, FODMAP levels, and USDA nutritional data - helping everyone make informed decisions about their diet.This is aNext.jsproject bootstrapped withcreate-next-app.",
                        "github": "https://github.com/Pho86/journeyhacks-2025",
                        "url": "https://devpost.com/software/food-sensi"
                    },
                    {
                        "title": "miXologist",
                        "description": "An AI powered Cocktail Recipe Bot",
                        "story": "Inspiration: The creativity of bartendersWhat it does: An AI powered cocktail recipe bot that takes user inputs of available ingredients, or simply a chosen \"vibe\", and curates cocktail recommendations based on it.How we built it: Back-end using Python Flask and the latest version of Open AI's API. Front-end using HTML, CSS, and Javascript. Product management and others using Figma, Procreate, and Google Slides.Challenges we ran into: Configuring the OpenAI API and formatting the website properly.Accomplishments that we're proud of: Having a working final product that had all errors and bugs ironed out.What we learned: How to turn a vision to reality- going from planning stage from website to Figma and ProCreate, to eventually coding the website form scratch.What's next for miXologist: Usage by hobbyist bartenders, and adaptations to include food items, since the prompts will be largely the same.",
                        "github": "https://github.com/ShafeiW/JourneyHacks-2025",
                        "url": "https://devpost.com/software/mixologist-n9eruf"
                    },
                    {
                        "title": "HeatSpace",
                        "description": "Let's optimize comfort with HeatSpace",
                        "story": "Optimizing Indoor Heating with Smart Algorithms and AIInspiration\nHeating inefficiencies waste energy and increase costs. Many businesses and homes suffer from poor heat distribution, leading to cold spots, excessive power usage, and discomfort.What if we could analyze and optimize heating systems using AI and computational modeling?HeatSpace is a smart heat optimization system that intelligently analyzes floor plans, simulates heat propagation, and recommends heater placements for maximum efficiency and comfort.What It Does\nHeatSpace allows users to:Upload a 3D Floor Plan (.usdz format)\nDetect cold spots using heat diffusion simulation\nAutomatically generate optimal heater placements\nVisualize the heat coverage with a dynamic heatmap\nAdjust and fine-tune settings for improved efficiency\nHow We Built ItBackend: Flask, NumPy, OpenCV, SciPy\nFrontend: Next.js (React), TailwindCSS\nData Processing: USDZ to OBJ Conversion\nAlgorithms:\nHeat Diffusion Simulation (Gaussian Decay Model)\nOptimal Heater Placement (k-D Tree + Greedy Optimization)\nWall & Obstacle Detection (Computational Geometry)\nWhy It MattersEnergy Efficiency: Reduces heating costs for homes, offices, and smart buildings\nComfort Optimization: Ensures even heat distribution\nSustainability: Lowers carbon footprint by minimizing wasted heat\nIoT & Smart Home Ready: Can integrate with smart thermostats and HVAC systems\nChallenges We FacedUSDZ to 2D Floor Plan Conversion \u2013 required custom 3D processing\nAccurate Heat Propagation Simulation \u2013 refined heat diffusion modeling\nOptimizing Placement for Different Room Layouts \u2013 used machine learning and computational geometry\nFuture EnhancementsAI-Powered Adaptive Heating \u2013 dynamically adjust heat output in real-time\nMachine Learning for Personalized Climate Control\nIoT Integration with Smart Thermostats\nWeb & Mobile App Expansion for user control",
                        "github": "https://github.com/Ekanshthegreat/SafeSpace",
                        "url": "https://devpost.com/software/heatspace"
                    },
                    {
                        "title": "Food Wars",
                        "description": "This game is a food shooter and it never ends, you can shoot at donuts till the end of time, until your hunger is satiated.",
                        "story": "Inspiration: FoodWhat it does: it is a game that will end your boredom and increase your hungerHow we built it: We built it using pygame in python & OOPChallenges we ran into: shooting out lasersAccomplishments that we're proud of: its workingWhat we learned: we learnt how to use pygame and we designed our very first gameWhat's next for Food Wars: make scoring, create an end where the player loses",
                        "github": "https://github.com/layanb4/Food-Wars",
                        "url": "https://devpost.com/software/food-wars-t42hji"
                    },
                    {
                        "title": "Food Finder",
                        "description": "Is you're significant other constantly saying \"I don't know what to eat\" and \"I'm hungry\"? Food Finder is here to help!",
                        "story": "",
                        "github": "https://github.com/ribsyo/journeyHacks",
                        "url": "https://devpost.com/software/food-finder-y76cvd"
                    },
                    {
                        "title": "clubbr",
                        "description": "sfss club days in a website",
                        "story": "Inspiration: SFSS WebsiteWhat it does: Its a Schedule Website that manages your club eventsHow we built it: next.jsChallenges we ran into: xAccomplishments that we're proud of: xWhat we learned: 8 hr is very hard to make a projectWhat's next for clubbr: dev?",
                        "github": "https://github.com/JeknJok/clubbr",
                        "url": "https://devpost.com/software/clubbr"
                    }
                ]
            ]
        },
        {
            "title": "Global Hack Week: AI/ML",
            "location": "Online",
            "url": "https://global-hack-week-ai-ml-23773.devpost.com/",
            "submission_dates": "Feb 07 - 13, 2025",
            "themes": [
                "Beginner Friendly",
                "Machine Learning/AI",
                "Open Ended"
            ],
            "organization": "Major League Hacking",
            "winners": false,
            "projects": []
        },
        {
            "title": "BCHACKS 6.0",
            "location": "Charles E. Fipke Centre",
            "url": "https://bchacks-6.devpost.com/",
            "submission_dates": "Feb 09, 2025",
            "themes": [
                "Beginner Friendly",
                "Design",
                "Open Ended"
            ],
            "organization": "Computer Science Course Union",
            "winners": false,
            "projects": [
                [
                    {
                        "title": "Escape the Ordinary",
                        "description": "Unconventional Escape Room: Break the rules, solve the puzzles, and escape the ordinary!",
                        "story": "Inspiration: The inspiration for Escape the Ordinary came from the desire to challenge the traditional escape room concept. Instead of relying on typical puzzle-solving and physical locks, we wanted to create an immersive experience that blends unpredictable elements with engaging gameplay. The idea of an unconventional escape room is to offer players a fresh, mind-bending adventure that keeps them on their toes with every twist and turn.What it does: Escape the Ordinary is a dynamic, unpredictable game that takes the player through a series of unconventional puzzles, each randomly generated to ensure no two playthroughs are the same. The game features:\nRandomized puzzles: Mini-games like number guessing, dot clicking, and riddles, each with varying difficulty levels.\nTime-based mechanics: Players must solve puzzles before time runs out to move on to the next challenge.\nImmersive environment: The game\u2019s visual design is meant to complement the chaotic, unexpected gameplay.How we built it: We built Escape the Ordinary using Python and Pygame, which provided the flexibility needed for real-time game mechanics and graphics rendering. The steps included:\nGame Design: We conceptualized the flow of the game, incorporating different types of puzzles and interactions.\nProgramming: The game was coded using Python, with Pygame handling the graphical interface, random puzzle generation, and timing elements.\nGraphics: We designed visual assets for each puzzle, including backgrounds, buttons, and timers to enhance the immersive experience.Challenges we ran into: Puzzle Randomization: Ensuring that puzzles were unique for each session while maintaining a logical flow was tricky. It required building algorithms that could adapt based on player choices and time constraints.\nUser Input Management: Handling various input methods (keyboard, mouse, and clicks) seamlessly across mini-games proved difficult at times.\nBalancing Difficulty: Adjusting the difficulty of puzzles while keeping the game engaging and fair was an ongoing challenge.Accomplishments that we're proud of: Unique gameplay: The combination of time-based pressure, randomization, and diverse puzzles provides a truly one-of-a-kind experience.\nSmooth User Experience: Despite the complexity of the random puzzles and time constraints, we managed to keep the gameplay fluid and accessible.\nA polished prototype: We\u2019re proud to have a fully functional prototype that offers a complete escape room experience, even in its early stages.What we learned: Creative Problem Solving: We learned how to think outside the box and incorporate randomness into gameplay without losing player engagement or creating frustration.\nGame Development Fundamentals: From handling game loops in Pygame to working with timers and random generation, we gained valuable experience in developing interactive games.\nTeam Collaboration: Collaborating closely with each other helped us merge ideas and techniques to make the game both fun and challenging.What's next for Escape the Ordinary: Additional Levels & Puzzles: We plan to add more levels with new types of puzzles and challenges.\nMultiplayer Mode: Introducing multiplayer functionality where players can solve puzzles together or race against each other.\nMobile Version: Converting the game into a mobile-friendly format so players can enjoy Escape the Ordinary on-the-go.\nStory Mode: Adding an overarching narrative that ties the puzzles together and gives players more context behind the challenges.",
                        "github": "https://github.com/PrashaantM/textEscapeRoom",
                        "url": "https://devpost.com/software/dream-weaver-igc3np"
                    },
                    {
                        "title": "Recipe Receptionist ",
                        "description": "Bite-Sized Insights: Watch, Analyze, and Savor Every Detail\u2014Your AI-Powered Food Video Companion! ",
                        "story": "Inspiration: We created Recipe Receptionist to solve the frustration of finding specific moments in long videos, like key lecture examples or unique cooking tips. We also wanted to make video content more accessible for people with disabilities, such as those with visual or hearing impairments, who often struggle to access or interpret videos.What it does: The app lets users upload a video or paste a URL. It analyzes the video frame by frame, transcribes the audio, and lets users ask specific questions about the content. For example:Students can ask, \"What was the example problem solved at 30 minutes?\"Cooking enthusiasts can ask, \"What was the chef\u2019s secret tip?\"For accessibility:Visually impaired users: Get audio descriptions of visual content.Hearing-impaired users: Receive accurate transcriptions and visual summaries.Cognitive disabilities: Simplifies complex video content into easy-to-understand answers.How we built it: Frontend: Streamlit for a simple interface.Backend: Python for video and audio processing.APIs: OpenAI\u2019s Whisper for transcription and GPT-4 for answering questions.Video Processing: OpenCV for frames and FFmpeg for audio extraction.URL Handling: you-get to download videos from URLs.Challenges we ran into: Slow video processing for long videos.API rate limits from OpenAI.Ensuring accessibility for disabled users.Handling large video files and different formats.Accomplishments that we're proud of: It's super lightweight and comprises two essential files, and relatively few modules are needed. Perfect for microsystems.Integrating multiple technologies into a seamless app.Making video content more accessible and inclusive.Building a functional prototype quickly.Positive feedback from the accessibility community.There are many image detection/analyzing apps but not many video ones, so this is in a league of its ownWhat we learned: Balancing performance and accuracy in video processing.How AI can make content more inclusive.Handling large datasets and optimizing efficiency.The importance of user feedback for improvement.What's next for Recipe Receptionist: Better Accessibility: Add sign language interpretation, text-to-speech, and real-time captions.Faster Performance: Optimize processing for longer videos.Smarter AI: Add summarization, keyword search, and emotion analysis.User Customization: Let users adjust settings like frame rate and language.Platform Integration: Work with YouTube, Vimeo, and Coursera.Community Collaboration: Open-source the project and partner with accessibility organizations.",
                        "github": "https://github.com/Toughboli/Recipe-Receptionist",
                        "url": "https://devpost.com/software/recipe-receptionist"
                    },
                    {
                        "title": "Chromesthesia",
                        "description": "Chromesthesia, a neurological condition that blends sights and sounds, a modern audio video art piece",
                        "story": "Inspiration: The inspiration for our project was to create a system that can simulate chromesthesia in the form of art and also generate perceptive descriptionsWhat it does: The system we built allows user to visualize and generate audio visual art. This system will:Display audio in an unconventional wayHelp spread awareness of chromesthesiaProvide insightful descriptions of art pieces,How we built it: Using an engine in python, the script creates shape and form visualization of an audio file and displays what people with chromesthesia could possibly experienceChallenges we ran into: As this is a hackathon project, the obvious challenge we ran into is time as we want to make a somewhat functional and presentable project in a 2 days span. The other is the fact that we never use the Django with react before.Accomplishments that we're proud of: Some accomplishments that we're most proud of are:Django to frontend apiChromesthesia visualizationsReact frontendSeamless integration modelsEngaging animations,What we learned: We learned how to use Django framework implemented together with a react front endWhat's next for Chromesthesia: Our big goal for chromesthesia is to spread awareness about differing neurological conditions that may affect people around us",
                        "github": "https://github.com/bobtrolledu/BCHacks6",
                        "url": "https://devpost.com/software/chromesthesia-75xtzb"
                    },
                    {
                        "title": "ExpressiWay",
                        "description": "ExpressiWay allows people to chat with and understand each other using a common symbol language - emoji and kaomoji, hence breaks the barrier of language in an international communication setting. ",
                        "story": "\ud83c\udf1fInspiration: Communication is fundamental to human interaction, yet for many individuals\u2014especially those with Autism Spectrum Disorder (ASD)\u2014traditional text-based methods can feel restrictive. We envisionedExpressiWayas a platform where language is more than words, enabling users to express themselves invisual, auditory, and symbolicways.\ud83d\udd25What It Does: \ud83c\udfa8Multimodal Chat Platform: ExpressiWay is a revolutionaryLLM-poweredchat system that breaks away from text-only conversations.\u2728Key Features:\ud83d\udfe1AI-generated emojis & symbolsto convey emotions.\ud83d\udd35Visual imagesto enhance expression.\ud83d\udd34Sound clipsfor non-verbal communication.\ud83c\udf0dDesigned for both ASD and general usersto promote inclusion.,ExpressiWay bridges thegap between neurodivergent and neurotypical communication styles, making conversations morenatural and expressive.\ud83d\udee0\ufe0fHow We Built It: Backend:\u2699\ufe0f Python & Flask for lightweight, efficient RESTful APIs.Frontend:\ud83c\udfa8 JavaScript, HTML, and CSS for a smooth, accessible UI.AI Integration:\ud83e\udd16 Google Gemini LLM, fine-tuned foradaptive multimodal output.,RESTful API-based communicationensuresstructured & secure interactions.LLM-generated multimodal expressionstailored to different communication styles.Scalable architectureto support multiple chatrooms and dynamic responses.,\u2694\ufe0fChallenges We Faced: \ud83d\udd39Fine-tuning AI for social expression:Making Google Gemini generatecontextually relevantmultimodal responses.\ud83d\udd39Balancing inclusivity & usability:Designing a system that works forboth ASD users and the general public.\ud83d\udd39Optimizing response time:Achievingreal-time performancewhile using RESTful APIs instead of WebSockets.\ud83c\udfc6Accomplishments We're Proud Of: \u2705 Successfullyintegrated AI-driven multimodal communication.\u2705 Created atruly inclusivechat experience thatbreaks linguistic barriers.\u2705 Fine-tuned Google Gemini foradaptive, meaningful interactions.\u2705 Built ascalable, accessiblechat system that supports diverse user needs.\ud83c\udf93What We Learned: \ud83d\udca1Understanding ASD communication styleswas crucial for refining our approach.\ud83d\udca1Fine-tuning LLMs for social interactionsrequires deep insights intolinguistic & non-verbal expression.\ud83d\udca1Optimizing RESTful API communicationcan achieve near real-time performance without WebSockets.\ud83d\udca1Accessibility testingis key to ensuringseamless user experiencesfor diverse communities.\ud83d\ude80What's Next for ExpressiWay?: \ud83d\udd1cExpanding multimodal capabilities:Integratinggesture-basedandhaptic feedbackfeatures.\ud83d\udd1cVoice-to-symbol translation:Allowing users tospeak while AI generates visual representations.\ud83d\udd1cPersonalized AI adaptability:Further refiningGoogle Gemini\u2019s responsesto cater to user preferences.\ud83d\udd1cCommunity-driven customization:Enabling users todefine their own multimodal response styles.\ud83c\udf0dExpressiWay is just the beginning of a new era of inclusive communication\u2014where every voice finds its perfect path.Please find detailed information about the motivation and what we have achieved of this project in our github repo page andReadMe",
                        "github": "https://github.com/m-iDev-0792/ExpressiWay",
                        "url": "https://devpost.com/software/babel-chatting-room"
                    },
                    {
                        "title": "Ge0de's Online Banking System",
                        "description": "Online Unconventional Banking Website",
                        "story": "Inspiration: Unconventional Avant-Garde Originality.What it does: It's a banking website, but not exactly. It's got a bunch of easter eggs. Have fun.How we built it: All-nighters on VSCode working on JS, HTML, CSS.Challenges we ran into: Keeping the willpower up while coding until 6 AM.Accomplishments that we're proud of: Nothing has been accomplished yet. The awards await.What we learned: Discipline, Camaraderie, Sacrifice.What's next for Ge0de's Online Banking: Larger Scale Web App if it ends up winning.",
                        "github": "https://github.com/ge0de/BC-Hacks-6.0-Hackathon",
                        "url": "https://devpost.com/software/ge0de-s-online-banking"
                    },
                    {
                        "title": "Get Swole",
                        "description": "Your AI-powered workout application-track, analyze, and perfect your form in real-time with intelligent motion detection!",
                        "story": "Inspiration: Began as a team of two but became one before we even started. Despite the challenges, I eventually came to making an application that highlights computer vision and its applications which turned into trying to help my lack of going to the gym. \nGOAL: Help lifters perfect their form, track their progress, prevent injuries--just like having a personal trainer, but smarter.What it does: Get Swole uses real-time computer vision and AI-powered motion analysis to track workouts like deadlifts, squats, and bench presses. By leveraging landmark detection and joint angle calculations, it provides instant feedback on form, rep counting (unfinished), and overall workout efficiency.How I built it: Frontend: Built with React and styled using Tailwind CSS\nBackend: Developed with Flask and Socket.IO, the main bulk being a MediaPipe implementation for real-time pose detection\nAI Models: Machine learning models trained to recognize and analyze key workout movemennts, predicting reps and form accuracy.\nLive Streaming: Uses OpenCV and WebSockets (Socket.IO) to send real-time video data from the backend to the frontend.Challenges we ran into: Mislabeled ASCII key bindings ~ 1 hour\nFailed to do frontend and backend ~ 5 hours\nSlept ~ 8 hours\nConnecting ports ~ 3 hours\nTried to do frontend and backend and wasted lots of time making an NLP algorithm just to realize it had nothing to do with my original concept at all ~ 5 hours\nPrompt Engineering debugging ~ 10 hoursAccomplishments that we're proud of: Successfully implemented MediaPipe and tailored it with logistic regression models to predict bad posture thresholds.Built a fully functional live streaming systemCreated a user-friendly UI that gives users the option to test out different models (do all models work? no)Overcame major technical obstacles as someone who has never touched frontend, directories, backend, really anything except for Jupyter notebook and AI.,What we learned: Learned how to implement MediaPipeDeveloped stronger directory and data preprocessing skillsLearned how to use WebSockets, Flask, React, Node.js, CSSLearned how to integrate frontend and backend applications,What's next for Get Swole: More workout models: Get models that can fix your posture on all workout variantsForm correction feedback: Original idea was to create a savage gym trainer that would chastise the user and emotionally manipulate them to continue working outProgress tracking: Implement a dashboard of some kindCreate a leaderboard,",
                        "github": "https://github.com/SealKFC/HackathonCS6.git",
                        "url": "https://devpost.com/software/get-swole"
                    }
                ]
            ]
        },
        {
            "title": "UpStart 2025: Entrepreneurship Competition",
            "location": "Concordia University - JMSB Building",
            "url": "https://upstart-2025.devpost.com/",
            "submission_dates": "Feb 08 - 09, 2025",
            "themes": [
                "Beginner Friendly",
                "Enterprise",
                "Open Ended"
            ],
            "organization": "GinaCody School Entrepreneurship Society",
            "winners": false,
            "projects": [
                [
                    {
                        "title": "RideQuest",
                        "description": "RideQuest is an AI-powered gamified rewards app that incentivizes eco-friendly commuting by offering points, achievements, and exclusive discounts.\r\n",
                        "story": "Inspiration: As software engineering students who rely on public transit daily and care deeply about the health of our planet, we wanted apply our technical skills to create a fun and engaging way to encourage people like us to adopt eco-friendly commuting habits. We were inspired by the potential of gamification and AI to drive behavioural change, making sustainable travel not just a responsibility but an enjoyable and rewarding experience.What it does: RideQuest is an AI-powered gamified rewards app that incentivizes users to choose eco-friendly transportation methods such as biking, walking, carpooling, or using public transit. Users earn points based on their commuting choices, unlock achievements, and gain access to exclusive discounts and rewards. The app also features AI-driven route optimization, social challenges, and leaderboards to keep users engaged.",
                        "github": "",
                        "url": "https://devpost.com/software/ridequest"
                    },
                    {
                        "title": "SafeShift",
                        "description": "Workplace accidents cost lives. Our AI detects hazards in real time, preventing injuries before they happen. Safer workers, fewer tragedies. Because safety should never be an afterthought.",
                        "story": "Inspiration: Having experiences in the workfield, one of our teammates was petrified by the alarming amount of overlooked security protocols that occur on a daily basis. The place wascrawlingwith hand pallet trucks and forklifts, but they never suggested to his 16 year old self to wear steel-toe shoes. It is our duty as citizens of the world to ensure proper safety amongst all workers.What it does: SafeShift is an advanced AI-powered system designed to detect workplace safety hazards in real-time. Our solution is fully customizable, allowing businesses to define specific safety requirements based on their industry needs. For smaller-scale companies, we offer a pre-configured version with built-in safety detections for essential protective gear, available at a more accessible rate. Whether it\u2019s ensuring compliance with PPE regulations or identifying hazardous workplace behaviors, SafeShift provides a proactive approach to safety monitoring.How we built it: We made an in-house machine learning algorithm and trained it on an extensive, open-source computer vision dataset. Our AI continuously improves through deep learning, ensuring accurate detection and adaptation to diverse workplace environments.  It has over 3.6 million parameters.Challenges we ran into: We were severely limited by time. Built under tight deadlines, we didn't have the resources to fully train our prototype model to its full capacity. Also, if given more time, we could train the same AI model to detect litter. This would add value by making our company more green and sustainable.Accomplishments that we're proud of: Despite the constraints, our current model successfully detects essential PPE such as hard hats. This is just the beginning\u2014our vision for workplace safety is clearer than ever, and we\u2019re proud to have taken the first step toward revolutionizing safety monitoring through AI.What we learned: Beyond technical development, we gained valuable insight into the entrepreneurial side of software engineering. Understanding profit margins, B2B partnerships, and real-world business strategies reshaped how we approach software development\u2014not just as engineers but as innovators building a scalable and impactful solution.What's next for SafeShift: Our goal is to integrate an expansive range of safety procedures into SafeShift. From construction sites to warehouses, factories, and beyond, we envision a future where workplace accidents become a thing of the past\u2014because no one should have to compromise on safety.",
                        "github": "https://github.com/OrangeMold/ComputerVisionDemo",
                        "url": "https://devpost.com/software/safeshift"
                    },
                    {
                        "title": "Snow Pathway",
                        "description": "Navigate the path to your lecture\u2019s key moments",
                        "story": "Inspiration: The idea behind \"SnowPathway\" was inspired by students' need for a more engaging e-learning experience. Many struggle with short attention spans and difficulty pinpointing essential information in lengthy lectures. \"SnowTrail\" solves this by offering an interactive platform that guides students to crucial moments in lectures, enabling them to access accurate answers swiftly and effectively.What it does: Video Transcription with Deepgram:Why Deepgram? For video ingestion, transcription is crucial. Deepgram\u2019s API is leveraged to extract sentence-level timestamps, allowing precise mapping of spoken content to video durations.\nChunking Videos: Using sentence-level timestamps, videos are segmented into chunks of specific durations. A sliding window approach with overlapping chunks is applied to maintain context continuity between segments.\nDocument Processing with Amazon Textract:From Cortex to Textract: Initially, Cortex\u2019s parse document function was considered. However, its lack of page-level extraction led to a switch to Amazon Textract, which supports fine-grained processing.\nStoring Processed Chunks: Once processed, lecture chunks are stored in a Cortex table, which forms the backbone of the search service, enabling efficient indexing and retrieval.\nQuery Processing:Queries are derived from the user\u2019s chat history and rephrased to resolve ambiguous references.\nUsers can apply filters, such as lecture name, triggering metadata filtering to narrow down search results.\nCortex\u2019s Hybrid Search:Cortex combines metadata filtering with semantic search to identify the most relevant lectures.\nThe system retrieves the top three documents, complete with their associated content.\nAI Response Generation:The Mistral-Large-2 model generates AI-driven responses using the retrieved documents.\nUsers are provided with response context, including page numbers and timestamps, for quick access to source materials.Trulens Evaluation: Metadata Filtering vs. Global Search:Local search (using metadata) and global search were compared for lecture content localization.\nResults: Cortex\u2019s search algorithm proved robust, delivering comparable relevance in both approaches. Metadata filtering, however, provided faster results by narrowing the search scope.\nChunk Duration Optimization:Three chunk durations were tested: 30 seconds, 1 minute, and 2 minutes, each with a slight overlap to preserve context.\nFindings:\nLarger chunks increased latency due to higher token consumption.\n60-second chunks struck the optimal balance, achieving 90% answer relevance while maintaining efficiency.What's next for Snow Pathway: integration with image captioning to understand whiteboard stills from lecture videos\ngeneral summary of the lecture by breaking it down into meaningful shorts\ngenerate flashcards from lecture content to quiz students what they learn",
                        "github": "",
                        "url": "https://devpost.com/software/snow-pathway"
                    },
                    {
                        "title": "Whereabouts?",
                        "description": "A topical and innovative app that allows you to scan the label of any item and have it tell you were it\u2019s from and suggest local alternatives",
                        "story": "Inspiration: We were inspired by recent events. We wanted to make something topical and useful that can capitalize on the current state of society, especially in Canada. With all of these talks of tariffs, we're franklytArrffied. With a strong emphasis on shopping local, we wanted to make something that is easy as possible for the average person to use.What it does: Our app allows users to scan products and figure out where they come from! Users can shop locally and reduce their carbon footprint at the same time!How we built it: We built the mock-up of the app using primarily Figma and Canvas was used for the pitch deck.Challenges we Faced: We struggled determining an idea for the project and we spent quite a lot of time brainstorming and not working.Achievements: We are proud to have been able to accomplish what we did. We were able to make a proper app mock-up and did plenty of research involved in starting a business. We worked together as a team to make a wonderful app that we believe is important and impactful.What's next for Whereabouts?: We plan on expanding our product globally and helping everyone worldwide to be sustainable and shop knowingly.",
                        "github": "",
                        "url": "https://devpost.com/software/whereabouts-tqpls8"
                    },
                    {
                        "title": "SafeRide",
                        "description": "SafeRide ensures safer commutes with quick video reporting, live location sharing, and instant access to authorities. AI categorizes incidents, prioritizes urgent cases, and learns from past reports.",
                        "story": "SafeRide was inspired by the growing need for a faster, more reliable way to report safety incidents in public transit. Many cases go unreported or escalate due to slow response times, misinformation, or lack of proper reporting channels. Our solution is a user-friendly platform that allows commuters to quickly report incidents with video, notify authorities, firefighters, and first responders instantly, and share their live location in emergencies. AI will help categorize reports, assign priority levels, and learn from past incidents to improve response times and decision-making.However, bringing this idea to life comes with challenges. Securing funding to develop and deploy the platform might be challenging, as building a robust and secure system requires resources. Ensuring AI accuracy, integrating with transit systems like Chrono, and gaining the trust of authorities and commuters are also key obstacles we must overcome.Despite these challenges, we believe SafeRide has the potential to revolutionize transit safety. Looking ahead, we aim to refine our concept, explore partnerships, and secure the necessary support to turn this vision into a reality.",
                        "github": "",
                        "url": "https://devpost.com/software/saferide-9gs3o1"
                    },
                    {
                        "title": "Cogo Carpooling",
                        "description": "saftey",
                        "story": "",
                        "github": "",
                        "url": "https://devpost.com/software/cogo-carpooling"
                    },
                    {
                        "title": "Sponta",
                        "description": "Sponta: made to be spontaneous is an application to help build a schedule to go on activities in different cities",
                        "story": "",
                        "github": "",
                        "url": "https://devpost.com/software/sponta"
                    },
                    {
                        "title": "Camel Crew",
                        "description": "Transportation Optimization System",
                        "story": "",
                        "github": "",
                        "url": "https://devpost.com/software/camel-crew"
                    },
                    {
                        "title": "[16] - FreeWheel - A voice control wheelchair",
                        "description": "Freewheel is autonomous electric wheelchair designed for people with reduced mobility. The product aims to make people physically safe all by keeping their independence. ",
                        "story": "For people with reduced mobility, even moving around their own home can be unsafe. Navigating tight spaces, avoiding obstacles, and controlling a wheelchair manually can be difficult, leading to frustration and potential risks.The usual solution? Relying on a caregiver. But constantly needing help takes away a person\u2019s sense of independence and freedom in their own space.That\u2019s why we created Freewheel\u2014a voice-controlled smart wheelchair designed to make indoor mobility both safe and independent. Using a smartphone app that integrates with Siri and Google Assistant, users can control their wheelchair with simple voice commands.The proximity sensors detect walls and obstacles, which provides secure movement without collisions. Our product only works inside households, since it can have potential dangers otherwise.With Freewheel, people no longer have to choose between safety and independence\u2014they can have both. Our project falls under Personal Safety, because we believe that true safety means being able to move freely without risks or constant assistance. By combining smart technology with mobility aid, we\u2019re giving people the confidence to navigate their homes safely and on their own terms.",
                        "github": "",
                        "url": "https://devpost.com/software/freewheel-a-voice-control-wheelchair"
                    },
                    {
                        "title": "IgniSense",
                        "description": "Nature breathes, Our solution act",
                        "story": "",
                        "github": "",
                        "url": "https://devpost.com/software/ignisense"
                    },
                    {
                        "title": "INDUPRENEURS/SACS",
                        "description": "SACS",
                        "story": "",
                        "github": "",
                        "url": "https://devpost.com/software/indupreneurs-sacs"
                    },
                    {
                        "title": "Buckle Buddy",
                        "description": "Buckle Buddy is a seat belt adjuster aiming to reduce the risk of injuries in car crashes for females  due to seatbelt misplacement. It's a product for women made by women.",
                        "story": "",
                        "github": "",
                        "url": "https://devpost.com/software/buckle-buddy"
                    },
                    {
                        "title": "Theft Bait",
                        "description": "A secure, durable, customizable, and stylish backpack designed to protect your valuables and enhance your everyday life.",
                        "story": "Inspiration: While traveling, we were afraid of getting our items stolen or our bags pickpocketed so we were constantly on high alert or holding our bags in the front so we could make sure they were secure.What it does: High security backpack with anti-theft and anti-pickpocketing features that protects people, especially travellers, from being worried about getting their valuables stolen.How we built it: We will need manufacturers and suppliers for the materials. We prompted image generation tools in order to get a mockup of the product and our web developer designed and created the website.Challenges we ran into: The pitch deck took a long time to finish due to the extensive market, material and industry research that had to be performed.Accomplishments that we're proud of: We are proud that we came up with a way to include unique features in our product with a high profit margin and competitive pricing while working together as a team efficiently.What we learned: We learned that time management is crucial to successful idea and product development and that clear communication with visual demonstrations is the easiest way to avoid misunderstandings.What's next for Theft Bait: We plan to expand to get into retail stores while also creating various limited edition collections and designs. We will also expand our product range to include other types of bags with similar features and technology. For instance, backpacking ones used to travel over long periods of time.",
                        "github": "",
                        "url": "https://devpost.com/software/theft-bait"
                    },
                    {
                        "title": "KenKoo",
                        "description": "KenKoo is an AI-driven wellness platform that transforms raw health data into personalized, predictive, and actionable insights, Unlike traditional health trackers that simply monitor metrics.",
                        "story": "I was inspired by my own personal story and challenges with health after having experimented in various ways with myself, in terms of diet, protocols, supplements and so on. I have tried to optimized for everything manually and decided that KenKoo was the all in one integrated solution for meUnfinished UI :(  ->https://v0.dev/chat/ken-koo-ui-design-dzjZZeY7ec5?b=b_8wddDsueuiDLinktree :) ->https://linktr.ee/iampades",
                        "github": "",
                        "url": "https://devpost.com/software/kenkoo"
                    },
                    {
                        "title": "UpThrust",
                        "description": "EcoThrust enables major airline hubs to meet government sustainability targets by providing an accessible way for airlines to refuel eco-friendly fuel on demand in their respective terminals. ",
                        "story": "",
                        "github": "",
                        "url": "https://devpost.com/software/upthrust"
                    },
                    {
                        "title": "IADS",
                        "description": "IADS is an intelligent AI system to prevent drowning",
                        "story": "Intelligent Anti-Drowning System (IADS) \u2013 Revolutionizing Pool Safety with AIDrowning remains a leading cause of accidental death, especially among young children. Traditional safety measures require constant supervision, which isn\u2019t always possible. IADS (Intelligent Anti-Drowning System) is here to change that.What is IADS?\nIADS is a cutting-edge AI-powered surveillance system designed to monitor swimming pools in real-time, detect potential drowning risks, and alert caregivers immediately\u2014ensuring safety without the need for constant human supervision.What Makes IADS Unique?\n\ud83c\udf0a Advanced AI Monitoring \u2013 Detects distress signals and unusual movements in the water.(Pose Detection)\n\ud83d\udcb0 Cost-Effective Solution \u2013 More affordable than existing drowning prevention technologies.\n\ud83c\udf31 Eco-Friendly Design \u2013 Built with 3D-printed components and solar-powered options for outdoor pools.\n\ud83d\udd0b Sustainable Power \u2013 Operates on a rechargeable battery, ensuring reliability even in off-grid locations.\n\ud83d\udce1 Instant Alerts \u2013 Sends real-time notifications to caregivers, parents, and pool owners.With IADS, we bring peace of mind to families, pool owners, and communities by making swimming safer, smarter, and more sustainable.Enjoy the water\u2014worry-free. IADS is always watching, so you don\u2019t have to.Would you like this to be tailored further for investors, customers, or a business proposal? \ud83d\ude0a\ud83d\ude80",
                        "github": "",
                        "url": "https://devpost.com/software/iads"
                    },
                    {
                        "title": "Safey",
                        "description": "A smart way to stay safe",
                        "story": "Every second counts in an emergency. Whether it's an elderly parent needing assistance, a hiker lost in the wilderness, or a woman walking alone at night, having a reliable way to call for help can save lives. That\u2019s why we created the Emergency Alert Bracelet a small, lightweight, and cost-effective solution designed to keep you connected when it matters most.\nWith a simple sliding mechanism to prevent accidental activation, the bracelet connects to a smartphone app via Bluetooth to send distress signals to pre-selected contacts. When triggered, it shares the user\u2019s real-time GPS location, alerting loved ones and bypassing the need to contact emergency services like 911. But what truly sets our bracelet apart is its offline capability: even in areas without internet or Bluetooth connectivity, the bracelet can send a standalone GPS signal through long-range, low-power networks, ensuring you're never truly out of reach.\nThe accompanying app goes a step further, offering real-time hazard mapping. By analyzing crime statistics, lighting data, and pedestrian infrastructure, it warns users of dangerous routes and suggests safer alternatives. Together, the bracelet and app form a powerful safety ecosystem, designed for accessibility and affordability.\nWhether you're protecting your loved ones or safeguarding yourself, the Emergency Alert Bracelet redefines personal safety. It\u2019s not just a product; it\u2019s peace of mind in your pocket, ready to respond when the unthinkable happens.",
                        "github": "",
                        "url": "https://devpost.com/software/safey-bracelet"
                    },
                    {
                        "title": "SafePath",
                        "description": "AI-Powered Safety Assistant",
                        "story": "",
                        "github": "",
                        "url": "https://devpost.com/software/safepath-rsedu1"
                    },
                    {
                        "title": "EcoFlow",
                        "description": "EcoFlow",
                        "story": "Abt inside the Zip.",
                        "github": "",
                        "url": "https://devpost.com/software/ecoflow-of5q1g"
                    },
                    {
                        "title": "Hoyt",
                        "description": "Finding street parking is a headache, a waste of time, and a polluter. We are building an app that provides real-time accurate parking recommendations to frustrated drivers.",
                        "story": "It is a system that allows users to search for a destination and visualize parking availability based on precomputed and live parking data. Destinations are grouped into zones (100m\u00b2), and parking attempts are clustered into regions (50m\u00b2). Each region has a probability score that determines how easy or difficult it is to find parking. Users interact with an interactive map where regions are color-coded based on parking probability. When a user hovers over a region, they can see detailed parking statistics for that area. By using a static dataset, the app provides fast and realistic parking insights, allowing users to simulate real-world parking conditions.",
                        "github": "",
                        "url": "https://devpost.com/software/hoyt"
                    }
                ]
            ]
        }
    ]
}